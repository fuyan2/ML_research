{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fuyan2/ML_research/blob/master/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UbSar6wsliRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "outputId": "5b405660-a5ec-4baa-ed6a-454c089a7c65"
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pdb\n",
        "import copy\n",
        "import multiprocessing as mp\n",
        "\n",
        "from datetime import datetime\n",
        "from skimage.measure import compare_ssim\n",
        "\n",
        "#Defining Parameters\n",
        "IMG_ROWS = 2\n",
        "IMG_COLS = 1\n",
        "NUM_LABEL = 2\n",
        "INV_HIDDEN = 50\n",
        "EPOCHS = 100\n",
        "learning_rate = 0.1\n",
        "loss_beta = 0.001\n",
        "BATCH_SIZE = 250\n",
        "\n",
        "#Flatten input dataset\n",
        "x1_0 = np.reshape(np.random.uniform(-11,11, 500), [500,-1])\n",
        "\n",
        "x2_0 = np.sqrt(15**2 - x1_0**2) \n",
        "x3_0 = np.sqrt(14**2 - x1_0**2)\n",
        "x4_0 = np.sqrt(13**2 - x1_0**2)\n",
        "x5_0 = np.sqrt(12**2 - x1_0**2)\n",
        "x6_0 = np.sqrt(11**2 - x1_0**2)\n",
        "\n",
        "x_0_0 = np.concatenate((x1_0, x2_0), axis=1)\n",
        "x_0_1 = np.concatenate((x1_0, x3_0), axis=1)\n",
        "x_0_2 = np.concatenate((x1_0, x4_0), axis=1)\n",
        "x_0_3 = np.concatenate((x1_0, x5_0), axis=1)\n",
        "x_0_4 = np.concatenate((x1_0, x6_0), axis=1)\n",
        "\n",
        "\n",
        "x1_1 = np.reshape(np.random.uniform(-1,21, 500), [500,-1])\n",
        "x2_1 = - np.sqrt(15**2 - (x1_1 -10 )**2)-0.3\n",
        "x3_1 = - np.sqrt(14**2 - (x1_1 -10 )**2)-0.3\n",
        "x4_1 = - np.sqrt(13**2 - (x1_1 -10 )**2)-0.3\n",
        "x5_1 = - np.sqrt(12**2 - (x1_1 -10 )**2)-0.3\n",
        "x6_1 = - np.sqrt(11**2 - (x1_1 -10 )**2)-0.3\n",
        "\n",
        "x_1_0 = np.concatenate((x1_1, x2_1), axis=1)\n",
        "x_1_1 = np.concatenate((x1_1, x3_1), axis=1)\n",
        "x_1_2 = np.concatenate((x1_1, x4_1), axis=1)\n",
        "x_1_3 = np.concatenate((x1_1, x5_1), axis=1)\n",
        "x_1_4 = np.concatenate((x1_1, x6_1), axis=1)\n",
        "\n",
        "# print(x_1.shape)\n",
        "x_train = np.concatenate((x_0_0,x_0_1,x_0_2, x_0_3, x_0_4, x_1_0, x_1_1, x_1_2, x_1_3, x_1_4), axis=0)\n",
        "# print(x_train.shape)\n",
        "# print(x_train)\n",
        "y_0 = np.full((2500,1),0, dtype=np.int32)\n",
        "y_1 = np.full((2500,1),1, dtype=np.int32)\n",
        "y_train = np.concatenate((y_0,y_1), axis=0)\n",
        "# print(y_train.shape)\n",
        "# print(y_train)\n",
        "# plt.plot(x_train[0:2500,0], x_train[0:2500,1],'.')\n",
        "# plt.plot(x_train[2500:5000,0], x_train[2500:5000,1],'.')\n",
        "train = np.concatenate((x_train,y_train),axis=1)\n",
        "np.random.shuffle(train)\n",
        "# print(train.shape)\n",
        "# print(train)\n",
        "plt.plot(train[:,0], train[:,1],'.')\n",
        "x_train = train[:,[0,1]]\n",
        "y_train = train[:,[2]]\n",
        "print(x_train)\n",
        "print(y_train)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  8.84647097 -13.24872082]\n",
            " [ 10.53795041 -14.2896608 ]\n",
            " [  5.96240934  10.41391736]\n",
            " ...\n",
            " [  4.48204412 -14.24819568]\n",
            " [  0.79733344  10.97106464]\n",
            " [ -4.28661859  10.13039491]]\n",
            "[[1.]\n",
            " [1.]\n",
            " [0.]\n",
            " ...\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFKCAYAAADMuCxnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmUAgEAiECOD/A2b13tEBJH/qAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "jejegzbaxmRW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 41572
        },
        "outputId": "4f4f7094-371c-4c23-e69c-e1d5d67b7d80"
      },
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "# (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "# x_train = np.reshape(x_train, [x_train.shape[0], -1])\n",
        "# x_test = np.reshape(x_test, [x_test.shape[0], -1])\n",
        "# y_train = np.reshape(y_train, [y_train.shape[0], -1])\n",
        "# y_test = np.reshape(y_test, [y_test.shape[0], -1])\n",
        "\n",
        "#construct dataset\n",
        "features = tf.placeholder(tf.float32, shape=[None, IMG_ROWS * IMG_COLS])\n",
        "labels = tf.placeholder(tf.int32, shape=[None, 1])\n",
        "batch_size = tf.placeholder(tf.int64)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels)).batch(batch_size).repeat()\n",
        "iter = dataset.make_initializable_iterator()\n",
        "x, y_ = iter.get_next()\n",
        "y = tf.one_hot(tf.reshape(y_,[-1]), NUM_LABEL)\n",
        "\n",
        "# print(x)\n",
        "# print(y_)\n",
        "# print(y)\n",
        "# print(y_train)\n",
        "# print(y_train.shape)\n",
        "# print(x_train.shape)\n",
        "# xavier_initializer = tf.contrib.layers.xavier_initializer()\n",
        "\n",
        "def layer(input, num_units):\n",
        "  W = tf.Variable(tf.zeros([input.shape[1], num_units], tf.float32), name=\"w\")\n",
        "  B = tf.Variable(tf.zeros([num_units], tf.float32), name=\"b\")\n",
        "  output = tf.matmul(input,W)+B\n",
        "  return W, B, output\n",
        "\n",
        "def lrelu(x, alpha):\n",
        "  return tf.nn.relu(x) - alpha * tf.nn.relu(-x)\n",
        "\n",
        "def inverter(y, model_weights):\n",
        "  # Input layer\n",
        "  ww = tf.matmul(model_weights, inv_weights['w_model'])\n",
        "  wy = tf.matmul(y, inv_weights['w_label'])\n",
        "  wt = tf.add(wy, ww)\n",
        "  hidden_layer =  tf.add(wt, inv_weights['b_in'])\n",
        "  rect = lrelu(hidden_layer, 0.3)\n",
        "  # Output Layer\n",
        "  out_layer = tf.add(tf.matmul(rect, inv_weights['w_out']), inv_weights['b_out'])\n",
        "  rect = lrelu(out_layer, 0.3)\n",
        "  return tf.tanh(rect)\n",
        "\n",
        "#Build Logistic Layer\n",
        "with tf.name_scope(\"logistic_layer\"):\n",
        "#   w,b,z = layer(x,NUM_LABEL)\n",
        "  w = tf.Variable(tf.zeros([x.shape[1], NUM_LABEL], tf.float32), name=\"w\")\n",
        "  b = tf.Variable(tf.zeros([NUM_LABEL], tf.float32), name=\"b\")\n",
        "  y_ml = tf.nn.softmax(tf.matmul(x,w)+b)\n",
        "\n",
        "#Build Inverter Regularizer\n",
        "model_weights = tf.concat([tf.reshape(w,[1, -1]),tf.reshape(b,[1, -1])], 1)\n",
        "# print(model_weights)\n",
        "inv_weights = {\n",
        "  'w_model': tf.Variable(tf.zeros([tf.reshape(model_weights, [-1]).shape[0], INV_HIDDEN])),\n",
        "  'w_label': tf.Variable(tf.zeros([NUM_LABEL, INV_HIDDEN])),\n",
        "  'w_out': tf.Variable(tf.zeros([INV_HIDDEN, IMG_ROWS * IMG_COLS])),\n",
        "  'b_in': tf.Variable(tf.zeros([INV_HIDDEN])),\n",
        "  'b_out': tf.Variable(tf.zeros([IMG_ROWS * IMG_COLS]))\n",
        "}\n",
        "\n",
        "inv_x = inverter(y, model_weights)\n",
        "# print(inv_x)\n",
        "# Calculate loss\n",
        "class_loss = tf.losses.softmax_cross_entropy(y,y_ml)\n",
        "inv_loss = tf.losses.mean_squared_error(labels=x, predictions=inv_x)\n",
        "# calculate prediction accuracy\n",
        "correct = tf.equal(tf.argmax(y_ml, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "def train(loss_beta, learning_rate, Epoch):\n",
        "  total_loss = class_loss - loss_beta * inv_loss\n",
        "  model_optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(total_loss, var_list=[w,b])\n",
        "  inverter_optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(inv_loss, var_list=[inv_weights])\n",
        "  init_vars = tf.global_variables_initializer()\n",
        "  \n",
        "  with tf.Session() as sess:\n",
        "    sess.run(init_vars)\n",
        "   \n",
        "    # initialise iterator with train data\n",
        "    sess.run(iter.initializer, feed_dict = {features: x_train, labels: y_train, batch_size: 100})\n",
        "    \n",
        "    print('Training...')\n",
        "    for i in range(Epoch):\n",
        "      sess.run(model_optimizer)\n",
        "      sess.run(inverter_optimizer)\n",
        "      train_acc = sess.run(accuracy)\n",
        "      train_total_loss = sess.run(total_loss)\n",
        "      train_inv_loss = sess.run(inv_loss)\n",
        "      train_class_loss = sess.run(class_loss)\n",
        "      print(\"step %g train accuracy is %g, total_loss is %g, inv_loss is %g, class_loss is %g\"%(i, train_acc,train_total_loss, train_inv_loss, train_class_loss))\n",
        "    # initialise iterator with test data\n",
        "    sess.run(iter.initializer, feed_dict = {features: x_train, labels: y_train, batch_size: y_train.shape[0]})\n",
        "    test_acc = sess.run(accuracy)\n",
        "    print(\"beta is %g, test accuracy is %g\"%(beta, test_acc))\n",
        "      \n",
        "    return test_acc\n",
        "\n",
        "betas = [0.0, 0.001, 0.01, 0.1, 0.5, 1., 2., 5., 7., 10., 15., 20.]\n",
        "test_accs = np.zeros(len(betas))\n",
        "for i,beta in enumerate(betas):\n",
        "  test_accs[i] = train(beta,0.01,200)\n",
        "\n",
        "np.save(\"logreg_acc\", test_accs)\n",
        "plt.plot(betas, test_accs)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "step 0 train accuracy is 0.99, total_loss is 0.525347, inv_loss is 123.671, class_loss is 0.524549\n",
            "step 1 train accuracy is 1, total_loss is 0.459239, inv_loss is 102.835, class_loss is 0.447879\n",
            "step 2 train accuracy is 0.98, total_loss is 0.419309, inv_loss is 115.876, class_loss is 0.424172\n",
            "step 3 train accuracy is 1, total_loss is 0.387407, inv_loss is 118.258, class_loss is 0.398682\n",
            "step 4 train accuracy is 1, total_loss is 0.392796, inv_loss is 107.837, class_loss is 0.39172\n",
            "step 5 train accuracy is 1, total_loss is 0.373339, inv_loss is 111.076, class_loss is 0.370208\n",
            "step 6 train accuracy is 1, total_loss is 0.373689, inv_loss is 117.912, class_loss is 0.37163\n",
            "step 7 train accuracy is 1, total_loss is 0.367764, inv_loss is 116.513, class_loss is 0.365356\n",
            "step 8 train accuracy is 0.99, total_loss is 0.355723, inv_loss is 112.632, class_loss is 0.360448\n",
            "step 9 train accuracy is 1, total_loss is 0.355943, inv_loss is 111.392, class_loss is 0.35926\n",
            "step 10 train accuracy is 1, total_loss is 0.357323, inv_loss is 102.722, class_loss is 0.353192\n",
            "step 11 train accuracy is 0.99, total_loss is 0.356668, inv_loss is 107.241, class_loss is 0.341093\n",
            "step 12 train accuracy is 1, total_loss is 0.342501, inv_loss is 104.536, class_loss is 0.352631\n",
            "step 13 train accuracy is 1, total_loss is 0.342363, inv_loss is 113.849, class_loss is 0.342696\n",
            "step 14 train accuracy is 1, total_loss is 0.345738, inv_loss is 115.728, class_loss is 0.348495\n",
            "step 15 train accuracy is 1, total_loss is 0.336106, inv_loss is 114.343, class_loss is 0.344838\n",
            "step 16 train accuracy is 1, total_loss is 0.342363, inv_loss is 114.652, class_loss is 0.338635\n",
            "step 17 train accuracy is 1, total_loss is 0.33916, inv_loss is 106.647, class_loss is 0.339774\n",
            "step 18 train accuracy is 1, total_loss is 0.336142, inv_loss is 118.665, class_loss is 0.342162\n",
            "step 19 train accuracy is 1, total_loss is 0.337885, inv_loss is 114.43, class_loss is 0.34367\n",
            "step 20 train accuracy is 0.99, total_loss is 0.335067, inv_loss is 122.334, class_loss is 0.332545\n",
            "step 21 train accuracy is 1, total_loss is 0.341239, inv_loss is 112.895, class_loss is 0.332893\n",
            "step 22 train accuracy is 1, total_loss is 0.331913, inv_loss is 118.506, class_loss is 0.336813\n",
            "step 23 train accuracy is 1, total_loss is 0.335969, inv_loss is 120.538, class_loss is 0.328996\n",
            "step 24 train accuracy is 1, total_loss is 0.333998, inv_loss is 110.465, class_loss is 0.334211\n",
            "step 25 train accuracy is 1, total_loss is 0.334521, inv_loss is 123.671, class_loss is 0.332229\n",
            "step 26 train accuracy is 1, total_loss is 0.334539, inv_loss is 102.835, class_loss is 0.330224\n",
            "step 27 train accuracy is 0.99, total_loss is 0.332965, inv_loss is 115.876, class_loss is 0.331726\n",
            "step 28 train accuracy is 1, total_loss is 0.325546, inv_loss is 118.258, class_loss is 0.329841\n",
            "step 29 train accuracy is 1, total_loss is 0.33429, inv_loss is 107.837, class_loss is 0.336136\n",
            "step 30 train accuracy is 1, total_loss is 0.327679, inv_loss is 111.076, class_loss is 0.327828\n",
            "step 31 train accuracy is 1, total_loss is 0.333691, inv_loss is 117.912, class_loss is 0.331359\n",
            "step 32 train accuracy is 1, total_loss is 0.33064, inv_loss is 116.513, class_loss is 0.329637\n",
            "step 33 train accuracy is 1, total_loss is 0.327269, inv_loss is 112.632, class_loss is 0.330447\n",
            "step 34 train accuracy is 1, total_loss is 0.328278, inv_loss is 111.392, class_loss is 0.330573\n",
            "step 35 train accuracy is 1, total_loss is 0.330299, inv_loss is 102.722, class_loss is 0.329552\n",
            "step 36 train accuracy is 0.99, total_loss is 0.332777, inv_loss is 107.241, class_loss is 0.32295\n",
            "step 37 train accuracy is 1, total_loss is 0.324775, inv_loss is 104.536, class_loss is 0.330812\n",
            "step 38 train accuracy is 1, total_loss is 0.324936, inv_loss is 113.849, class_loss is 0.324953\n",
            "step 39 train accuracy is 1, total_loss is 0.329107, inv_loss is 115.728, class_loss is 0.330805\n",
            "step 40 train accuracy is 1, total_loss is 0.3229, inv_loss is 114.343, class_loss is 0.327855\n",
            "step 41 train accuracy is 1, total_loss is 0.326811, inv_loss is 114.652, class_loss is 0.325086\n",
            "step 42 train accuracy is 1, total_loss is 0.325637, inv_loss is 106.647, class_loss is 0.325915\n",
            "step 43 train accuracy is 1, total_loss is 0.324431, inv_loss is 118.665, class_loss is 0.327775\n",
            "step 44 train accuracy is 1, total_loss is 0.325612, inv_loss is 114.43, class_loss is 0.330256\n",
            "step 45 train accuracy is 1, total_loss is 0.324462, inv_loss is 122.334, class_loss is 0.323067\n",
            "step 46 train accuracy is 1, total_loss is 0.33066, inv_loss is 112.895, class_loss is 0.323127\n",
            "step 47 train accuracy is 1, total_loss is 0.323567, inv_loss is 118.506, class_loss is 0.327284\n",
            "step 48 train accuracy is 1, total_loss is 0.326325, inv_loss is 120.538, class_loss is 0.321427\n",
            "step 49 train accuracy is 1, total_loss is 0.324742, inv_loss is 110.465, class_loss is 0.324955\n",
            "step 50 train accuracy is 1, total_loss is 0.326057, inv_loss is 123.671, class_loss is 0.323971\n",
            "step 51 train accuracy is 1, total_loss is 0.326101, inv_loss is 102.835, class_loss is 0.322941\n",
            "step 52 train accuracy is 1, total_loss is 0.32566, inv_loss is 115.876, class_loss is 0.324053\n",
            "step 53 train accuracy is 1, total_loss is 0.320092, inv_loss is 118.258, class_loss is 0.323108\n",
            "step 54 train accuracy is 1, total_loss is 0.326572, inv_loss is 107.837, class_loss is 0.329179\n",
            "step 55 train accuracy is 1, total_loss is 0.321613, inv_loss is 111.076, class_loss is 0.322413\n",
            "step 56 train accuracy is 1, total_loss is 0.326908, inv_loss is 117.912, class_loss is 0.324881\n",
            "step 57 train accuracy is 1, total_loss is 0.324217, inv_loss is 116.513, class_loss is 0.323336\n",
            "step 58 train accuracy is 1, total_loss is 0.322065, inv_loss is 112.632, class_loss is 0.324661\n",
            "step 59 train accuracy is 1, total_loss is 0.322728, inv_loss is 111.392, class_loss is 0.324737\n",
            "step 60 train accuracy is 1, total_loss is 0.324323, inv_loss is 102.722, class_loss is 0.324469\n",
            "step 61 train accuracy is 0.99, total_loss is 0.326782, inv_loss is 107.241, class_loss is 0.319218\n",
            "step 62 train accuracy is 1, total_loss is 0.320804, inv_loss is 104.536, class_loss is 0.325261\n",
            "step 63 train accuracy is 1, total_loss is 0.320689, inv_loss is 113.849, class_loss is 0.320633\n",
            "step 64 train accuracy is 1, total_loss is 0.324805, inv_loss is 115.728, class_loss is 0.325769\n",
            "step 65 train accuracy is 1, total_loss is 0.319479, inv_loss is 114.343, class_loss is 0.323155\n",
            "step 66 train accuracy is 1, total_loss is 0.322435, inv_loss is 114.652, class_loss is 0.321218\n",
            "step 67 train accuracy is 1, total_loss is 0.321666, inv_loss is 106.647, class_loss is 0.321795\n",
            "step 68 train accuracy is 1, total_loss is 0.32083, inv_loss is 118.665, class_loss is 0.323282\n",
            "step 69 train accuracy is 1, total_loss is 0.321827, inv_loss is 114.43, class_loss is 0.325645\n",
            "step 70 train accuracy is 1, total_loss is 0.321119, inv_loss is 122.334, class_loss is 0.320114\n",
            "step 71 train accuracy is 1, total_loss is 0.326968, inv_loss is 112.895, class_loss is 0.319928\n",
            "step 72 train accuracy is 1, total_loss is 0.320776, inv_loss is 118.506, class_loss is 0.324025\n",
            "step 73 train accuracy is 1, total_loss is 0.322824, inv_loss is 120.538, class_loss is 0.318852\n",
            "step 74 train accuracy is 1, total_loss is 0.321311, inv_loss is 110.465, class_loss is 0.321627\n",
            "step 75 train accuracy is 1, total_loss is 0.32278, inv_loss is 123.671, class_loss is 0.32092\n",
            "step 76 train accuracy is 1, total_loss is 0.322844, inv_loss is 102.835, class_loss is 0.32015\n",
            "step 77 train accuracy is 1, total_loss is 0.322768, inv_loss is 115.876, class_loss is 0.321124\n",
            "step 78 train accuracy is 1, total_loss is 0.31805, inv_loss is 118.258, class_loss is 0.320513\n",
            "step 79 train accuracy is 1, total_loss is 0.323302, inv_loss is 107.837, class_loss is 0.326247\n",
            "step 80 train accuracy is 1, total_loss is 0.319164, inv_loss is 111.076, class_loss is 0.320234\n",
            "step 81 train accuracy is 1, total_loss is 0.323885, inv_loss is 117.912, class_loss is 0.322109\n",
            "step 82 train accuracy is 1, total_loss is 0.321475, inv_loss is 116.513, class_loss is 0.320609\n",
            "step 83 train accuracy is 1, total_loss is 0.319791, inv_loss is 112.632, class_loss is 0.322054\n",
            "step 84 train accuracy is 1, total_loss is 0.320284, inv_loss is 111.392, class_loss is 0.322137\n",
            "step 85 train accuracy is 1, total_loss is 0.321618, inv_loss is 102.722, class_loss is 0.322152\n",
            "step 86 train accuracy is 1, total_loss is 0.323879, inv_loss is 107.241, class_loss is 0.317608\n",
            "step 87 train accuracy is 1, total_loss is 0.31903, inv_loss is 104.536, class_loss is 0.3226\n",
            "step 88 train accuracy is 1, total_loss is 0.318744, inv_loss is 113.849, class_loss is 0.318659\n",
            "step 89 train accuracy is 1, total_loss is 0.32278, inv_loss is 115.728, class_loss is 0.323261\n",
            "step 90 train accuracy is 1, total_loss is 0.31789, inv_loss is 114.343, class_loss is 0.320913\n",
            "step 91 train accuracy is 1, total_loss is 0.320345, inv_loss is 114.652, class_loss is 0.319337\n",
            "step 92 train accuracy is 1, total_loss is 0.319737, inv_loss is 106.647, class_loss is 0.319785\n",
            "step 93 train accuracy is 1, total_loss is 0.31904, inv_loss is 118.665, class_loss is 0.321046\n",
            "step 94 train accuracy is 1, total_loss is 0.319962, inv_loss is 114.43, class_loss is 0.323208\n",
            "step 95 train accuracy is 1, total_loss is 0.319472, inv_loss is 122.334, class_loss is 0.318658\n",
            "step 96 train accuracy is 1, total_loss is 0.32501, inv_loss is 112.895, class_loss is 0.318324\n",
            "step 97 train accuracy is 1, total_loss is 0.319362, inv_loss is 118.506, class_loss is 0.322345\n",
            "step 98 train accuracy is 1, total_loss is 0.320976, inv_loss is 120.538, class_loss is 0.317542\n",
            "step 99 train accuracy is 1, total_loss is 0.319492, inv_loss is 110.465, class_loss is 0.319897\n",
            "step 100 train accuracy is 1, total_loss is 0.320988, inv_loss is 123.671, class_loss is 0.319312\n",
            "step 101 train accuracy is 1, total_loss is 0.321087, inv_loss is 102.835, class_loss is 0.318649\n",
            "step 102 train accuracy is 1, total_loss is 0.321176, inv_loss is 115.876, class_loss is 0.319562\n",
            "step 103 train accuracy is 1, total_loss is 0.316982, inv_loss is 118.258, class_loss is 0.319133\n",
            "step 104 train accuracy is 1, total_loss is 0.321448, inv_loss is 107.837, class_loss is 0.324575\n",
            "step 105 train accuracy is 1, total_loss is 0.317832, inv_loss is 111.076, class_loss is 0.319046\n",
            "step 106 train accuracy is 1, total_loss is 0.322122, inv_loss is 117.912, class_loss is 0.320545\n",
            "step 107 train accuracy is 1, total_loss is 0.319941, inv_loss is 116.513, class_loss is 0.319069\n",
            "step 108 train accuracy is 1, total_loss is 0.318494, inv_loss is 112.632, class_loss is 0.320533\n",
            "step 109 train accuracy is 1, total_loss is 0.318897, inv_loss is 111.392, class_loss is 0.320645\n",
            "step 110 train accuracy is 1, total_loss is 0.320059, inv_loss is 102.722, class_loss is 0.320794\n",
            "step 111 train accuracy is 1, total_loss is 0.322121, inv_loss is 107.241, class_loss is 0.316712\n",
            "step 112 train accuracy is 1, total_loss is 0.318017, inv_loss is 104.536, class_loss is 0.321005\n",
            "step 113 train accuracy is 1, total_loss is 0.317622, inv_loss is 113.849, class_loss is 0.317523\n",
            "step 114 train accuracy is 1, total_loss is 0.321584, inv_loss is 115.728, class_loss is 0.321723\n",
            "step 115 train accuracy is 1, total_loss is 0.316966, inv_loss is 114.343, class_loss is 0.319591\n",
            "step 116 train accuracy is 1, total_loss is 0.319114, inv_loss is 114.652, class_loss is 0.318209\n",
            "step 117 train accuracy is 1, total_loss is 0.318587, inv_loss is 106.647, class_loss is 0.318586\n",
            "step 118 train accuracy is 1, total_loss is 0.317958, inv_loss is 118.665, class_loss is 0.319696\n",
            "step 119 train accuracy is 1, total_loss is 0.318844, inv_loss is 114.43, class_loss is 0.321669\n",
            "step 120 train accuracy is 1, total_loss is 0.318491, inv_loss is 122.334, class_loss is 0.317786\n",
            "step 121 train accuracy is 1, total_loss is 0.323766, inv_loss is 112.895, class_loss is 0.317355\n",
            "step 122 train accuracy is 1, total_loss is 0.318502, inv_loss is 118.506, class_loss is 0.321306\n",
            "step 123 train accuracy is 1, total_loss is 0.319821, inv_loss is 120.538, class_loss is 0.316745\n",
            "step 124 train accuracy is 1, total_loss is 0.318358, inv_loss is 110.465, class_loss is 0.318831\n",
            "step 125 train accuracy is 1, total_loss is 0.319839, inv_loss is 123.671, class_loss is 0.318312\n",
            "step 126 train accuracy is 1, total_loss is 0.319977, inv_loss is 102.835, class_loss is 0.317703\n",
            "step 127 train accuracy is 1, total_loss is 0.320151, inv_loss is 115.876, class_loss is 0.318584\n",
            "step 128 train accuracy is 1, total_loss is 0.316326, inv_loss is 118.258, class_loss is 0.318277\n",
            "step 129 train accuracy is 1, total_loss is 0.320236, inv_loss is 107.837, class_loss is 0.323471\n",
            "step 130 train accuracy is 1, total_loss is 0.316992, inv_loss is 111.076, class_loss is 0.318293\n",
            "step 131 train accuracy is 1, total_loss is 0.320948, inv_loss is 117.912, class_loss is 0.319531\n",
            "step 132 train accuracy is 1, total_loss is 0.318956, inv_loss is 116.513, class_loss is 0.318073\n",
            "step 133 train accuracy is 1, total_loss is 0.317649, inv_loss is 112.632, class_loss is 0.319523\n",
            "step 134 train accuracy is 1, total_loss is 0.317998, inv_loss is 111.392, class_loss is 0.319669\n",
            "step 135 train accuracy is 1, total_loss is 0.319039, inv_loss is 102.722, class_loss is 0.319889\n",
            "step 136 train accuracy is 1, total_loss is 0.320926, inv_loss is 107.241, class_loss is 0.316142\n",
            "step 137 train accuracy is 1, total_loss is 0.317359, inv_loss is 104.536, class_loss is 0.319929\n",
            "step 138 train accuracy is 1, total_loss is 0.31689, inv_loss is 113.849, class_loss is 0.316783\n",
            "step 139 train accuracy is 1, total_loss is 0.320785, inv_loss is 115.728, class_loss is 0.320669\n",
            "step 140 train accuracy is 1, total_loss is 0.31636, inv_loss is 114.343, class_loss is 0.318716\n",
            "step 141 train accuracy is 1, total_loss is 0.3183, inv_loss is 114.652, class_loss is 0.317453\n",
            "step 142 train accuracy is 1, total_loss is 0.317819, inv_loss is 106.647, class_loss is 0.317787\n",
            "step 143 train accuracy is 1, total_loss is 0.317229, inv_loss is 118.665, class_loss is 0.318788\n",
            "step 144 train accuracy is 1, total_loss is 0.318094, inv_loss is 114.43, class_loss is 0.320596\n",
            "step 145 train accuracy is 1, total_loss is 0.31784, inv_loss is 122.334, class_loss is 0.317202\n",
            "step 146 train accuracy is 1, total_loss is 0.322892, inv_loss is 112.895, class_loss is 0.316705\n",
            "step 147 train accuracy is 1, total_loss is 0.31792, inv_loss is 118.506, class_loss is 0.320593\n",
            "step 148 train accuracy is 1, total_loss is 0.319026, inv_loss is 120.538, class_loss is 0.316207\n",
            "step 149 train accuracy is 1, total_loss is 0.317579, inv_loss is 110.465, class_loss is 0.318107\n",
            "step 150 train accuracy is 1, total_loss is 0.319032, inv_loss is 123.671, class_loss is 0.317626\n",
            "step 151 train accuracy is 1, total_loss is 0.319208, inv_loss is 102.835, class_loss is 0.317049\n",
            "step 152 train accuracy is 1, total_loss is 0.319427, inv_loss is 115.876, class_loss is 0.317912\n",
            "step 153 train accuracy is 1, total_loss is 0.315882, inv_loss is 118.258, class_loss is 0.317693\n",
            "step 154 train accuracy is 1, total_loss is 0.319374, inv_loss is 107.837, class_loss is 0.322676\n",
            "step 155 train accuracy is 1, total_loss is 0.316413, inv_loss is 111.076, class_loss is 0.317771\n",
            "step 156 train accuracy is 1, total_loss is 0.320102, inv_loss is 117.912, class_loss is 0.318816\n",
            "step 157 train accuracy is 1, total_loss is 0.318268, inv_loss is 116.513, class_loss is 0.317373\n",
            "step 158 train accuracy is 1, total_loss is 0.317051, inv_loss is 112.632, class_loss is 0.318797\n",
            "step 159 train accuracy is 1, total_loss is 0.317367, inv_loss is 111.392, class_loss is 0.318977\n",
            "step 160 train accuracy is 1, total_loss is 0.318318, inv_loss is 102.722, class_loss is 0.319235\n",
            "step 161 train accuracy is 1, total_loss is 0.320053, inv_loss is 107.241, class_loss is 0.315747\n",
            "step 162 train accuracy is 1, total_loss is 0.316895, inv_loss is 104.536, class_loss is 0.319147\n",
            "step 163 train accuracy is 1, total_loss is 0.316373, inv_loss is 113.849, class_loss is 0.316262\n",
            "step 164 train accuracy is 1, total_loss is 0.320209, inv_loss is 115.728, class_loss is 0.319894\n",
            "step 165 train accuracy is 1, total_loss is 0.31593, inv_loss is 114.343, class_loss is 0.318093\n",
            "step 166 train accuracy is 1, total_loss is 0.31772, inv_loss is 114.652, class_loss is 0.316907\n",
            "step 167 train accuracy is 1, total_loss is 0.317268, inv_loss is 106.647, class_loss is 0.317214\n",
            "step 168 train accuracy is 1, total_loss is 0.316702, inv_loss is 118.665, class_loss is 0.318134\n",
            "step 169 train accuracy is 1, total_loss is 0.317554, inv_loss is 114.43, class_loss is 0.319798\n",
            "step 170 train accuracy is 1, total_loss is 0.317375, inv_loss is 122.334, class_loss is 0.316782\n",
            "step 171 train accuracy is 1, total_loss is 0.322236, inv_loss is 112.895, class_loss is 0.316237\n",
            "step 172 train accuracy is 1, total_loss is 0.317498, inv_loss is 118.506, class_loss is 0.320068\n",
            "step 173 train accuracy is 1, total_loss is 0.318441, inv_loss is 120.538, class_loss is 0.315819\n",
            "step 174 train accuracy is 1, total_loss is 0.31701, inv_loss is 110.465, class_loss is 0.31758\n",
            "step 175 train accuracy is 1, total_loss is 0.318429, inv_loss is 123.671, class_loss is 0.317125\n",
            "step 176 train accuracy is 1, total_loss is 0.31864, inv_loss is 102.835, class_loss is 0.316568\n",
            "step 177 train accuracy is 1, total_loss is 0.318884, inv_loss is 115.876, class_loss is 0.317418\n",
            "step 178 train accuracy is 1, total_loss is 0.315562, inv_loss is 118.258, class_loss is 0.31727\n",
            "step 179 train accuracy is 1, total_loss is 0.318725, inv_loss is 107.837, class_loss is 0.32207\n",
            "step 180 train accuracy is 1, total_loss is 0.315989, inv_loss is 111.076, class_loss is 0.317386\n",
            "step 181 train accuracy is 1, total_loss is 0.319458, inv_loss is 117.912, class_loss is 0.318281\n",
            "step 182 train accuracy is 1, total_loss is 0.31776, inv_loss is 116.513, class_loss is 0.316854\n",
            "step 183 train accuracy is 1, total_loss is 0.316604, inv_loss is 112.632, class_loss is 0.318247\n",
            "step 184 train accuracy is 1, total_loss is 0.316899, inv_loss is 111.392, class_loss is 0.318458\n",
            "step 185 train accuracy is 1, total_loss is 0.317779, inv_loss is 102.722, class_loss is 0.318737\n",
            "step 186 train accuracy is 1, total_loss is 0.319382, inv_loss is 107.241, class_loss is 0.315457\n",
            "step 187 train accuracy is 1, total_loss is 0.316549, inv_loss is 104.536, class_loss is 0.31855\n",
            "step 188 train accuracy is 1, total_loss is 0.315989, inv_loss is 113.849, class_loss is 0.315875\n",
            "step 189 train accuracy is 1, total_loss is 0.319771, inv_loss is 115.728, class_loss is 0.319296\n",
            "step 190 train accuracy is 1, total_loss is 0.315609, inv_loss is 114.343, class_loss is 0.317625\n",
            "step 191 train accuracy is 1, total_loss is 0.317284, inv_loss is 114.652, class_loss is 0.316493\n",
            "step 192 train accuracy is 1, total_loss is 0.316851, inv_loss is 106.647, class_loss is 0.316783\n",
            "step 193 train accuracy is 1, total_loss is 0.316302, inv_loss is 118.665, class_loss is 0.317639\n",
            "step 194 train accuracy is 1, total_loss is 0.317144, inv_loss is 114.43, class_loss is 0.319178\n",
            "step 195 train accuracy is 1, total_loss is 0.317028, inv_loss is 122.334, class_loss is 0.316464\n",
            "step 196 train accuracy is 1, total_loss is 0.32172, inv_loss is 112.895, class_loss is 0.315884\n",
            "step 197 train accuracy is 1, total_loss is 0.317178, inv_loss is 118.506, class_loss is 0.319663\n",
            "step 198 train accuracy is 1, total_loss is 0.317991, inv_loss is 120.538, class_loss is 0.315524\n",
            "step 199 train accuracy is 1, total_loss is 0.316575, inv_loss is 110.465, class_loss is 0.31718\n",
            "beta is 0, test accuracy is 1\n",
            "Training...\n",
            "step 0 train accuracy is 0.99, total_loss is 0.413387, inv_loss is 123.671, class_loss is 0.524549\n",
            "step 1 train accuracy is 1, total_loss is 0.345995, inv_loss is 102.835, class_loss is 0.447879\n",
            "step 2 train accuracy is 0.98, total_loss is 0.297853, inv_loss is 115.876, class_loss is 0.424172\n",
            "step 3 train accuracy is 1, total_loss is 0.26628, inv_loss is 118.258, class_loss is 0.398682\n",
            "step 4 train accuracy is 1, total_loss is 0.280332, inv_loss is 107.837, class_loss is 0.39172\n",
            "step 5 train accuracy is 1, total_loss is 0.257024, inv_loss is 111.076, class_loss is 0.370208\n",
            "step 6 train accuracy is 1, total_loss is 0.258022, inv_loss is 117.912, class_loss is 0.37163\n",
            "step 7 train accuracy is 1, total_loss is 0.254182, inv_loss is 116.513, class_loss is 0.365356\n",
            "step 8 train accuracy is 0.99, total_loss is 0.238038, inv_loss is 112.632, class_loss is 0.360448\n",
            "step 9 train accuracy is 1, total_loss is 0.237999, inv_loss is 111.392, class_loss is 0.35926\n",
            "step 10 train accuracy is 1, total_loss is 0.245796, inv_loss is 102.722, class_loss is 0.353192\n",
            "step 11 train accuracy is 0.99, total_loss is 0.256091, inv_loss is 107.241, class_loss is 0.341093\n",
            "step 12 train accuracy is 1, total_loss is 0.230772, inv_loss is 104.536, class_loss is 0.352631\n",
            "step 13 train accuracy is 1, total_loss is 0.227595, inv_loss is 113.849, class_loss is 0.342696\n",
            "step 14 train accuracy is 1, total_loss is 0.232853, inv_loss is 115.728, class_loss is 0.348495\n",
            "step 15 train accuracy is 1, total_loss is 0.21882, inv_loss is 114.343, class_loss is 0.344838\n",
            "step 16 train accuracy is 1, total_loss is 0.234082, inv_loss is 114.652, class_loss is 0.338635\n",
            "step 17 train accuracy is 1, total_loss is 0.221753, inv_loss is 106.647, class_loss is 0.339774\n",
            "step 18 train accuracy is 1, total_loss is 0.225376, inv_loss is 118.665, class_loss is 0.342162\n",
            "step 19 train accuracy is 1, total_loss is 0.237279, inv_loss is 114.43, class_loss is 0.34367\n",
            "step 20 train accuracy is 0.99, total_loss is 0.223841, inv_loss is 122.334, class_loss is 0.332545\n",
            "step 21 train accuracy is 1, total_loss is 0.231469, inv_loss is 112.895, class_loss is 0.332893\n",
            "step 22 train accuracy is 1, total_loss is 0.21441, inv_loss is 118.506, class_loss is 0.336813\n",
            "step 23 train accuracy is 1, total_loss is 0.21736, inv_loss is 120.538, class_loss is 0.328996\n",
            "step 24 train accuracy is 1, total_loss is 0.223165, inv_loss is 110.465, class_loss is 0.334211\n",
            "step 25 train accuracy is 1, total_loss is 0.222561, inv_loss is 123.671, class_loss is 0.332229\n",
            "step 26 train accuracy is 1, total_loss is 0.221295, inv_loss is 102.835, class_loss is 0.330224\n",
            "step 27 train accuracy is 0.99, total_loss is 0.211509, inv_loss is 115.876, class_loss is 0.331726\n",
            "step 28 train accuracy is 1, total_loss is 0.204419, inv_loss is 118.258, class_loss is 0.329841\n",
            "step 29 train accuracy is 1, total_loss is 0.221826, inv_loss is 107.837, class_loss is 0.336136\n",
            "step 30 train accuracy is 1, total_loss is 0.211364, inv_loss is 111.076, class_loss is 0.327828\n",
            "step 31 train accuracy is 1, total_loss is 0.218024, inv_loss is 117.912, class_loss is 0.331359\n",
            "step 32 train accuracy is 1, total_loss is 0.217057, inv_loss is 116.513, class_loss is 0.329637\n",
            "step 33 train accuracy is 1, total_loss is 0.209584, inv_loss is 112.632, class_loss is 0.330447\n",
            "step 34 train accuracy is 1, total_loss is 0.210334, inv_loss is 111.392, class_loss is 0.330573\n",
            "step 35 train accuracy is 1, total_loss is 0.218772, inv_loss is 102.722, class_loss is 0.329552\n",
            "step 36 train accuracy is 0.99, total_loss is 0.2322, inv_loss is 107.241, class_loss is 0.32295\n",
            "step 37 train accuracy is 1, total_loss is 0.213047, inv_loss is 104.536, class_loss is 0.330812\n",
            "step 38 train accuracy is 1, total_loss is 0.210168, inv_loss is 113.849, class_loss is 0.324953\n",
            "step 39 train accuracy is 1, total_loss is 0.216221, inv_loss is 115.728, class_loss is 0.330805\n",
            "step 40 train accuracy is 1, total_loss is 0.205613, inv_loss is 114.343, class_loss is 0.327855\n",
            "step 41 train accuracy is 1, total_loss is 0.218531, inv_loss is 114.652, class_loss is 0.325086\n",
            "step 42 train accuracy is 1, total_loss is 0.20823, inv_loss is 106.647, class_loss is 0.325915\n",
            "step 43 train accuracy is 1, total_loss is 0.213666, inv_loss is 118.665, class_loss is 0.327775\n",
            "step 44 train accuracy is 1, total_loss is 0.225007, inv_loss is 114.43, class_loss is 0.330256\n",
            "step 45 train accuracy is 1, total_loss is 0.213236, inv_loss is 122.334, class_loss is 0.323067\n",
            "step 46 train accuracy is 1, total_loss is 0.220889, inv_loss is 112.895, class_loss is 0.323127\n",
            "step 47 train accuracy is 1, total_loss is 0.206063, inv_loss is 118.506, class_loss is 0.327284\n",
            "step 48 train accuracy is 1, total_loss is 0.207717, inv_loss is 120.538, class_loss is 0.321427\n",
            "step 49 train accuracy is 1, total_loss is 0.213909, inv_loss is 110.465, class_loss is 0.324955\n",
            "step 50 train accuracy is 1, total_loss is 0.214097, inv_loss is 123.671, class_loss is 0.323971\n",
            "step 51 train accuracy is 1, total_loss is 0.212857, inv_loss is 102.835, class_loss is 0.322941\n",
            "step 52 train accuracy is 1, total_loss is 0.204204, inv_loss is 115.876, class_loss is 0.324053\n",
            "step 53 train accuracy is 1, total_loss is 0.198965, inv_loss is 118.258, class_loss is 0.323108\n",
            "step 54 train accuracy is 1, total_loss is 0.214108, inv_loss is 107.837, class_loss is 0.329179\n",
            "step 55 train accuracy is 1, total_loss is 0.205298, inv_loss is 111.076, class_loss is 0.322413\n",
            "step 56 train accuracy is 1, total_loss is 0.211241, inv_loss is 117.912, class_loss is 0.324881\n",
            "step 57 train accuracy is 1, total_loss is 0.210634, inv_loss is 116.513, class_loss is 0.323336\n",
            "step 58 train accuracy is 1, total_loss is 0.20438, inv_loss is 112.632, class_loss is 0.324661\n",
            "step 59 train accuracy is 1, total_loss is 0.204784, inv_loss is 111.392, class_loss is 0.324737\n",
            "step 60 train accuracy is 1, total_loss is 0.212796, inv_loss is 102.722, class_loss is 0.324469\n",
            "step 61 train accuracy is 0.99, total_loss is 0.226205, inv_loss is 107.241, class_loss is 0.319218\n",
            "step 62 train accuracy is 1, total_loss is 0.209076, inv_loss is 104.536, class_loss is 0.325261\n",
            "step 63 train accuracy is 1, total_loss is 0.205921, inv_loss is 113.849, class_loss is 0.320633\n",
            "step 64 train accuracy is 1, total_loss is 0.211919, inv_loss is 115.728, class_loss is 0.325769\n",
            "step 65 train accuracy is 1, total_loss is 0.202192, inv_loss is 114.343, class_loss is 0.323155\n",
            "step 66 train accuracy is 1, total_loss is 0.214154, inv_loss is 114.652, class_loss is 0.321218\n",
            "step 67 train accuracy is 1, total_loss is 0.204259, inv_loss is 106.647, class_loss is 0.321795\n",
            "step 68 train accuracy is 1, total_loss is 0.210064, inv_loss is 118.665, class_loss is 0.323282\n",
            "step 69 train accuracy is 1, total_loss is 0.221221, inv_loss is 114.43, class_loss is 0.325645\n",
            "step 70 train accuracy is 1, total_loss is 0.209893, inv_loss is 122.334, class_loss is 0.320114\n",
            "step 71 train accuracy is 1, total_loss is 0.217198, inv_loss is 112.895, class_loss is 0.319928\n",
            "step 72 train accuracy is 1, total_loss is 0.203272, inv_loss is 118.506, class_loss is 0.324025\n",
            "step 73 train accuracy is 1, total_loss is 0.204215, inv_loss is 120.538, class_loss is 0.318852\n",
            "step 74 train accuracy is 1, total_loss is 0.210477, inv_loss is 110.465, class_loss is 0.321627\n",
            "step 75 train accuracy is 1, total_loss is 0.21082, inv_loss is 123.671, class_loss is 0.32092\n",
            "step 76 train accuracy is 1, total_loss is 0.2096, inv_loss is 102.835, class_loss is 0.32015\n",
            "step 77 train accuracy is 1, total_loss is 0.201313, inv_loss is 115.876, class_loss is 0.321124\n",
            "step 78 train accuracy is 1, total_loss is 0.196923, inv_loss is 118.258, class_loss is 0.320513\n",
            "step 79 train accuracy is 1, total_loss is 0.210838, inv_loss is 107.837, class_loss is 0.326247\n",
            "step 80 train accuracy is 1, total_loss is 0.202849, inv_loss is 111.076, class_loss is 0.320234\n",
            "step 81 train accuracy is 1, total_loss is 0.208217, inv_loss is 117.912, class_loss is 0.322109\n",
            "step 82 train accuracy is 1, total_loss is 0.207893, inv_loss is 116.513, class_loss is 0.320609\n",
            "step 83 train accuracy is 1, total_loss is 0.202105, inv_loss is 112.632, class_loss is 0.322054\n",
            "step 84 train accuracy is 1, total_loss is 0.20234, inv_loss is 111.392, class_loss is 0.322137\n",
            "step 85 train accuracy is 1, total_loss is 0.210091, inv_loss is 102.722, class_loss is 0.322152\n",
            "step 86 train accuracy is 1, total_loss is 0.223301, inv_loss is 107.241, class_loss is 0.317608\n",
            "step 87 train accuracy is 1, total_loss is 0.207301, inv_loss is 104.536, class_loss is 0.3226\n",
            "step 88 train accuracy is 1, total_loss is 0.203976, inv_loss is 113.849, class_loss is 0.318659\n",
            "step 89 train accuracy is 1, total_loss is 0.209894, inv_loss is 115.728, class_loss is 0.323261\n",
            "step 90 train accuracy is 1, total_loss is 0.200603, inv_loss is 114.343, class_loss is 0.320913\n",
            "step 91 train accuracy is 1, total_loss is 0.212065, inv_loss is 114.652, class_loss is 0.319337\n",
            "step 92 train accuracy is 1, total_loss is 0.20233, inv_loss is 106.647, class_loss is 0.319785\n",
            "step 93 train accuracy is 1, total_loss is 0.208275, inv_loss is 118.665, class_loss is 0.321046\n",
            "step 94 train accuracy is 1, total_loss is 0.219357, inv_loss is 114.43, class_loss is 0.323208\n",
            "step 95 train accuracy is 1, total_loss is 0.208246, inv_loss is 122.334, class_loss is 0.318658\n",
            "step 96 train accuracy is 1, total_loss is 0.21524, inv_loss is 112.895, class_loss is 0.318324\n",
            "step 97 train accuracy is 1, total_loss is 0.201858, inv_loss is 118.506, class_loss is 0.322345\n",
            "step 98 train accuracy is 1, total_loss is 0.202367, inv_loss is 120.538, class_loss is 0.317542\n",
            "step 99 train accuracy is 1, total_loss is 0.208659, inv_loss is 110.465, class_loss is 0.319897\n",
            "step 100 train accuracy is 1, total_loss is 0.209027, inv_loss is 123.671, class_loss is 0.319312\n",
            "step 101 train accuracy is 1, total_loss is 0.207843, inv_loss is 102.835, class_loss is 0.318649\n",
            "step 102 train accuracy is 1, total_loss is 0.199721, inv_loss is 115.876, class_loss is 0.319562\n",
            "step 103 train accuracy is 1, total_loss is 0.195855, inv_loss is 118.258, class_loss is 0.319133\n",
            "step 104 train accuracy is 1, total_loss is 0.208984, inv_loss is 107.837, class_loss is 0.324575\n",
            "step 105 train accuracy is 1, total_loss is 0.201517, inv_loss is 111.076, class_loss is 0.319046\n",
            "step 106 train accuracy is 1, total_loss is 0.206455, inv_loss is 117.912, class_loss is 0.320545\n",
            "step 107 train accuracy is 1, total_loss is 0.206359, inv_loss is 116.513, class_loss is 0.319069\n",
            "step 108 train accuracy is 1, total_loss is 0.200809, inv_loss is 112.632, class_loss is 0.320533\n",
            "step 109 train accuracy is 1, total_loss is 0.200953, inv_loss is 111.392, class_loss is 0.320645\n",
            "step 110 train accuracy is 1, total_loss is 0.208533, inv_loss is 102.722, class_loss is 0.320794\n",
            "step 111 train accuracy is 1, total_loss is 0.221544, inv_loss is 107.241, class_loss is 0.316712\n",
            "step 112 train accuracy is 1, total_loss is 0.206289, inv_loss is 104.536, class_loss is 0.321005\n",
            "step 113 train accuracy is 1, total_loss is 0.202855, inv_loss is 113.849, class_loss is 0.317523\n",
            "step 114 train accuracy is 1, total_loss is 0.208698, inv_loss is 115.728, class_loss is 0.321723\n",
            "step 115 train accuracy is 1, total_loss is 0.199679, inv_loss is 114.343, class_loss is 0.319591\n",
            "step 116 train accuracy is 1, total_loss is 0.210834, inv_loss is 114.652, class_loss is 0.318209\n",
            "step 117 train accuracy is 1, total_loss is 0.20118, inv_loss is 106.647, class_loss is 0.318586\n",
            "step 118 train accuracy is 1, total_loss is 0.207193, inv_loss is 118.665, class_loss is 0.319696\n",
            "step 119 train accuracy is 1, total_loss is 0.218238, inv_loss is 114.43, class_loss is 0.321669\n",
            "step 120 train accuracy is 1, total_loss is 0.207265, inv_loss is 122.334, class_loss is 0.317786\n",
            "step 121 train accuracy is 1, total_loss is 0.213996, inv_loss is 112.895, class_loss is 0.317355\n",
            "step 122 train accuracy is 1, total_loss is 0.200998, inv_loss is 118.506, class_loss is 0.321306\n",
            "step 123 train accuracy is 1, total_loss is 0.201213, inv_loss is 120.538, class_loss is 0.316745\n",
            "step 124 train accuracy is 1, total_loss is 0.207525, inv_loss is 110.465, class_loss is 0.318831\n",
            "step 125 train accuracy is 1, total_loss is 0.207879, inv_loss is 123.671, class_loss is 0.318312\n",
            "step 126 train accuracy is 1, total_loss is 0.206733, inv_loss is 102.835, class_loss is 0.317703\n",
            "step 127 train accuracy is 1, total_loss is 0.198695, inv_loss is 115.876, class_loss is 0.318584\n",
            "step 128 train accuracy is 1, total_loss is 0.195199, inv_loss is 118.258, class_loss is 0.318277\n",
            "step 129 train accuracy is 1, total_loss is 0.207772, inv_loss is 107.837, class_loss is 0.323471\n",
            "step 130 train accuracy is 1, total_loss is 0.200677, inv_loss is 111.076, class_loss is 0.318293\n",
            "step 131 train accuracy is 1, total_loss is 0.205281, inv_loss is 117.912, class_loss is 0.319531\n",
            "step 132 train accuracy is 1, total_loss is 0.205374, inv_loss is 116.513, class_loss is 0.318073\n",
            "step 133 train accuracy is 1, total_loss is 0.199964, inv_loss is 112.632, class_loss is 0.319523\n",
            "step 134 train accuracy is 1, total_loss is 0.200055, inv_loss is 111.392, class_loss is 0.319669\n",
            "step 135 train accuracy is 1, total_loss is 0.207513, inv_loss is 102.722, class_loss is 0.319889\n",
            "step 136 train accuracy is 1, total_loss is 0.220349, inv_loss is 107.241, class_loss is 0.316142\n",
            "step 137 train accuracy is 1, total_loss is 0.20563, inv_loss is 104.536, class_loss is 0.319929\n",
            "step 138 train accuracy is 1, total_loss is 0.202122, inv_loss is 113.849, class_loss is 0.316783\n",
            "step 139 train accuracy is 1, total_loss is 0.207899, inv_loss is 115.728, class_loss is 0.320669\n",
            "step 140 train accuracy is 1, total_loss is 0.199073, inv_loss is 114.343, class_loss is 0.318716\n",
            "step 141 train accuracy is 1, total_loss is 0.21002, inv_loss is 114.652, class_loss is 0.317453\n",
            "step 142 train accuracy is 1, total_loss is 0.200412, inv_loss is 106.647, class_loss is 0.317787\n",
            "step 143 train accuracy is 1, total_loss is 0.206463, inv_loss is 118.665, class_loss is 0.318788\n",
            "step 144 train accuracy is 1, total_loss is 0.217488, inv_loss is 114.43, class_loss is 0.320596\n",
            "step 145 train accuracy is 1, total_loss is 0.206614, inv_loss is 122.334, class_loss is 0.317202\n",
            "step 146 train accuracy is 1, total_loss is 0.213121, inv_loss is 112.895, class_loss is 0.316705\n",
            "step 147 train accuracy is 1, total_loss is 0.200416, inv_loss is 118.506, class_loss is 0.320593\n",
            "step 148 train accuracy is 1, total_loss is 0.200417, inv_loss is 120.538, class_loss is 0.316207\n",
            "step 149 train accuracy is 1, total_loss is 0.206746, inv_loss is 110.465, class_loss is 0.318107\n",
            "step 150 train accuracy is 1, total_loss is 0.207071, inv_loss is 123.671, class_loss is 0.317626\n",
            "step 151 train accuracy is 1, total_loss is 0.205964, inv_loss is 102.835, class_loss is 0.317049\n",
            "step 152 train accuracy is 1, total_loss is 0.197971, inv_loss is 115.876, class_loss is 0.317912\n",
            "step 153 train accuracy is 1, total_loss is 0.194755, inv_loss is 118.258, class_loss is 0.317693\n",
            "step 154 train accuracy is 1, total_loss is 0.20691, inv_loss is 107.837, class_loss is 0.322676\n",
            "step 155 train accuracy is 1, total_loss is 0.200098, inv_loss is 111.076, class_loss is 0.317771\n",
            "step 156 train accuracy is 1, total_loss is 0.204435, inv_loss is 117.912, class_loss is 0.318816\n",
            "step 157 train accuracy is 1, total_loss is 0.204686, inv_loss is 116.513, class_loss is 0.317373\n",
            "step 158 train accuracy is 1, total_loss is 0.199366, inv_loss is 112.632, class_loss is 0.318797\n",
            "step 159 train accuracy is 1, total_loss is 0.199424, inv_loss is 111.392, class_loss is 0.318977\n",
            "step 160 train accuracy is 1, total_loss is 0.206792, inv_loss is 102.722, class_loss is 0.319235\n",
            "step 161 train accuracy is 1, total_loss is 0.219475, inv_loss is 107.241, class_loss is 0.315747\n",
            "step 162 train accuracy is 1, total_loss is 0.205166, inv_loss is 104.536, class_loss is 0.319147\n",
            "step 163 train accuracy is 1, total_loss is 0.201605, inv_loss is 113.849, class_loss is 0.316262\n",
            "step 164 train accuracy is 1, total_loss is 0.207323, inv_loss is 115.728, class_loss is 0.319894\n",
            "step 165 train accuracy is 1, total_loss is 0.198643, inv_loss is 114.343, class_loss is 0.318093\n",
            "step 166 train accuracy is 1, total_loss is 0.20944, inv_loss is 114.652, class_loss is 0.316907\n",
            "step 167 train accuracy is 1, total_loss is 0.199861, inv_loss is 106.647, class_loss is 0.317214\n",
            "step 168 train accuracy is 1, total_loss is 0.205936, inv_loss is 118.665, class_loss is 0.318134\n",
            "step 169 train accuracy is 1, total_loss is 0.216948, inv_loss is 114.43, class_loss is 0.319798\n",
            "step 170 train accuracy is 1, total_loss is 0.20615, inv_loss is 122.334, class_loss is 0.316782\n",
            "step 171 train accuracy is 1, total_loss is 0.212465, inv_loss is 112.895, class_loss is 0.316237\n",
            "step 172 train accuracy is 1, total_loss is 0.199994, inv_loss is 118.506, class_loss is 0.320068\n",
            "step 173 train accuracy is 1, total_loss is 0.199832, inv_loss is 120.538, class_loss is 0.315819\n",
            "step 174 train accuracy is 1, total_loss is 0.206177, inv_loss is 110.465, class_loss is 0.31758\n",
            "step 175 train accuracy is 1, total_loss is 0.206469, inv_loss is 123.671, class_loss is 0.317125\n",
            "step 176 train accuracy is 1, total_loss is 0.205396, inv_loss is 102.835, class_loss is 0.316568\n",
            "step 177 train accuracy is 1, total_loss is 0.197428, inv_loss is 115.876, class_loss is 0.317418\n",
            "step 178 train accuracy is 1, total_loss is 0.194435, inv_loss is 118.258, class_loss is 0.31727\n",
            "step 179 train accuracy is 1, total_loss is 0.206261, inv_loss is 107.837, class_loss is 0.32207\n",
            "step 180 train accuracy is 1, total_loss is 0.199674, inv_loss is 111.076, class_loss is 0.317386\n",
            "step 181 train accuracy is 1, total_loss is 0.20379, inv_loss is 117.912, class_loss is 0.318281\n",
            "step 182 train accuracy is 1, total_loss is 0.204177, inv_loss is 116.513, class_loss is 0.316854\n",
            "step 183 train accuracy is 1, total_loss is 0.198918, inv_loss is 112.632, class_loss is 0.318247\n",
            "step 184 train accuracy is 1, total_loss is 0.198955, inv_loss is 111.392, class_loss is 0.318458\n",
            "step 185 train accuracy is 1, total_loss is 0.206253, inv_loss is 102.722, class_loss is 0.318737\n",
            "step 186 train accuracy is 1, total_loss is 0.218805, inv_loss is 107.241, class_loss is 0.315457\n",
            "step 187 train accuracy is 1, total_loss is 0.204821, inv_loss is 104.536, class_loss is 0.31855\n",
            "step 188 train accuracy is 1, total_loss is 0.201221, inv_loss is 113.849, class_loss is 0.315875\n",
            "step 189 train accuracy is 1, total_loss is 0.206885, inv_loss is 115.728, class_loss is 0.319296\n",
            "step 190 train accuracy is 1, total_loss is 0.198323, inv_loss is 114.343, class_loss is 0.317625\n",
            "step 191 train accuracy is 1, total_loss is 0.209004, inv_loss is 114.652, class_loss is 0.316493\n",
            "step 192 train accuracy is 1, total_loss is 0.199444, inv_loss is 106.647, class_loss is 0.316783\n",
            "step 193 train accuracy is 1, total_loss is 0.205536, inv_loss is 118.665, class_loss is 0.317639\n",
            "step 194 train accuracy is 1, total_loss is 0.216539, inv_loss is 114.43, class_loss is 0.319178\n",
            "step 195 train accuracy is 1, total_loss is 0.205802, inv_loss is 122.334, class_loss is 0.316464\n",
            "step 196 train accuracy is 1, total_loss is 0.21195, inv_loss is 112.895, class_loss is 0.315884\n",
            "step 197 train accuracy is 1, total_loss is 0.199674, inv_loss is 118.506, class_loss is 0.319663\n",
            "step 198 train accuracy is 1, total_loss is 0.199382, inv_loss is 120.538, class_loss is 0.315524\n",
            "step 199 train accuracy is 1, total_loss is 0.205741, inv_loss is 110.465, class_loss is 0.31718\n",
            "beta is 0.001, test accuracy is 1\n",
            "Training...\n",
            "step 0 train accuracy is 0.99, total_loss is -0.594258, inv_loss is 123.671, class_loss is 0.524549\n",
            "step 1 train accuracy is 1, total_loss is -0.6732, inv_loss is 102.835, class_loss is 0.447879\n",
            "step 2 train accuracy is 0.98, total_loss is -0.795248, inv_loss is 115.876, class_loss is 0.424172\n",
            "step 3 train accuracy is 1, total_loss is -0.823864, inv_loss is 118.258, class_loss is 0.398682\n",
            "step 4 train accuracy is 1, total_loss is -0.731843, inv_loss is 107.837, class_loss is 0.39172\n",
            "step 5 train accuracy is 1, total_loss is -0.789812, inv_loss is 111.076, class_loss is 0.370208\n",
            "step 6 train accuracy is 1, total_loss is -0.782984, inv_loss is 117.912, class_loss is 0.37163\n",
            "step 7 train accuracy is 1, total_loss is -0.768062, inv_loss is 116.513, class_loss is 0.365356\n",
            "step 8 train accuracy is 0.99, total_loss is -0.821132, inv_loss is 112.632, class_loss is 0.360448\n",
            "step 9 train accuracy is 1, total_loss is -0.823494, inv_loss is 111.392, class_loss is 0.35926\n",
            "step 10 train accuracy is 1, total_loss is -0.757942, inv_loss is 102.722, class_loss is 0.353192\n",
            "step 11 train accuracy is 0.99, total_loss is -0.649105, inv_loss is 107.241, class_loss is 0.341093\n",
            "step 12 train accuracy is 1, total_loss is -0.774781, inv_loss is 104.536, class_loss is 0.352631\n",
            "step 13 train accuracy is 1, total_loss is -0.805317, inv_loss is 113.849, class_loss is 0.342696\n",
            "step 14 train accuracy is 1, total_loss is -0.78312, inv_loss is 115.728, class_loss is 0.348495\n",
            "step 15 train accuracy is 1, total_loss is -0.836762, inv_loss is 114.343, class_loss is 0.344838\n",
            "step 16 train accuracy is 1, total_loss is -0.74044, inv_loss is 114.652, class_loss is 0.338635\n",
            "step 17 train accuracy is 1, total_loss is -0.83491, inv_loss is 106.647, class_loss is 0.339774\n",
            "step 18 train accuracy is 1, total_loss is -0.771511, inv_loss is 118.665, class_loss is 0.342162\n",
            "step 19 train accuracy is 1, total_loss is -0.66817, inv_loss is 114.43, class_loss is 0.34367\n",
            "step 20 train accuracy is 0.99, total_loss is -0.777192, inv_loss is 122.334, class_loss is 0.332545\n",
            "step 21 train accuracy is 1, total_loss is -0.756464, inv_loss is 112.895, class_loss is 0.332893\n",
            "step 22 train accuracy is 1, total_loss is -0.843126, inv_loss is 118.506, class_loss is 0.336813\n",
            "step 23 train accuracy is 1, total_loss is -0.850119, inv_loss is 120.538, class_loss is 0.328996\n",
            "step 24 train accuracy is 1, total_loss is -0.774335, inv_loss is 110.465, class_loss is 0.334211\n",
            "step 25 train accuracy is 1, total_loss is -0.785084, inv_loss is 123.671, class_loss is 0.332229\n",
            "step 26 train accuracy is 1, total_loss is -0.7979, inv_loss is 102.835, class_loss is 0.330224\n",
            "step 27 train accuracy is 0.99, total_loss is -0.881592, inv_loss is 115.876, class_loss is 0.331726\n",
            "step 28 train accuracy is 1, total_loss is -0.885724, inv_loss is 118.258, class_loss is 0.329841\n",
            "step 29 train accuracy is 1, total_loss is -0.790349, inv_loss is 107.837, class_loss is 0.336136\n",
            "step 30 train accuracy is 1, total_loss is -0.835472, inv_loss is 111.076, class_loss is 0.327828\n",
            "step 31 train accuracy is 1, total_loss is -0.822981, inv_loss is 117.912, class_loss is 0.331359\n",
            "step 32 train accuracy is 1, total_loss is -0.805186, inv_loss is 116.513, class_loss is 0.329637\n",
            "step 33 train accuracy is 1, total_loss is -0.849586, inv_loss is 112.632, class_loss is 0.330447\n",
            "step 34 train accuracy is 1, total_loss is -0.85116, inv_loss is 111.392, class_loss is 0.330573\n",
            "step 35 train accuracy is 1, total_loss is -0.784966, inv_loss is 102.722, class_loss is 0.329552\n",
            "step 36 train accuracy is 0.99, total_loss is -0.672996, inv_loss is 107.241, class_loss is 0.32295\n",
            "step 37 train accuracy is 1, total_loss is -0.792507, inv_loss is 104.536, class_loss is 0.330812\n",
            "step 38 train accuracy is 1, total_loss is -0.822743, inv_loss is 113.849, class_loss is 0.324953\n",
            "step 39 train accuracy is 1, total_loss is -0.799752, inv_loss is 115.728, class_loss is 0.330805\n",
            "step 40 train accuracy is 1, total_loss is -0.849968, inv_loss is 114.343, class_loss is 0.327855\n",
            "step 41 train accuracy is 1, total_loss is -0.755991, inv_loss is 114.652, class_loss is 0.325086\n",
            "step 42 train accuracy is 1, total_loss is -0.848433, inv_loss is 106.647, class_loss is 0.325915\n",
            "step 43 train accuracy is 1, total_loss is -0.783221, inv_loss is 118.665, class_loss is 0.327775\n",
            "step 44 train accuracy is 1, total_loss is -0.680443, inv_loss is 114.43, class_loss is 0.330256\n",
            "step 45 train accuracy is 1, total_loss is -0.787796, inv_loss is 122.334, class_loss is 0.323067\n",
            "step 46 train accuracy is 1, total_loss is -0.767044, inv_loss is 112.895, class_loss is 0.323127\n",
            "step 47 train accuracy is 1, total_loss is -0.851472, inv_loss is 118.506, class_loss is 0.327284\n",
            "step 48 train accuracy is 1, total_loss is -0.859762, inv_loss is 120.538, class_loss is 0.321427\n",
            "step 49 train accuracy is 1, total_loss is -0.78359, inv_loss is 110.465, class_loss is 0.324955\n",
            "step 50 train accuracy is 1, total_loss is -0.793548, inv_loss is 123.671, class_loss is 0.323971\n",
            "step 51 train accuracy is 1, total_loss is -0.806338, inv_loss is 102.835, class_loss is 0.322941\n",
            "step 52 train accuracy is 1, total_loss is -0.888896, inv_loss is 115.876, class_loss is 0.324053\n",
            "step 53 train accuracy is 1, total_loss is -0.891179, inv_loss is 118.258, class_loss is 0.323108\n",
            "step 54 train accuracy is 1, total_loss is -0.798067, inv_loss is 107.837, class_loss is 0.329179\n",
            "step 55 train accuracy is 1, total_loss is -0.841538, inv_loss is 111.076, class_loss is 0.322413\n",
            "step 56 train accuracy is 1, total_loss is -0.829764, inv_loss is 117.912, class_loss is 0.324881\n",
            "step 57 train accuracy is 1, total_loss is -0.811609, inv_loss is 116.513, class_loss is 0.323336\n",
            "step 58 train accuracy is 1, total_loss is -0.854789, inv_loss is 112.632, class_loss is 0.324661\n",
            "step 59 train accuracy is 1, total_loss is -0.85671, inv_loss is 111.392, class_loss is 0.324737\n",
            "step 60 train accuracy is 1, total_loss is -0.790942, inv_loss is 102.722, class_loss is 0.324469\n",
            "step 61 train accuracy is 0.99, total_loss is -0.678991, inv_loss is 107.241, class_loss is 0.319218\n",
            "step 62 train accuracy is 1, total_loss is -0.796478, inv_loss is 104.536, class_loss is 0.325261\n",
            "step 63 train accuracy is 1, total_loss is -0.82699, inv_loss is 113.849, class_loss is 0.320633\n",
            "step 64 train accuracy is 1, total_loss is -0.804054, inv_loss is 115.728, class_loss is 0.325769\n",
            "step 65 train accuracy is 1, total_loss is -0.853389, inv_loss is 114.343, class_loss is 0.323155\n",
            "step 66 train accuracy is 1, total_loss is -0.760368, inv_loss is 114.652, class_loss is 0.321218\n",
            "step 67 train accuracy is 1, total_loss is -0.852404, inv_loss is 106.647, class_loss is 0.321795\n",
            "step 68 train accuracy is 1, total_loss is -0.786823, inv_loss is 118.665, class_loss is 0.323282\n",
            "step 69 train accuracy is 1, total_loss is -0.684228, inv_loss is 114.43, class_loss is 0.325645\n",
            "step 70 train accuracy is 1, total_loss is -0.79114, inv_loss is 122.334, class_loss is 0.320114\n",
            "step 71 train accuracy is 1, total_loss is -0.770735, inv_loss is 112.895, class_loss is 0.319928\n",
            "step 72 train accuracy is 1, total_loss is -0.854263, inv_loss is 118.506, class_loss is 0.324025\n",
            "step 73 train accuracy is 1, total_loss is -0.863264, inv_loss is 120.538, class_loss is 0.318852\n",
            "step 74 train accuracy is 1, total_loss is -0.787022, inv_loss is 110.465, class_loss is 0.321627\n",
            "step 75 train accuracy is 1, total_loss is -0.796825, inv_loss is 123.671, class_loss is 0.32092\n",
            "step 76 train accuracy is 1, total_loss is -0.809595, inv_loss is 102.835, class_loss is 0.32015\n",
            "step 77 train accuracy is 1, total_loss is -0.891788, inv_loss is 115.876, class_loss is 0.321124\n",
            "step 78 train accuracy is 1, total_loss is -0.893221, inv_loss is 118.258, class_loss is 0.320513\n",
            "step 79 train accuracy is 1, total_loss is -0.801337, inv_loss is 107.837, class_loss is 0.326247\n",
            "step 80 train accuracy is 1, total_loss is -0.843987, inv_loss is 111.076, class_loss is 0.320234\n",
            "step 81 train accuracy is 1, total_loss is -0.832788, inv_loss is 117.912, class_loss is 0.322109\n",
            "step 82 train accuracy is 1, total_loss is -0.81435, inv_loss is 116.513, class_loss is 0.320609\n",
            "step 83 train accuracy is 1, total_loss is -0.857064, inv_loss is 112.632, class_loss is 0.322054\n",
            "step 84 train accuracy is 1, total_loss is -0.859153, inv_loss is 111.392, class_loss is 0.322137\n",
            "step 85 train accuracy is 1, total_loss is -0.793647, inv_loss is 102.722, class_loss is 0.322152\n",
            "step 86 train accuracy is 1, total_loss is -0.681894, inv_loss is 107.241, class_loss is 0.317608\n",
            "step 87 train accuracy is 1, total_loss is -0.798252, inv_loss is 104.536, class_loss is 0.3226\n",
            "step 88 train accuracy is 1, total_loss is -0.828935, inv_loss is 113.849, class_loss is 0.318659\n",
            "step 89 train accuracy is 1, total_loss is -0.806079, inv_loss is 115.728, class_loss is 0.323261\n",
            "step 90 train accuracy is 1, total_loss is -0.854978, inv_loss is 114.343, class_loss is 0.320913\n",
            "step 91 train accuracy is 1, total_loss is -0.762458, inv_loss is 114.652, class_loss is 0.319337\n",
            "step 92 train accuracy is 1, total_loss is -0.854333, inv_loss is 106.647, class_loss is 0.319785\n",
            "step 93 train accuracy is 1, total_loss is -0.788612, inv_loss is 118.665, class_loss is 0.321046\n",
            "step 94 train accuracy is 1, total_loss is -0.686093, inv_loss is 114.43, class_loss is 0.323208\n",
            "step 95 train accuracy is 1, total_loss is -0.792786, inv_loss is 122.334, class_loss is 0.318658\n",
            "step 96 train accuracy is 1, total_loss is -0.772693, inv_loss is 112.895, class_loss is 0.318324\n",
            "step 97 train accuracy is 1, total_loss is -0.855677, inv_loss is 118.506, class_loss is 0.322345\n",
            "step 98 train accuracy is 1, total_loss is -0.865112, inv_loss is 120.538, class_loss is 0.317542\n",
            "step 99 train accuracy is 1, total_loss is -0.78884, inv_loss is 110.465, class_loss is 0.319897\n",
            "step 100 train accuracy is 1, total_loss is -0.798617, inv_loss is 123.671, class_loss is 0.319312\n",
            "step 101 train accuracy is 1, total_loss is -0.811351, inv_loss is 102.835, class_loss is 0.318649\n",
            "step 102 train accuracy is 1, total_loss is -0.89338, inv_loss is 115.876, class_loss is 0.319562\n",
            "step 103 train accuracy is 1, total_loss is -0.894289, inv_loss is 118.258, class_loss is 0.319133\n",
            "step 104 train accuracy is 1, total_loss is -0.803191, inv_loss is 107.837, class_loss is 0.324575\n",
            "step 105 train accuracy is 1, total_loss is -0.845319, inv_loss is 111.076, class_loss is 0.319046\n",
            "step 106 train accuracy is 1, total_loss is -0.834551, inv_loss is 117.912, class_loss is 0.320545\n",
            "step 107 train accuracy is 1, total_loss is -0.815884, inv_loss is 116.513, class_loss is 0.319069\n",
            "step 108 train accuracy is 1, total_loss is -0.85836, inv_loss is 112.632, class_loss is 0.320533\n",
            "step 109 train accuracy is 1, total_loss is -0.860541, inv_loss is 111.392, class_loss is 0.320645\n",
            "step 110 train accuracy is 1, total_loss is -0.795206, inv_loss is 102.722, class_loss is 0.320794\n",
            "step 111 train accuracy is 1, total_loss is -0.683652, inv_loss is 107.241, class_loss is 0.316712\n",
            "step 112 train accuracy is 1, total_loss is -0.799265, inv_loss is 104.536, class_loss is 0.321005\n",
            "step 113 train accuracy is 1, total_loss is -0.830057, inv_loss is 113.849, class_loss is 0.317523\n",
            "step 114 train accuracy is 1, total_loss is -0.807275, inv_loss is 115.728, class_loss is 0.321723\n",
            "step 115 train accuracy is 1, total_loss is -0.855902, inv_loss is 114.343, class_loss is 0.319591\n",
            "step 116 train accuracy is 1, total_loss is -0.763689, inv_loss is 114.652, class_loss is 0.318209\n",
            "step 117 train accuracy is 1, total_loss is -0.855483, inv_loss is 106.647, class_loss is 0.318586\n",
            "step 118 train accuracy is 1, total_loss is -0.789694, inv_loss is 118.665, class_loss is 0.319696\n",
            "step 119 train accuracy is 1, total_loss is -0.687211, inv_loss is 114.43, class_loss is 0.321669\n",
            "step 120 train accuracy is 1, total_loss is -0.793767, inv_loss is 122.334, class_loss is 0.317786\n",
            "step 121 train accuracy is 1, total_loss is -0.773937, inv_loss is 112.895, class_loss is 0.317355\n",
            "step 122 train accuracy is 1, total_loss is -0.856538, inv_loss is 118.506, class_loss is 0.321306\n",
            "step 123 train accuracy is 1, total_loss is -0.866266, inv_loss is 120.538, class_loss is 0.316745\n",
            "step 124 train accuracy is 1, total_loss is -0.789975, inv_loss is 110.465, class_loss is 0.318831\n",
            "step 125 train accuracy is 1, total_loss is -0.799766, inv_loss is 123.671, class_loss is 0.318312\n",
            "step 126 train accuracy is 1, total_loss is -0.812461, inv_loss is 102.835, class_loss is 0.317703\n",
            "step 127 train accuracy is 1, total_loss is -0.894406, inv_loss is 115.876, class_loss is 0.318584\n",
            "step 128 train accuracy is 1, total_loss is -0.894944, inv_loss is 118.258, class_loss is 0.318277\n",
            "step 129 train accuracy is 1, total_loss is -0.804403, inv_loss is 107.837, class_loss is 0.323471\n",
            "step 130 train accuracy is 1, total_loss is -0.846159, inv_loss is 111.076, class_loss is 0.318293\n",
            "step 131 train accuracy is 1, total_loss is -0.835724, inv_loss is 117.912, class_loss is 0.319531\n",
            "step 132 train accuracy is 1, total_loss is -0.816869, inv_loss is 116.513, class_loss is 0.318073\n",
            "step 133 train accuracy is 1, total_loss is -0.859205, inv_loss is 112.632, class_loss is 0.319523\n",
            "step 134 train accuracy is 1, total_loss is -0.861439, inv_loss is 111.392, class_loss is 0.319669\n",
            "step 135 train accuracy is 1, total_loss is -0.796225, inv_loss is 102.722, class_loss is 0.319889\n",
            "step 136 train accuracy is 1, total_loss is -0.684847, inv_loss is 107.241, class_loss is 0.316142\n",
            "step 137 train accuracy is 1, total_loss is -0.799924, inv_loss is 104.536, class_loss is 0.319929\n",
            "step 138 train accuracy is 1, total_loss is -0.830789, inv_loss is 113.849, class_loss is 0.316783\n",
            "step 139 train accuracy is 1, total_loss is -0.808074, inv_loss is 115.728, class_loss is 0.320669\n",
            "step 140 train accuracy is 1, total_loss is -0.856508, inv_loss is 114.343, class_loss is 0.318716\n",
            "step 141 train accuracy is 1, total_loss is -0.764503, inv_loss is 114.652, class_loss is 0.317453\n",
            "step 142 train accuracy is 1, total_loss is -0.856251, inv_loss is 106.647, class_loss is 0.317787\n",
            "step 143 train accuracy is 1, total_loss is -0.790424, inv_loss is 118.665, class_loss is 0.318788\n",
            "step 144 train accuracy is 1, total_loss is -0.687961, inv_loss is 114.43, class_loss is 0.320596\n",
            "step 145 train accuracy is 1, total_loss is -0.794419, inv_loss is 122.334, class_loss is 0.317202\n",
            "step 146 train accuracy is 1, total_loss is -0.774812, inv_loss is 112.895, class_loss is 0.316705\n",
            "step 147 train accuracy is 1, total_loss is -0.857119, inv_loss is 118.506, class_loss is 0.320593\n",
            "step 148 train accuracy is 1, total_loss is -0.867062, inv_loss is 120.538, class_loss is 0.316207\n",
            "step 149 train accuracy is 1, total_loss is -0.790754, inv_loss is 110.465, class_loss is 0.318107\n",
            "step 150 train accuracy is 1, total_loss is -0.800573, inv_loss is 123.671, class_loss is 0.317626\n",
            "step 151 train accuracy is 1, total_loss is -0.813231, inv_loss is 102.835, class_loss is 0.317049\n",
            "step 152 train accuracy is 1, total_loss is -0.89513, inv_loss is 115.876, class_loss is 0.317912\n",
            "step 153 train accuracy is 1, total_loss is -0.895388, inv_loss is 118.258, class_loss is 0.317693\n",
            "step 154 train accuracy is 1, total_loss is -0.805265, inv_loss is 107.837, class_loss is 0.322676\n",
            "step 155 train accuracy is 1, total_loss is -0.846738, inv_loss is 111.076, class_loss is 0.317771\n",
            "step 156 train accuracy is 1, total_loss is -0.836571, inv_loss is 117.912, class_loss is 0.318816\n",
            "step 157 train accuracy is 1, total_loss is -0.817557, inv_loss is 116.513, class_loss is 0.317373\n",
            "step 158 train accuracy is 1, total_loss is -0.859803, inv_loss is 112.632, class_loss is 0.318797\n",
            "step 159 train accuracy is 1, total_loss is -0.86207, inv_loss is 111.392, class_loss is 0.318977\n",
            "step 160 train accuracy is 1, total_loss is -0.796947, inv_loss is 102.722, class_loss is 0.319235\n",
            "step 161 train accuracy is 1, total_loss is -0.68572, inv_loss is 107.241, class_loss is 0.315747\n",
            "step 162 train accuracy is 1, total_loss is -0.800388, inv_loss is 104.536, class_loss is 0.319147\n",
            "step 163 train accuracy is 1, total_loss is -0.831306, inv_loss is 113.849, class_loss is 0.316262\n",
            "step 164 train accuracy is 1, total_loss is -0.80865, inv_loss is 115.728, class_loss is 0.319894\n",
            "step 165 train accuracy is 1, total_loss is -0.856938, inv_loss is 114.343, class_loss is 0.318093\n",
            "step 166 train accuracy is 1, total_loss is -0.765083, inv_loss is 114.652, class_loss is 0.316907\n",
            "step 167 train accuracy is 1, total_loss is -0.856802, inv_loss is 106.647, class_loss is 0.317214\n",
            "step 168 train accuracy is 1, total_loss is -0.790951, inv_loss is 118.665, class_loss is 0.318134\n",
            "step 169 train accuracy is 1, total_loss is -0.688501, inv_loss is 114.43, class_loss is 0.319798\n",
            "step 170 train accuracy is 1, total_loss is -0.794883, inv_loss is 122.334, class_loss is 0.316782\n",
            "step 171 train accuracy is 1, total_loss is -0.775468, inv_loss is 112.895, class_loss is 0.316237\n",
            "step 172 train accuracy is 1, total_loss is -0.857541, inv_loss is 118.506, class_loss is 0.320068\n",
            "step 173 train accuracy is 1, total_loss is -0.867647, inv_loss is 120.538, class_loss is 0.315819\n",
            "step 174 train accuracy is 1, total_loss is -0.791323, inv_loss is 110.465, class_loss is 0.31758\n",
            "step 175 train accuracy is 1, total_loss is -0.801176, inv_loss is 123.671, class_loss is 0.317125\n",
            "step 176 train accuracy is 1, total_loss is -0.813799, inv_loss is 102.835, class_loss is 0.316568\n",
            "step 177 train accuracy is 1, total_loss is -0.895673, inv_loss is 115.876, class_loss is 0.317418\n",
            "step 178 train accuracy is 1, total_loss is -0.895708, inv_loss is 118.258, class_loss is 0.31727\n",
            "step 179 train accuracy is 1, total_loss is -0.805914, inv_loss is 107.837, class_loss is 0.32207\n",
            "step 180 train accuracy is 1, total_loss is -0.847162, inv_loss is 111.076, class_loss is 0.317386\n",
            "step 181 train accuracy is 1, total_loss is -0.837215, inv_loss is 117.912, class_loss is 0.318281\n",
            "step 182 train accuracy is 1, total_loss is -0.818066, inv_loss is 116.513, class_loss is 0.316854\n",
            "step 183 train accuracy is 1, total_loss is -0.860251, inv_loss is 112.632, class_loss is 0.318247\n",
            "step 184 train accuracy is 1, total_loss is -0.862538, inv_loss is 111.392, class_loss is 0.318458\n",
            "step 185 train accuracy is 1, total_loss is -0.797485, inv_loss is 102.722, class_loss is 0.318737\n",
            "step 186 train accuracy is 1, total_loss is -0.686391, inv_loss is 107.241, class_loss is 0.315457\n",
            "step 187 train accuracy is 1, total_loss is -0.800733, inv_loss is 104.536, class_loss is 0.31855\n",
            "step 188 train accuracy is 1, total_loss is -0.831691, inv_loss is 113.849, class_loss is 0.315875\n",
            "step 189 train accuracy is 1, total_loss is -0.809088, inv_loss is 115.728, class_loss is 0.319296\n",
            "step 190 train accuracy is 1, total_loss is -0.857259, inv_loss is 114.343, class_loss is 0.317625\n",
            "step 191 train accuracy is 1, total_loss is -0.765518, inv_loss is 114.652, class_loss is 0.316493\n",
            "step 192 train accuracy is 1, total_loss is -0.857219, inv_loss is 106.647, class_loss is 0.316783\n",
            "step 193 train accuracy is 1, total_loss is -0.791351, inv_loss is 118.665, class_loss is 0.317639\n",
            "step 194 train accuracy is 1, total_loss is -0.68891, inv_loss is 114.43, class_loss is 0.319178\n",
            "step 195 train accuracy is 1, total_loss is -0.79523, inv_loss is 122.334, class_loss is 0.316464\n",
            "step 196 train accuracy is 1, total_loss is -0.775983, inv_loss is 112.895, class_loss is 0.315884\n",
            "step 197 train accuracy is 1, total_loss is -0.857862, inv_loss is 118.506, class_loss is 0.319663\n",
            "step 198 train accuracy is 1, total_loss is -0.868096, inv_loss is 120.538, class_loss is 0.315524\n",
            "step 199 train accuracy is 1, total_loss is -0.791758, inv_loss is 110.465, class_loss is 0.31718\n",
            "beta is 0.01, test accuracy is 1\n",
            "Training...\n",
            "step 0 train accuracy is 0.99, total_loss is -10.6707, inv_loss is 123.671, class_loss is 0.524549\n",
            "step 1 train accuracy is 1, total_loss is -10.8651, inv_loss is 102.835, class_loss is 0.447879\n",
            "step 2 train accuracy is 0.98, total_loss is -11.7263, inv_loss is 115.876, class_loss is 0.424172\n",
            "step 3 train accuracy is 1, total_loss is -11.7253, inv_loss is 118.258, class_loss is 0.398682\n",
            "step 4 train accuracy is 1, total_loss is -10.8536, inv_loss is 107.837, class_loss is 0.39172\n",
            "step 5 train accuracy is 1, total_loss is -11.2582, inv_loss is 111.076, class_loss is 0.370208\n",
            "step 6 train accuracy is 1, total_loss is -11.193, inv_loss is 117.912, class_loss is 0.37163\n",
            "step 7 train accuracy is 1, total_loss is -10.9905, inv_loss is 116.513, class_loss is 0.365356\n",
            "step 8 train accuracy is 0.99, total_loss is -11.4128, inv_loss is 112.632, class_loss is 0.360448\n",
            "step 9 train accuracy is 1, total_loss is -11.4384, inv_loss is 111.392, class_loss is 0.35926\n",
            "step 10 train accuracy is 1, total_loss is -10.7953, inv_loss is 102.722, class_loss is 0.353192\n",
            "step 11 train accuracy is 0.99, total_loss is -9.70106, inv_loss is 107.241, class_loss is 0.341093\n",
            "step 12 train accuracy is 1, total_loss is -10.8303, inv_loss is 104.536, class_loss is 0.352631\n",
            "step 13 train accuracy is 1, total_loss is -11.1344, inv_loss is 113.849, class_loss is 0.342696\n",
            "step 14 train accuracy is 1, total_loss is -10.9429, inv_loss is 115.728, class_loss is 0.348495\n",
            "step 15 train accuracy is 1, total_loss is -11.3926, inv_loss is 114.343, class_loss is 0.344838\n",
            "step 16 train accuracy is 1, total_loss is -10.4857, inv_loss is 114.652, class_loss is 0.338635\n",
            "step 17 train accuracy is 1, total_loss is -11.4015, inv_loss is 106.647, class_loss is 0.339774\n",
            "step 18 train accuracy is 1, total_loss is -10.7404, inv_loss is 118.665, class_loss is 0.342162\n",
            "step 19 train accuracy is 1, total_loss is -9.72267, inv_loss is 114.43, class_loss is 0.34367\n",
            "step 20 train accuracy is 0.99, total_loss is -10.7875, inv_loss is 122.334, class_loss is 0.332545\n",
            "step 21 train accuracy is 1, total_loss is -10.6358, inv_loss is 112.895, class_loss is 0.332893\n",
            "step 22 train accuracy is 1, total_loss is -11.4185, inv_loss is 118.506, class_loss is 0.336813\n",
            "step 23 train accuracy is 1, total_loss is -11.5249, inv_loss is 120.538, class_loss is 0.328996\n",
            "step 24 train accuracy is 1, total_loss is -10.7493, inv_loss is 110.465, class_loss is 0.334211\n",
            "step 25 train accuracy is 1, total_loss is -10.8615, inv_loss is 123.671, class_loss is 0.332229\n",
            "step 26 train accuracy is 1, total_loss is -10.9898, inv_loss is 102.835, class_loss is 0.330224\n",
            "step 27 train accuracy is 0.99, total_loss is -11.8126, inv_loss is 115.876, class_loss is 0.331726\n",
            "step 28 train accuracy is 1, total_loss is -11.7872, inv_loss is 118.258, class_loss is 0.329841\n",
            "step 29 train accuracy is 1, total_loss is -10.9121, inv_loss is 107.837, class_loss is 0.336136\n",
            "step 30 train accuracy is 1, total_loss is -11.3038, inv_loss is 111.076, class_loss is 0.327828\n",
            "step 31 train accuracy is 1, total_loss is -11.233, inv_loss is 117.912, class_loss is 0.331359\n",
            "step 32 train accuracy is 1, total_loss is -11.0276, inv_loss is 116.513, class_loss is 0.329637\n",
            "step 33 train accuracy is 1, total_loss is -11.4413, inv_loss is 112.632, class_loss is 0.330447\n",
            "step 34 train accuracy is 1, total_loss is -11.4661, inv_loss is 111.392, class_loss is 0.330573\n",
            "step 35 train accuracy is 1, total_loss is -10.8223, inv_loss is 102.722, class_loss is 0.329552\n",
            "step 36 train accuracy is 0.99, total_loss is -9.72495, inv_loss is 107.241, class_loss is 0.32295\n",
            "step 37 train accuracy is 1, total_loss is -10.848, inv_loss is 104.536, class_loss is 0.330812\n",
            "step 38 train accuracy is 1, total_loss is -11.1519, inv_loss is 113.849, class_loss is 0.324953\n",
            "step 39 train accuracy is 1, total_loss is -10.9595, inv_loss is 115.728, class_loss is 0.330805\n",
            "step 40 train accuracy is 1, total_loss is -11.4058, inv_loss is 114.343, class_loss is 0.327855\n",
            "step 41 train accuracy is 1, total_loss is -10.5012, inv_loss is 114.652, class_loss is 0.325086\n",
            "step 42 train accuracy is 1, total_loss is -11.4151, inv_loss is 106.647, class_loss is 0.325915\n",
            "step 43 train accuracy is 1, total_loss is -10.7521, inv_loss is 118.665, class_loss is 0.327775\n",
            "step 44 train accuracy is 1, total_loss is -9.73494, inv_loss is 114.43, class_loss is 0.330256\n",
            "step 45 train accuracy is 1, total_loss is -10.7981, inv_loss is 122.334, class_loss is 0.323067\n",
            "step 46 train accuracy is 1, total_loss is -10.6464, inv_loss is 112.895, class_loss is 0.323127\n",
            "step 47 train accuracy is 1, total_loss is -11.4268, inv_loss is 118.506, class_loss is 0.327284\n",
            "step 48 train accuracy is 1, total_loss is -11.5345, inv_loss is 120.538, class_loss is 0.321427\n",
            "step 49 train accuracy is 1, total_loss is -10.7586, inv_loss is 110.465, class_loss is 0.324955\n",
            "step 50 train accuracy is 1, total_loss is -10.87, inv_loss is 123.671, class_loss is 0.323971\n",
            "step 51 train accuracy is 1, total_loss is -10.9983, inv_loss is 102.835, class_loss is 0.322941\n",
            "step 52 train accuracy is 1, total_loss is -11.8199, inv_loss is 115.876, class_loss is 0.324053\n",
            "step 53 train accuracy is 1, total_loss is -11.7926, inv_loss is 118.258, class_loss is 0.323108\n",
            "step 54 train accuracy is 1, total_loss is -10.9198, inv_loss is 107.837, class_loss is 0.329179\n",
            "step 55 train accuracy is 1, total_loss is -11.3099, inv_loss is 111.076, class_loss is 0.322413\n",
            "step 56 train accuracy is 1, total_loss is -11.2398, inv_loss is 117.912, class_loss is 0.324881\n",
            "step 57 train accuracy is 1, total_loss is -11.034, inv_loss is 116.513, class_loss is 0.323336\n",
            "step 58 train accuracy is 1, total_loss is -11.4465, inv_loss is 112.632, class_loss is 0.324661\n",
            "step 59 train accuracy is 1, total_loss is -11.4716, inv_loss is 111.392, class_loss is 0.324737\n",
            "step 60 train accuracy is 1, total_loss is -10.8283, inv_loss is 102.722, class_loss is 0.324469\n",
            "step 61 train accuracy is 0.99, total_loss is -9.73095, inv_loss is 107.241, class_loss is 0.319218\n",
            "step 62 train accuracy is 1, total_loss is -10.852, inv_loss is 104.536, class_loss is 0.325261\n",
            "step 63 train accuracy is 1, total_loss is -11.1561, inv_loss is 113.849, class_loss is 0.320633\n",
            "step 64 train accuracy is 1, total_loss is -10.9638, inv_loss is 115.728, class_loss is 0.325769\n",
            "step 65 train accuracy is 1, total_loss is -11.4092, inv_loss is 114.343, class_loss is 0.323155\n",
            "step 66 train accuracy is 1, total_loss is -10.5056, inv_loss is 114.652, class_loss is 0.321218\n",
            "step 67 train accuracy is 1, total_loss is -11.419, inv_loss is 106.647, class_loss is 0.321795\n",
            "step 68 train accuracy is 1, total_loss is -10.7557, inv_loss is 118.665, class_loss is 0.323282\n",
            "step 69 train accuracy is 1, total_loss is -9.73872, inv_loss is 114.43, class_loss is 0.325645\n",
            "step 70 train accuracy is 1, total_loss is -10.8015, inv_loss is 122.334, class_loss is 0.320114\n",
            "step 71 train accuracy is 1, total_loss is -10.6501, inv_loss is 112.895, class_loss is 0.319928\n",
            "step 72 train accuracy is 1, total_loss is -11.4296, inv_loss is 118.506, class_loss is 0.324025\n",
            "step 73 train accuracy is 1, total_loss is -11.5381, inv_loss is 120.538, class_loss is 0.318852\n",
            "step 74 train accuracy is 1, total_loss is -10.762, inv_loss is 110.465, class_loss is 0.321627\n",
            "step 75 train accuracy is 1, total_loss is -10.8733, inv_loss is 123.671, class_loss is 0.32092\n",
            "step 76 train accuracy is 1, total_loss is -11.0015, inv_loss is 102.835, class_loss is 0.32015\n",
            "step 77 train accuracy is 1, total_loss is -11.8228, inv_loss is 115.876, class_loss is 0.321124\n",
            "step 78 train accuracy is 1, total_loss is -11.7947, inv_loss is 118.258, class_loss is 0.320513\n",
            "step 79 train accuracy is 1, total_loss is -10.9231, inv_loss is 107.837, class_loss is 0.326247\n",
            "step 80 train accuracy is 1, total_loss is -11.3124, inv_loss is 111.076, class_loss is 0.320234\n",
            "step 81 train accuracy is 1, total_loss is -11.2428, inv_loss is 117.912, class_loss is 0.322109\n",
            "step 82 train accuracy is 1, total_loss is -11.0368, inv_loss is 116.513, class_loss is 0.320609\n",
            "step 83 train accuracy is 1, total_loss is -11.4488, inv_loss is 112.632, class_loss is 0.322054\n",
            "step 84 train accuracy is 1, total_loss is -11.4741, inv_loss is 111.392, class_loss is 0.322137\n",
            "step 85 train accuracy is 1, total_loss is -10.831, inv_loss is 102.722, class_loss is 0.322152\n",
            "step 86 train accuracy is 1, total_loss is -9.73385, inv_loss is 107.241, class_loss is 0.317608\n",
            "step 87 train accuracy is 1, total_loss is -10.8538, inv_loss is 104.536, class_loss is 0.3226\n",
            "step 88 train accuracy is 1, total_loss is -11.158, inv_loss is 113.849, class_loss is 0.318659\n",
            "step 89 train accuracy is 1, total_loss is -10.9658, inv_loss is 115.728, class_loss is 0.323261\n",
            "step 90 train accuracy is 1, total_loss is -11.4108, inv_loss is 114.343, class_loss is 0.320913\n",
            "step 91 train accuracy is 1, total_loss is -10.5077, inv_loss is 114.652, class_loss is 0.319337\n",
            "step 92 train accuracy is 1, total_loss is -11.421, inv_loss is 106.647, class_loss is 0.319785\n",
            "step 93 train accuracy is 1, total_loss is -10.7575, inv_loss is 118.665, class_loss is 0.321046\n",
            "step 94 train accuracy is 1, total_loss is -9.74059, inv_loss is 114.43, class_loss is 0.323208\n",
            "step 95 train accuracy is 1, total_loss is -10.8031, inv_loss is 122.334, class_loss is 0.318658\n",
            "step 96 train accuracy is 1, total_loss is -10.652, inv_loss is 112.895, class_loss is 0.318324\n",
            "step 97 train accuracy is 1, total_loss is -11.431, inv_loss is 118.506, class_loss is 0.322345\n",
            "step 98 train accuracy is 1, total_loss is -11.5399, inv_loss is 120.538, class_loss is 0.317542\n",
            "step 99 train accuracy is 1, total_loss is -10.7638, inv_loss is 110.465, class_loss is 0.319897\n",
            "step 100 train accuracy is 1, total_loss is -10.8751, inv_loss is 123.671, class_loss is 0.319312\n",
            "step 101 train accuracy is 1, total_loss is -11.0033, inv_loss is 102.835, class_loss is 0.318649\n",
            "step 102 train accuracy is 1, total_loss is -11.8244, inv_loss is 115.876, class_loss is 0.319562\n",
            "step 103 train accuracy is 1, total_loss is -11.7957, inv_loss is 118.258, class_loss is 0.319133\n",
            "step 104 train accuracy is 1, total_loss is -10.9249, inv_loss is 107.837, class_loss is 0.324575\n",
            "step 105 train accuracy is 1, total_loss is -11.3137, inv_loss is 111.076, class_loss is 0.319046\n",
            "step 106 train accuracy is 1, total_loss is -11.2446, inv_loss is 117.912, class_loss is 0.320545\n",
            "step 107 train accuracy is 1, total_loss is -11.0383, inv_loss is 116.513, class_loss is 0.319069\n",
            "step 108 train accuracy is 1, total_loss is -11.4501, inv_loss is 112.632, class_loss is 0.320533\n",
            "step 109 train accuracy is 1, total_loss is -11.4755, inv_loss is 111.392, class_loss is 0.320645\n",
            "step 110 train accuracy is 1, total_loss is -10.8326, inv_loss is 102.722, class_loss is 0.320794\n",
            "step 111 train accuracy is 1, total_loss is -9.73561, inv_loss is 107.241, class_loss is 0.316712\n",
            "step 112 train accuracy is 1, total_loss is -10.8548, inv_loss is 104.536, class_loss is 0.321005\n",
            "step 113 train accuracy is 1, total_loss is -11.1592, inv_loss is 113.849, class_loss is 0.317523\n",
            "step 114 train accuracy is 1, total_loss is -10.967, inv_loss is 115.728, class_loss is 0.321723\n",
            "step 115 train accuracy is 1, total_loss is -11.4117, inv_loss is 114.343, class_loss is 0.319591\n",
            "step 116 train accuracy is 1, total_loss is -10.5089, inv_loss is 114.652, class_loss is 0.318209\n",
            "step 117 train accuracy is 1, total_loss is -11.4221, inv_loss is 106.647, class_loss is 0.318586\n",
            "step 118 train accuracy is 1, total_loss is -10.7586, inv_loss is 118.665, class_loss is 0.319696\n",
            "step 119 train accuracy is 1, total_loss is -9.74171, inv_loss is 114.43, class_loss is 0.321669\n",
            "step 120 train accuracy is 1, total_loss is -10.8041, inv_loss is 122.334, class_loss is 0.317786\n",
            "step 121 train accuracy is 1, total_loss is -10.6533, inv_loss is 112.895, class_loss is 0.317355\n",
            "step 122 train accuracy is 1, total_loss is -11.4319, inv_loss is 118.506, class_loss is 0.321306\n",
            "step 123 train accuracy is 1, total_loss is -11.5411, inv_loss is 120.538, class_loss is 0.316745\n",
            "step 124 train accuracy is 1, total_loss is -10.765, inv_loss is 110.465, class_loss is 0.318831\n",
            "step 125 train accuracy is 1, total_loss is -10.8762, inv_loss is 123.671, class_loss is 0.318312\n",
            "step 126 train accuracy is 1, total_loss is -11.0044, inv_loss is 102.835, class_loss is 0.317703\n",
            "step 127 train accuracy is 1, total_loss is -11.8254, inv_loss is 115.876, class_loss is 0.318584\n",
            "step 128 train accuracy is 1, total_loss is -11.7964, inv_loss is 118.258, class_loss is 0.318277\n",
            "step 129 train accuracy is 1, total_loss is -10.9262, inv_loss is 107.837, class_loss is 0.323471\n",
            "step 130 train accuracy is 1, total_loss is -11.3145, inv_loss is 111.076, class_loss is 0.318293\n",
            "step 131 train accuracy is 1, total_loss is -11.2458, inv_loss is 117.912, class_loss is 0.319531\n",
            "step 132 train accuracy is 1, total_loss is -11.0393, inv_loss is 116.513, class_loss is 0.318073\n",
            "step 133 train accuracy is 1, total_loss is -11.4509, inv_loss is 112.632, class_loss is 0.319523\n",
            "step 134 train accuracy is 1, total_loss is -11.4764, inv_loss is 111.392, class_loss is 0.319669\n",
            "step 135 train accuracy is 1, total_loss is -10.8336, inv_loss is 102.722, class_loss is 0.319889\n",
            "step 136 train accuracy is 1, total_loss is -9.7368, inv_loss is 107.241, class_loss is 0.316142\n",
            "step 137 train accuracy is 1, total_loss is -10.8555, inv_loss is 104.536, class_loss is 0.319929\n",
            "step 138 train accuracy is 1, total_loss is -11.1599, inv_loss is 113.849, class_loss is 0.316783\n",
            "step 139 train accuracy is 1, total_loss is -10.9678, inv_loss is 115.728, class_loss is 0.320669\n",
            "step 140 train accuracy is 1, total_loss is -11.4123, inv_loss is 114.343, class_loss is 0.318716\n",
            "step 141 train accuracy is 1, total_loss is -10.5097, inv_loss is 114.652, class_loss is 0.317453\n",
            "step 142 train accuracy is 1, total_loss is -11.4229, inv_loss is 106.647, class_loss is 0.317787\n",
            "step 143 train accuracy is 1, total_loss is -10.7593, inv_loss is 118.665, class_loss is 0.318788\n",
            "step 144 train accuracy is 1, total_loss is -9.74246, inv_loss is 114.43, class_loss is 0.320596\n",
            "step 145 train accuracy is 1, total_loss is -10.8047, inv_loss is 122.334, class_loss is 0.317202\n",
            "step 146 train accuracy is 1, total_loss is -10.6541, inv_loss is 112.895, class_loss is 0.316705\n",
            "step 147 train accuracy is 1, total_loss is -11.4325, inv_loss is 118.506, class_loss is 0.320593\n",
            "step 148 train accuracy is 1, total_loss is -11.5418, inv_loss is 120.538, class_loss is 0.316207\n",
            "step 149 train accuracy is 1, total_loss is -10.7657, inv_loss is 110.465, class_loss is 0.318107\n",
            "step 150 train accuracy is 1, total_loss is -10.877, inv_loss is 123.671, class_loss is 0.317626\n",
            "step 151 train accuracy is 1, total_loss is -11.0052, inv_loss is 102.835, class_loss is 0.317049\n",
            "step 152 train accuracy is 1, total_loss is -11.8261, inv_loss is 115.876, class_loss is 0.317912\n",
            "step 153 train accuracy is 1, total_loss is -11.7968, inv_loss is 118.258, class_loss is 0.317693\n",
            "step 154 train accuracy is 1, total_loss is -10.927, inv_loss is 107.837, class_loss is 0.322676\n",
            "step 155 train accuracy is 1, total_loss is -11.3151, inv_loss is 111.076, class_loss is 0.317771\n",
            "step 156 train accuracy is 1, total_loss is -11.2466, inv_loss is 117.912, class_loss is 0.318816\n",
            "step 157 train accuracy is 1, total_loss is -11.04, inv_loss is 116.513, class_loss is 0.317373\n",
            "step 158 train accuracy is 1, total_loss is -11.4515, inv_loss is 112.632, class_loss is 0.318797\n",
            "step 159 train accuracy is 1, total_loss is -11.477, inv_loss is 111.392, class_loss is 0.318977\n",
            "step 160 train accuracy is 1, total_loss is -10.8343, inv_loss is 102.722, class_loss is 0.319235\n",
            "step 161 train accuracy is 1, total_loss is -9.73768, inv_loss is 107.241, class_loss is 0.315747\n",
            "step 162 train accuracy is 1, total_loss is -10.8559, inv_loss is 104.536, class_loss is 0.319147\n",
            "step 163 train accuracy is 1, total_loss is -11.1604, inv_loss is 113.849, class_loss is 0.316262\n",
            "step 164 train accuracy is 1, total_loss is -10.9684, inv_loss is 115.728, class_loss is 0.319894\n",
            "step 165 train accuracy is 1, total_loss is -11.4127, inv_loss is 114.343, class_loss is 0.318093\n",
            "step 166 train accuracy is 1, total_loss is -10.5103, inv_loss is 114.652, class_loss is 0.316907\n",
            "step 167 train accuracy is 1, total_loss is -11.4234, inv_loss is 106.647, class_loss is 0.317214\n",
            "step 168 train accuracy is 1, total_loss is -10.7598, inv_loss is 118.665, class_loss is 0.318134\n",
            "step 169 train accuracy is 1, total_loss is -9.743, inv_loss is 114.43, class_loss is 0.319798\n",
            "step 170 train accuracy is 1, total_loss is -10.8052, inv_loss is 122.334, class_loss is 0.316782\n",
            "step 171 train accuracy is 1, total_loss is -10.6548, inv_loss is 112.895, class_loss is 0.316237\n",
            "step 172 train accuracy is 1, total_loss is -11.4329, inv_loss is 118.506, class_loss is 0.320068\n",
            "step 173 train accuracy is 1, total_loss is -11.5424, inv_loss is 120.538, class_loss is 0.315819\n",
            "step 174 train accuracy is 1, total_loss is -10.7663, inv_loss is 110.465, class_loss is 0.31758\n",
            "step 175 train accuracy is 1, total_loss is -10.8776, inv_loss is 123.671, class_loss is 0.317125\n",
            "step 176 train accuracy is 1, total_loss is -11.0057, inv_loss is 102.835, class_loss is 0.316568\n",
            "step 177 train accuracy is 1, total_loss is -11.8267, inv_loss is 115.876, class_loss is 0.317418\n",
            "step 178 train accuracy is 1, total_loss is -11.7971, inv_loss is 118.258, class_loss is 0.31727\n",
            "step 179 train accuracy is 1, total_loss is -10.9277, inv_loss is 107.837, class_loss is 0.32207\n",
            "step 180 train accuracy is 1, total_loss is -11.3155, inv_loss is 111.076, class_loss is 0.317386\n",
            "step 181 train accuracy is 1, total_loss is -11.2473, inv_loss is 117.912, class_loss is 0.318281\n",
            "step 182 train accuracy is 1, total_loss is -11.0405, inv_loss is 116.513, class_loss is 0.316854\n",
            "step 183 train accuracy is 1, total_loss is -11.4519, inv_loss is 112.632, class_loss is 0.318247\n",
            "step 184 train accuracy is 1, total_loss is -11.4775, inv_loss is 111.392, class_loss is 0.318458\n",
            "step 185 train accuracy is 1, total_loss is -10.8349, inv_loss is 102.722, class_loss is 0.318737\n",
            "step 186 train accuracy is 1, total_loss is -9.73835, inv_loss is 107.241, class_loss is 0.315457\n",
            "step 187 train accuracy is 1, total_loss is -10.8563, inv_loss is 104.536, class_loss is 0.31855\n",
            "step 188 train accuracy is 1, total_loss is -11.1608, inv_loss is 113.849, class_loss is 0.315875\n",
            "step 189 train accuracy is 1, total_loss is -10.9688, inv_loss is 115.728, class_loss is 0.319296\n",
            "step 190 train accuracy is 1, total_loss is -11.4131, inv_loss is 114.343, class_loss is 0.317625\n",
            "step 191 train accuracy is 1, total_loss is -10.5107, inv_loss is 114.652, class_loss is 0.316493\n",
            "step 192 train accuracy is 1, total_loss is -11.4239, inv_loss is 106.647, class_loss is 0.316783\n",
            "step 193 train accuracy is 1, total_loss is -10.7602, inv_loss is 118.665, class_loss is 0.317639\n",
            "step 194 train accuracy is 1, total_loss is -9.74341, inv_loss is 114.43, class_loss is 0.319178\n",
            "step 195 train accuracy is 1, total_loss is -10.8056, inv_loss is 122.334, class_loss is 0.316464\n",
            "step 196 train accuracy is 1, total_loss is -10.6553, inv_loss is 112.895, class_loss is 0.315884\n",
            "step 197 train accuracy is 1, total_loss is -11.4332, inv_loss is 118.506, class_loss is 0.319663\n",
            "step 198 train accuracy is 1, total_loss is -11.5429, inv_loss is 120.538, class_loss is 0.315524\n",
            "step 199 train accuracy is 1, total_loss is -10.7668, inv_loss is 110.465, class_loss is 0.31718\n",
            "beta is 0.1, test accuracy is 1\n",
            "Training...\n",
            "step 0 train accuracy is 0.99, total_loss is -55.4549, inv_loss is 123.671, class_loss is 0.524549\n",
            "step 1 train accuracy is 1, total_loss is -56.1627, inv_loss is 102.835, class_loss is 0.447879\n",
            "step 2 train accuracy is 0.98, total_loss is -60.3085, inv_loss is 115.876, class_loss is 0.424172\n",
            "step 3 train accuracy is 1, total_loss is -60.1761, inv_loss is 118.258, class_loss is 0.398682\n",
            "step 4 train accuracy is 1, total_loss is -55.8392, inv_loss is 107.837, class_loss is 0.39172\n",
            "step 5 train accuracy is 1, total_loss is -57.7842, inv_loss is 111.076, class_loss is 0.370208\n",
            "step 6 train accuracy is 1, total_loss is -57.46, inv_loss is 117.912, class_loss is 0.37163\n",
            "step 7 train accuracy is 1, total_loss is -56.4235, inv_loss is 116.513, class_loss is 0.365356\n",
            "step 8 train accuracy is 0.99, total_loss is -58.487, inv_loss is 112.632, class_loss is 0.360448\n",
            "step 9 train accuracy is 1, total_loss is -58.6159, inv_loss is 111.392, class_loss is 0.35926\n",
            "step 10 train accuracy is 1, total_loss is -55.4059, inv_loss is 102.722, class_loss is 0.353192\n",
            "step 11 train accuracy is 0.99, total_loss is -49.932, inv_loss is 107.241, class_loss is 0.341093\n",
            "step 12 train accuracy is 1, total_loss is -55.5216, inv_loss is 104.536, class_loss is 0.352631\n",
            "step 13 train accuracy is 1, total_loss is -57.0416, inv_loss is 113.849, class_loss is 0.342696\n",
            "step 14 train accuracy is 1, total_loss is -56.0972, inv_loss is 115.728, class_loss is 0.348495\n",
            "step 15 train accuracy is 1, total_loss is -58.3073, inv_loss is 114.343, class_loss is 0.344838\n",
            "step 16 train accuracy is 1, total_loss is -53.7978, inv_loss is 114.652, class_loss is 0.338635\n",
            "step 17 train accuracy is 1, total_loss is -58.3643, inv_loss is 106.647, class_loss is 0.339774\n",
            "step 18 train accuracy is 1, total_loss is -55.0465, inv_loss is 118.665, class_loss is 0.342162\n",
            "step 19 train accuracy is 1, total_loss is -49.9649, inv_loss is 114.43, class_loss is 0.34367\n",
            "step 20 train accuracy is 0.99, total_loss is -55.2778, inv_loss is 122.334, class_loss is 0.332545\n",
            "step 21 train accuracy is 1, total_loss is -54.5439, inv_loss is 112.895, class_loss is 0.332893\n",
            "step 22 train accuracy is 1, total_loss is -58.4201, inv_loss is 118.506, class_loss is 0.336813\n",
            "step 23 train accuracy is 1, total_loss is -58.9684, inv_loss is 120.538, class_loss is 0.328996\n",
            "step 24 train accuracy is 1, total_loss is -55.0826, inv_loss is 110.465, class_loss is 0.334211\n",
            "step 25 train accuracy is 1, total_loss is -55.6457, inv_loss is 123.671, class_loss is 0.332229\n",
            "step 26 train accuracy is 1, total_loss is -56.2874, inv_loss is 102.835, class_loss is 0.330224\n",
            "step 27 train accuracy is 0.99, total_loss is -60.3949, inv_loss is 115.876, class_loss is 0.331726\n",
            "step 28 train accuracy is 1, total_loss is -60.238, inv_loss is 118.258, class_loss is 0.329841\n",
            "step 29 train accuracy is 1, total_loss is -55.8977, inv_loss is 107.837, class_loss is 0.336136\n",
            "step 30 train accuracy is 1, total_loss is -57.8299, inv_loss is 111.076, class_loss is 0.327828\n",
            "step 31 train accuracy is 1, total_loss is -57.5, inv_loss is 117.912, class_loss is 0.331359\n",
            "step 32 train accuracy is 1, total_loss is -56.4606, inv_loss is 116.513, class_loss is 0.329637\n",
            "step 33 train accuracy is 1, total_loss is -58.5155, inv_loss is 112.632, class_loss is 0.330447\n",
            "step 34 train accuracy is 1, total_loss is -58.6436, inv_loss is 111.392, class_loss is 0.330573\n",
            "step 35 train accuracy is 1, total_loss is -55.4329, inv_loss is 102.722, class_loss is 0.329552\n",
            "step 36 train accuracy is 0.99, total_loss is -49.9559, inv_loss is 107.241, class_loss is 0.32295\n",
            "step 37 train accuracy is 1, total_loss is -55.5393, inv_loss is 104.536, class_loss is 0.330812\n",
            "step 38 train accuracy is 1, total_loss is -57.059, inv_loss is 113.849, class_loss is 0.324953\n",
            "step 39 train accuracy is 1, total_loss is -56.1138, inv_loss is 115.728, class_loss is 0.330805\n",
            "step 40 train accuracy is 1, total_loss is -58.3205, inv_loss is 114.343, class_loss is 0.327855\n",
            "step 41 train accuracy is 1, total_loss is -53.8133, inv_loss is 114.652, class_loss is 0.325086\n",
            "step 42 train accuracy is 1, total_loss is -58.3779, inv_loss is 106.647, class_loss is 0.325915\n",
            "step 43 train accuracy is 1, total_loss is -55.0582, inv_loss is 118.665, class_loss is 0.327775\n",
            "step 44 train accuracy is 1, total_loss is -49.9771, inv_loss is 114.43, class_loss is 0.330256\n",
            "step 45 train accuracy is 1, total_loss is -55.2885, inv_loss is 122.334, class_loss is 0.323067\n",
            "step 46 train accuracy is 1, total_loss is -54.5545, inv_loss is 112.895, class_loss is 0.323127\n",
            "step 47 train accuracy is 1, total_loss is -58.4284, inv_loss is 118.506, class_loss is 0.327284\n",
            "step 48 train accuracy is 1, total_loss is -58.9781, inv_loss is 120.538, class_loss is 0.321427\n",
            "step 49 train accuracy is 1, total_loss is -55.0919, inv_loss is 110.465, class_loss is 0.324955\n",
            "step 50 train accuracy is 1, total_loss is -55.6542, inv_loss is 123.671, class_loss is 0.323971\n",
            "step 51 train accuracy is 1, total_loss is -56.2958, inv_loss is 102.835, class_loss is 0.322941\n",
            "step 52 train accuracy is 1, total_loss is -60.4022, inv_loss is 115.876, class_loss is 0.324053\n",
            "step 53 train accuracy is 1, total_loss is -60.2434, inv_loss is 118.258, class_loss is 0.323108\n",
            "step 54 train accuracy is 1, total_loss is -55.9054, inv_loss is 107.837, class_loss is 0.329179\n",
            "step 55 train accuracy is 1, total_loss is -57.836, inv_loss is 111.076, class_loss is 0.322413\n",
            "step 56 train accuracy is 1, total_loss is -57.5067, inv_loss is 117.912, class_loss is 0.324881\n",
            "step 57 train accuracy is 1, total_loss is -56.4671, inv_loss is 116.513, class_loss is 0.323336\n",
            "step 58 train accuracy is 1, total_loss is -58.5207, inv_loss is 112.632, class_loss is 0.324661\n",
            "step 59 train accuracy is 1, total_loss is -58.6491, inv_loss is 111.392, class_loss is 0.324737\n",
            "step 60 train accuracy is 1, total_loss is -55.4389, inv_loss is 102.722, class_loss is 0.324469\n",
            "step 61 train accuracy is 0.99, total_loss is -49.9619, inv_loss is 107.241, class_loss is 0.319218\n",
            "step 62 train accuracy is 1, total_loss is -55.5433, inv_loss is 104.536, class_loss is 0.325261\n",
            "step 63 train accuracy is 1, total_loss is -57.0633, inv_loss is 113.849, class_loss is 0.320633\n",
            "step 64 train accuracy is 1, total_loss is -56.1181, inv_loss is 115.728, class_loss is 0.325769\n",
            "step 65 train accuracy is 1, total_loss is -58.3239, inv_loss is 114.343, class_loss is 0.323155\n",
            "step 66 train accuracy is 1, total_loss is -53.8177, inv_loss is 114.652, class_loss is 0.321218\n",
            "step 67 train accuracy is 1, total_loss is -58.3818, inv_loss is 106.647, class_loss is 0.321795\n",
            "step 68 train accuracy is 1, total_loss is -55.0618, inv_loss is 118.665, class_loss is 0.323282\n",
            "step 69 train accuracy is 1, total_loss is -49.9809, inv_loss is 114.43, class_loss is 0.325645\n",
            "step 70 train accuracy is 1, total_loss is -55.2918, inv_loss is 122.334, class_loss is 0.320114\n",
            "step 71 train accuracy is 1, total_loss is -54.5582, inv_loss is 112.895, class_loss is 0.319928\n",
            "step 72 train accuracy is 1, total_loss is -58.4312, inv_loss is 118.506, class_loss is 0.324025\n",
            "step 73 train accuracy is 1, total_loss is -58.9816, inv_loss is 120.538, class_loss is 0.318852\n",
            "step 74 train accuracy is 1, total_loss is -55.0953, inv_loss is 110.465, class_loss is 0.321627\n",
            "step 75 train accuracy is 1, total_loss is -55.6575, inv_loss is 123.671, class_loss is 0.32092\n",
            "step 76 train accuracy is 1, total_loss is -56.2991, inv_loss is 102.835, class_loss is 0.32015\n",
            "step 77 train accuracy is 1, total_loss is -60.4051, inv_loss is 115.876, class_loss is 0.321124\n",
            "step 78 train accuracy is 1, total_loss is -60.2455, inv_loss is 118.258, class_loss is 0.320513\n",
            "step 79 train accuracy is 1, total_loss is -55.9086, inv_loss is 107.837, class_loss is 0.326247\n",
            "step 80 train accuracy is 1, total_loss is -57.8384, inv_loss is 111.076, class_loss is 0.320234\n",
            "step 81 train accuracy is 1, total_loss is -57.5098, inv_loss is 117.912, class_loss is 0.322109\n",
            "step 82 train accuracy is 1, total_loss is -56.4698, inv_loss is 116.513, class_loss is 0.320609\n",
            "step 83 train accuracy is 1, total_loss is -58.5229, inv_loss is 112.632, class_loss is 0.322054\n",
            "step 84 train accuracy is 1, total_loss is -58.6516, inv_loss is 111.392, class_loss is 0.322137\n",
            "step 85 train accuracy is 1, total_loss is -55.4416, inv_loss is 102.722, class_loss is 0.322152\n",
            "step 86 train accuracy is 1, total_loss is -49.9648, inv_loss is 107.241, class_loss is 0.317608\n",
            "step 87 train accuracy is 1, total_loss is -55.5451, inv_loss is 104.536, class_loss is 0.3226\n",
            "step 88 train accuracy is 1, total_loss is -57.0652, inv_loss is 113.849, class_loss is 0.318659\n",
            "step 89 train accuracy is 1, total_loss is -56.1202, inv_loss is 115.728, class_loss is 0.323261\n",
            "step 90 train accuracy is 1, total_loss is -58.3255, inv_loss is 114.343, class_loss is 0.320913\n",
            "step 91 train accuracy is 1, total_loss is -53.8198, inv_loss is 114.652, class_loss is 0.319337\n",
            "step 92 train accuracy is 1, total_loss is -58.3838, inv_loss is 106.647, class_loss is 0.319785\n",
            "step 93 train accuracy is 1, total_loss is -55.0636, inv_loss is 118.665, class_loss is 0.321046\n",
            "step 94 train accuracy is 1, total_loss is -49.9828, inv_loss is 114.43, class_loss is 0.323208\n",
            "step 95 train accuracy is 1, total_loss is -55.2934, inv_loss is 122.334, class_loss is 0.318658\n",
            "step 96 train accuracy is 1, total_loss is -54.5602, inv_loss is 112.895, class_loss is 0.318324\n",
            "step 97 train accuracy is 1, total_loss is -58.4326, inv_loss is 118.506, class_loss is 0.322345\n",
            "step 98 train accuracy is 1, total_loss is -58.9834, inv_loss is 120.538, class_loss is 0.317542\n",
            "step 99 train accuracy is 1, total_loss is -55.0972, inv_loss is 110.465, class_loss is 0.319897\n",
            "step 100 train accuracy is 1, total_loss is -55.6593, inv_loss is 123.671, class_loss is 0.319312\n",
            "step 101 train accuracy is 1, total_loss is -56.3008, inv_loss is 102.835, class_loss is 0.318649\n",
            "step 102 train accuracy is 1, total_loss is -60.4066, inv_loss is 115.876, class_loss is 0.319562\n",
            "step 103 train accuracy is 1, total_loss is -60.2466, inv_loss is 118.258, class_loss is 0.319133\n",
            "step 104 train accuracy is 1, total_loss is -55.9105, inv_loss is 107.837, class_loss is 0.324575\n",
            "step 105 train accuracy is 1, total_loss is -57.8397, inv_loss is 111.076, class_loss is 0.319046\n",
            "step 106 train accuracy is 1, total_loss is -57.5115, inv_loss is 117.912, class_loss is 0.320545\n",
            "step 107 train accuracy is 1, total_loss is -56.4713, inv_loss is 116.513, class_loss is 0.319069\n",
            "step 108 train accuracy is 1, total_loss is -58.5242, inv_loss is 112.632, class_loss is 0.320533\n",
            "step 109 train accuracy is 1, total_loss is -58.653, inv_loss is 111.392, class_loss is 0.320645\n",
            "step 110 train accuracy is 1, total_loss is -55.4432, inv_loss is 102.722, class_loss is 0.320794\n",
            "step 111 train accuracy is 1, total_loss is -49.9665, inv_loss is 107.241, class_loss is 0.316712\n",
            "step 112 train accuracy is 1, total_loss is -55.5461, inv_loss is 104.536, class_loss is 0.321005\n",
            "step 113 train accuracy is 1, total_loss is -57.0663, inv_loss is 113.849, class_loss is 0.317523\n",
            "step 114 train accuracy is 1, total_loss is -56.1214, inv_loss is 115.728, class_loss is 0.321723\n",
            "step 115 train accuracy is 1, total_loss is -58.3264, inv_loss is 114.343, class_loss is 0.319591\n",
            "step 116 train accuracy is 1, total_loss is -53.821, inv_loss is 114.652, class_loss is 0.318209\n",
            "step 117 train accuracy is 1, total_loss is -58.3849, inv_loss is 106.647, class_loss is 0.318586\n",
            "step 118 train accuracy is 1, total_loss is -55.0647, inv_loss is 118.665, class_loss is 0.319696\n",
            "step 119 train accuracy is 1, total_loss is -49.9839, inv_loss is 114.43, class_loss is 0.321669\n",
            "step 120 train accuracy is 1, total_loss is -55.2944, inv_loss is 122.334, class_loss is 0.317786\n",
            "step 121 train accuracy is 1, total_loss is -54.5614, inv_loss is 112.895, class_loss is 0.317355\n",
            "step 122 train accuracy is 1, total_loss is -58.4335, inv_loss is 118.506, class_loss is 0.321306\n",
            "step 123 train accuracy is 1, total_loss is -58.9846, inv_loss is 120.538, class_loss is 0.316745\n",
            "step 124 train accuracy is 1, total_loss is -55.0983, inv_loss is 110.465, class_loss is 0.318831\n",
            "step 125 train accuracy is 1, total_loss is -55.6604, inv_loss is 123.671, class_loss is 0.318312\n",
            "step 126 train accuracy is 1, total_loss is -56.302, inv_loss is 102.835, class_loss is 0.317703\n",
            "step 127 train accuracy is 1, total_loss is -60.4077, inv_loss is 115.876, class_loss is 0.318584\n",
            "step 128 train accuracy is 1, total_loss is -60.2472, inv_loss is 118.258, class_loss is 0.318277\n",
            "step 129 train accuracy is 1, total_loss is -55.9117, inv_loss is 107.837, class_loss is 0.323471\n",
            "step 130 train accuracy is 1, total_loss is -57.8406, inv_loss is 111.076, class_loss is 0.318293\n",
            "step 131 train accuracy is 1, total_loss is -57.5127, inv_loss is 117.912, class_loss is 0.319531\n",
            "step 132 train accuracy is 1, total_loss is -56.4723, inv_loss is 116.513, class_loss is 0.318073\n",
            "step 133 train accuracy is 1, total_loss is -58.5251, inv_loss is 112.632, class_loss is 0.319523\n",
            "step 134 train accuracy is 1, total_loss is -58.6539, inv_loss is 111.392, class_loss is 0.319669\n",
            "step 135 train accuracy is 1, total_loss is -55.4442, inv_loss is 102.722, class_loss is 0.319889\n",
            "step 136 train accuracy is 1, total_loss is -49.9677, inv_loss is 107.241, class_loss is 0.316142\n",
            "step 137 train accuracy is 1, total_loss is -55.5467, inv_loss is 104.536, class_loss is 0.319929\n",
            "step 138 train accuracy is 1, total_loss is -57.0671, inv_loss is 113.849, class_loss is 0.316783\n",
            "step 139 train accuracy is 1, total_loss is -56.1222, inv_loss is 115.728, class_loss is 0.320669\n",
            "step 140 train accuracy is 1, total_loss is -58.327, inv_loss is 114.343, class_loss is 0.318716\n",
            "step 141 train accuracy is 1, total_loss is -53.8218, inv_loss is 114.652, class_loss is 0.317453\n",
            "step 142 train accuracy is 1, total_loss is -58.3857, inv_loss is 106.647, class_loss is 0.317787\n",
            "step 143 train accuracy is 1, total_loss is -55.0654, inv_loss is 118.665, class_loss is 0.318788\n",
            "step 144 train accuracy is 1, total_loss is -49.9847, inv_loss is 114.43, class_loss is 0.320596\n",
            "step 145 train accuracy is 1, total_loss is -55.2951, inv_loss is 122.334, class_loss is 0.317202\n",
            "step 146 train accuracy is 1, total_loss is -54.5623, inv_loss is 112.895, class_loss is 0.316705\n",
            "step 147 train accuracy is 1, total_loss is -58.4341, inv_loss is 118.506, class_loss is 0.320593\n",
            "step 148 train accuracy is 1, total_loss is -58.9853, inv_loss is 120.538, class_loss is 0.316207\n",
            "step 149 train accuracy is 1, total_loss is -55.0991, inv_loss is 110.465, class_loss is 0.318107\n",
            "step 150 train accuracy is 1, total_loss is -55.6612, inv_loss is 123.671, class_loss is 0.317626\n",
            "step 151 train accuracy is 1, total_loss is -56.3027, inv_loss is 102.835, class_loss is 0.317049\n",
            "step 152 train accuracy is 1, total_loss is -60.4084, inv_loss is 115.876, class_loss is 0.317912\n",
            "step 153 train accuracy is 1, total_loss is -60.2477, inv_loss is 118.258, class_loss is 0.317693\n",
            "step 154 train accuracy is 1, total_loss is -55.9126, inv_loss is 107.837, class_loss is 0.322676\n",
            "step 155 train accuracy is 1, total_loss is -57.8412, inv_loss is 111.076, class_loss is 0.317771\n",
            "step 156 train accuracy is 1, total_loss is -57.5135, inv_loss is 117.912, class_loss is 0.318816\n",
            "step 157 train accuracy is 1, total_loss is -56.473, inv_loss is 116.513, class_loss is 0.317373\n",
            "step 158 train accuracy is 1, total_loss is -58.5257, inv_loss is 112.632, class_loss is 0.318797\n",
            "step 159 train accuracy is 1, total_loss is -58.6545, inv_loss is 111.392, class_loss is 0.318977\n",
            "step 160 train accuracy is 1, total_loss is -55.4449, inv_loss is 102.722, class_loss is 0.319235\n",
            "step 161 train accuracy is 1, total_loss is -49.9686, inv_loss is 107.241, class_loss is 0.315747\n",
            "step 162 train accuracy is 1, total_loss is -55.5472, inv_loss is 104.536, class_loss is 0.319147\n",
            "step 163 train accuracy is 1, total_loss is -57.0676, inv_loss is 113.849, class_loss is 0.316262\n",
            "step 164 train accuracy is 1, total_loss is -56.1227, inv_loss is 115.728, class_loss is 0.319894\n",
            "step 165 train accuracy is 1, total_loss is -58.3275, inv_loss is 114.343, class_loss is 0.318093\n",
            "step 166 train accuracy is 1, total_loss is -53.8224, inv_loss is 114.652, class_loss is 0.316907\n",
            "step 167 train accuracy is 1, total_loss is -58.3862, inv_loss is 106.647, class_loss is 0.317214\n",
            "step 168 train accuracy is 1, total_loss is -55.0659, inv_loss is 118.665, class_loss is 0.318134\n",
            "step 169 train accuracy is 1, total_loss is -49.9852, inv_loss is 114.43, class_loss is 0.319798\n",
            "step 170 train accuracy is 1, total_loss is -55.2955, inv_loss is 122.334, class_loss is 0.316782\n",
            "step 171 train accuracy is 1, total_loss is -54.5629, inv_loss is 112.895, class_loss is 0.316237\n",
            "step 172 train accuracy is 1, total_loss is -58.4345, inv_loss is 118.506, class_loss is 0.320068\n",
            "step 173 train accuracy is 1, total_loss is -58.9859, inv_loss is 120.538, class_loss is 0.315819\n",
            "step 174 train accuracy is 1, total_loss is -55.0996, inv_loss is 110.465, class_loss is 0.31758\n",
            "step 175 train accuracy is 1, total_loss is -55.6618, inv_loss is 123.671, class_loss is 0.317125\n",
            "step 176 train accuracy is 1, total_loss is -56.3033, inv_loss is 102.835, class_loss is 0.316568\n",
            "step 177 train accuracy is 1, total_loss is -60.4089, inv_loss is 115.876, class_loss is 0.317418\n",
            "step 178 train accuracy is 1, total_loss is -60.248, inv_loss is 118.258, class_loss is 0.31727\n",
            "step 179 train accuracy is 1, total_loss is -55.9132, inv_loss is 107.837, class_loss is 0.32207\n",
            "step 180 train accuracy is 1, total_loss is -57.8416, inv_loss is 111.076, class_loss is 0.317386\n",
            "step 181 train accuracy is 1, total_loss is -57.5142, inv_loss is 117.912, class_loss is 0.318281\n",
            "step 182 train accuracy is 1, total_loss is -56.4735, inv_loss is 116.513, class_loss is 0.316854\n",
            "step 183 train accuracy is 1, total_loss is -58.5261, inv_loss is 112.632, class_loss is 0.318247\n",
            "step 184 train accuracy is 1, total_loss is -58.655, inv_loss is 111.392, class_loss is 0.318458\n",
            "step 185 train accuracy is 1, total_loss is -55.4455, inv_loss is 102.722, class_loss is 0.318737\n",
            "step 186 train accuracy is 1, total_loss is -49.9693, inv_loss is 107.241, class_loss is 0.315457\n",
            "step 187 train accuracy is 1, total_loss is -55.5476, inv_loss is 104.536, class_loss is 0.31855\n",
            "step 188 train accuracy is 1, total_loss is -57.068, inv_loss is 113.849, class_loss is 0.315875\n",
            "step 189 train accuracy is 1, total_loss is -56.1232, inv_loss is 115.728, class_loss is 0.319296\n",
            "step 190 train accuracy is 1, total_loss is -58.3278, inv_loss is 114.343, class_loss is 0.317625\n",
            "step 191 train accuracy is 1, total_loss is -53.8229, inv_loss is 114.652, class_loss is 0.316493\n",
            "step 192 train accuracy is 1, total_loss is -58.3867, inv_loss is 106.647, class_loss is 0.316783\n",
            "step 193 train accuracy is 1, total_loss is -55.0663, inv_loss is 118.665, class_loss is 0.317639\n",
            "step 194 train accuracy is 1, total_loss is -49.9856, inv_loss is 114.43, class_loss is 0.319178\n",
            "step 195 train accuracy is 1, total_loss is -55.2959, inv_loss is 122.334, class_loss is 0.316464\n",
            "step 196 train accuracy is 1, total_loss is -54.5634, inv_loss is 112.895, class_loss is 0.315884\n",
            "step 197 train accuracy is 1, total_loss is -58.4348, inv_loss is 118.506, class_loss is 0.319663\n",
            "step 198 train accuracy is 1, total_loss is -58.9864, inv_loss is 120.538, class_loss is 0.315524\n",
            "step 199 train accuracy is 1, total_loss is -55.1001, inv_loss is 110.465, class_loss is 0.31718\n",
            "beta is 0.5, test accuracy is 1\n",
            "Training...\n",
            "step 0 train accuracy is 0.99, total_loss is -111.435, inv_loss is 123.671, class_loss is 0.524549\n",
            "step 1 train accuracy is 1, total_loss is -112.785, inv_loss is 102.835, class_loss is 0.447879\n",
            "step 2 train accuracy is 0.98, total_loss is -121.036, inv_loss is 115.876, class_loss is 0.424172\n",
            "step 3 train accuracy is 1, total_loss is -120.74, inv_loss is 118.258, class_loss is 0.398682\n",
            "step 4 train accuracy is 1, total_loss is -112.071, inv_loss is 107.837, class_loss is 0.39172\n",
            "step 5 train accuracy is 1, total_loss is -115.942, inv_loss is 111.076, class_loss is 0.370208\n",
            "step 6 train accuracy is 1, total_loss is -115.294, inv_loss is 117.912, class_loss is 0.37163\n",
            "step 7 train accuracy is 1, total_loss is -113.215, inv_loss is 116.513, class_loss is 0.365356\n",
            "step 8 train accuracy is 0.99, total_loss is -117.33, inv_loss is 112.632, class_loss is 0.360448\n",
            "step 9 train accuracy is 1, total_loss is -117.588, inv_loss is 111.392, class_loss is 0.35926\n",
            "step 10 train accuracy is 1, total_loss is -111.169, inv_loss is 102.722, class_loss is 0.353192\n",
            "step 11 train accuracy is 0.99, total_loss is -100.221, inv_loss is 107.241, class_loss is 0.341093\n",
            "step 12 train accuracy is 1, total_loss is -111.386, inv_loss is 104.536, class_loss is 0.352631\n",
            "step 13 train accuracy is 1, total_loss is -114.426, inv_loss is 113.849, class_loss is 0.342696\n",
            "step 14 train accuracy is 1, total_loss is -112.54, inv_loss is 115.728, class_loss is 0.348495\n",
            "step 15 train accuracy is 1, total_loss is -116.951, inv_loss is 114.343, class_loss is 0.344838\n",
            "step 16 train accuracy is 1, total_loss is -107.938, inv_loss is 114.652, class_loss is 0.338635\n",
            "step 17 train accuracy is 1, total_loss is -117.068, inv_loss is 106.647, class_loss is 0.339774\n",
            "step 18 train accuracy is 1, total_loss is -110.429, inv_loss is 118.665, class_loss is 0.342162\n",
            "step 19 train accuracy is 1, total_loss is -100.268, inv_loss is 114.43, class_loss is 0.34367\n",
            "step 20 train accuracy is 0.99, total_loss is -110.891, inv_loss is 122.334, class_loss is 0.332545\n",
            "step 21 train accuracy is 1, total_loss is -109.429, inv_loss is 112.895, class_loss is 0.332893\n",
            "step 22 train accuracy is 1, total_loss is -117.172, inv_loss is 118.506, class_loss is 0.336813\n",
            "step 23 train accuracy is 1, total_loss is -118.273, inv_loss is 120.538, class_loss is 0.328996\n",
            "step 24 train accuracy is 1, total_loss is -110.499, inv_loss is 110.465, class_loss is 0.334211\n",
            "step 25 train accuracy is 1, total_loss is -111.626, inv_loss is 123.671, class_loss is 0.332229\n",
            "step 26 train accuracy is 1, total_loss is -112.909, inv_loss is 102.835, class_loss is 0.330224\n",
            "step 27 train accuracy is 0.99, total_loss is -121.123, inv_loss is 115.876, class_loss is 0.331726\n",
            "step 28 train accuracy is 1, total_loss is -120.802, inv_loss is 118.258, class_loss is 0.329841\n",
            "step 29 train accuracy is 1, total_loss is -112.13, inv_loss is 107.837, class_loss is 0.336136\n",
            "step 30 train accuracy is 1, total_loss is -115.987, inv_loss is 111.076, class_loss is 0.327828\n",
            "step 31 train accuracy is 1, total_loss is -115.334, inv_loss is 117.912, class_loss is 0.331359\n",
            "step 32 train accuracy is 1, total_loss is -113.252, inv_loss is 116.513, class_loss is 0.329637\n",
            "step 33 train accuracy is 1, total_loss is -117.358, inv_loss is 112.632, class_loss is 0.330447\n",
            "step 34 train accuracy is 1, total_loss is -117.615, inv_loss is 111.392, class_loss is 0.330573\n",
            "step 35 train accuracy is 1, total_loss is -111.196, inv_loss is 102.722, class_loss is 0.329552\n",
            "step 36 train accuracy is 0.99, total_loss is -100.245, inv_loss is 107.241, class_loss is 0.32295\n",
            "step 37 train accuracy is 1, total_loss is -111.403, inv_loss is 104.536, class_loss is 0.330812\n",
            "step 38 train accuracy is 1, total_loss is -114.443, inv_loss is 113.849, class_loss is 0.324953\n",
            "step 39 train accuracy is 1, total_loss is -112.557, inv_loss is 115.728, class_loss is 0.330805\n",
            "step 40 train accuracy is 1, total_loss is -116.964, inv_loss is 114.343, class_loss is 0.327855\n",
            "step 41 train accuracy is 1, total_loss is -107.953, inv_loss is 114.652, class_loss is 0.325086\n",
            "step 42 train accuracy is 1, total_loss is -117.081, inv_loss is 106.647, class_loss is 0.325915\n",
            "step 43 train accuracy is 1, total_loss is -110.441, inv_loss is 118.665, class_loss is 0.327775\n",
            "step 44 train accuracy is 1, total_loss is -100.28, inv_loss is 114.43, class_loss is 0.330256\n",
            "step 45 train accuracy is 1, total_loss is -110.901, inv_loss is 122.334, class_loss is 0.323067\n",
            "step 46 train accuracy is 1, total_loss is -109.44, inv_loss is 112.895, class_loss is 0.323127\n",
            "step 47 train accuracy is 1, total_loss is -117.18, inv_loss is 118.506, class_loss is 0.327284\n",
            "step 48 train accuracy is 1, total_loss is -118.282, inv_loss is 120.538, class_loss is 0.321427\n",
            "step 49 train accuracy is 1, total_loss is -110.509, inv_loss is 110.465, class_loss is 0.324955\n",
            "step 50 train accuracy is 1, total_loss is -111.634, inv_loss is 123.671, class_loss is 0.323971\n",
            "step 51 train accuracy is 1, total_loss is -112.918, inv_loss is 102.835, class_loss is 0.322941\n",
            "step 52 train accuracy is 1, total_loss is -121.13, inv_loss is 115.876, class_loss is 0.324053\n",
            "step 53 train accuracy is 1, total_loss is -120.807, inv_loss is 118.258, class_loss is 0.323108\n",
            "step 54 train accuracy is 1, total_loss is -112.137, inv_loss is 107.837, class_loss is 0.329179\n",
            "step 55 train accuracy is 1, total_loss is -115.994, inv_loss is 111.076, class_loss is 0.322413\n",
            "step 56 train accuracy is 1, total_loss is -115.34, inv_loss is 117.912, class_loss is 0.324881\n",
            "step 57 train accuracy is 1, total_loss is -113.258, inv_loss is 116.513, class_loss is 0.323336\n",
            "step 58 train accuracy is 1, total_loss is -117.363, inv_loss is 112.632, class_loss is 0.324661\n",
            "step 59 train accuracy is 1, total_loss is -117.621, inv_loss is 111.392, class_loss is 0.324737\n",
            "step 60 train accuracy is 1, total_loss is -111.202, inv_loss is 102.722, class_loss is 0.324469\n",
            "step 61 train accuracy is 0.99, total_loss is -100.251, inv_loss is 107.241, class_loss is 0.319218\n",
            "step 62 train accuracy is 1, total_loss is -111.407, inv_loss is 104.536, class_loss is 0.325261\n",
            "step 63 train accuracy is 1, total_loss is -114.447, inv_loss is 113.849, class_loss is 0.320633\n",
            "step 64 train accuracy is 1, total_loss is -112.561, inv_loss is 115.728, class_loss is 0.325769\n",
            "step 65 train accuracy is 1, total_loss is -116.967, inv_loss is 114.343, class_loss is 0.323155\n",
            "step 66 train accuracy is 1, total_loss is -107.958, inv_loss is 114.652, class_loss is 0.321218\n",
            "step 67 train accuracy is 1, total_loss is -117.085, inv_loss is 106.647, class_loss is 0.321795\n",
            "step 68 train accuracy is 1, total_loss is -110.444, inv_loss is 118.665, class_loss is 0.323282\n",
            "step 69 train accuracy is 1, total_loss is -100.284, inv_loss is 114.43, class_loss is 0.325645\n",
            "step 70 train accuracy is 1, total_loss is -110.905, inv_loss is 122.334, class_loss is 0.320114\n",
            "step 71 train accuracy is 1, total_loss is -109.443, inv_loss is 112.895, class_loss is 0.319928\n",
            "step 72 train accuracy is 1, total_loss is -117.183, inv_loss is 118.506, class_loss is 0.324025\n",
            "step 73 train accuracy is 1, total_loss is -118.286, inv_loss is 120.538, class_loss is 0.318852\n",
            "step 74 train accuracy is 1, total_loss is -110.512, inv_loss is 110.465, class_loss is 0.321627\n",
            "step 75 train accuracy is 1, total_loss is -111.638, inv_loss is 123.671, class_loss is 0.32092\n",
            "step 76 train accuracy is 1, total_loss is -112.921, inv_loss is 102.835, class_loss is 0.32015\n",
            "step 77 train accuracy is 1, total_loss is -121.133, inv_loss is 115.876, class_loss is 0.321124\n",
            "step 78 train accuracy is 1, total_loss is -120.809, inv_loss is 118.258, class_loss is 0.320513\n",
            "step 79 train accuracy is 1, total_loss is -112.141, inv_loss is 107.837, class_loss is 0.326247\n",
            "step 80 train accuracy is 1, total_loss is -115.996, inv_loss is 111.076, class_loss is 0.320234\n",
            "step 81 train accuracy is 1, total_loss is -115.343, inv_loss is 117.912, class_loss is 0.322109\n",
            "step 82 train accuracy is 1, total_loss is -113.261, inv_loss is 116.513, class_loss is 0.320609\n",
            "step 83 train accuracy is 1, total_loss is -117.366, inv_loss is 112.632, class_loss is 0.322054\n",
            "step 84 train accuracy is 1, total_loss is -117.623, inv_loss is 111.392, class_loss is 0.322137\n",
            "step 85 train accuracy is 1, total_loss is -111.205, inv_loss is 102.722, class_loss is 0.322152\n",
            "step 86 train accuracy is 1, total_loss is -100.253, inv_loss is 107.241, class_loss is 0.317608\n",
            "step 87 train accuracy is 1, total_loss is -111.409, inv_loss is 104.536, class_loss is 0.3226\n",
            "step 88 train accuracy is 1, total_loss is -114.449, inv_loss is 113.849, class_loss is 0.318659\n",
            "step 89 train accuracy is 1, total_loss is -112.563, inv_loss is 115.728, class_loss is 0.323261\n",
            "step 90 train accuracy is 1, total_loss is -116.969, inv_loss is 114.343, class_loss is 0.320913\n",
            "step 91 train accuracy is 1, total_loss is -107.96, inv_loss is 114.652, class_loss is 0.319337\n",
            "step 92 train accuracy is 1, total_loss is -117.087, inv_loss is 106.647, class_loss is 0.319785\n",
            "step 93 train accuracy is 1, total_loss is -110.446, inv_loss is 118.665, class_loss is 0.321046\n",
            "step 94 train accuracy is 1, total_loss is -100.286, inv_loss is 114.43, class_loss is 0.323208\n",
            "step 95 train accuracy is 1, total_loss is -110.906, inv_loss is 122.334, class_loss is 0.318658\n",
            "step 96 train accuracy is 1, total_loss is -109.445, inv_loss is 112.895, class_loss is 0.318324\n",
            "step 97 train accuracy is 1, total_loss is -117.185, inv_loss is 118.506, class_loss is 0.322345\n",
            "step 98 train accuracy is 1, total_loss is -118.288, inv_loss is 120.538, class_loss is 0.317542\n",
            "step 99 train accuracy is 1, total_loss is -110.514, inv_loss is 110.465, class_loss is 0.319897\n",
            "step 100 train accuracy is 1, total_loss is -111.64, inv_loss is 123.671, class_loss is 0.319312\n",
            "step 101 train accuracy is 1, total_loss is -112.923, inv_loss is 102.835, class_loss is 0.318649\n",
            "step 102 train accuracy is 1, total_loss is -121.134, inv_loss is 115.876, class_loss is 0.319562\n",
            "step 103 train accuracy is 1, total_loss is -120.81, inv_loss is 118.258, class_loss is 0.319133\n",
            "step 104 train accuracy is 1, total_loss is -112.142, inv_loss is 107.837, class_loss is 0.324575\n",
            "step 105 train accuracy is 1, total_loss is -115.997, inv_loss is 111.076, class_loss is 0.319046\n",
            "step 106 train accuracy is 1, total_loss is -115.345, inv_loss is 117.912, class_loss is 0.320545\n",
            "step 107 train accuracy is 1, total_loss is -113.263, inv_loss is 116.513, class_loss is 0.319069\n",
            "step 108 train accuracy is 1, total_loss is -117.367, inv_loss is 112.632, class_loss is 0.320533\n",
            "step 109 train accuracy is 1, total_loss is -117.625, inv_loss is 111.392, class_loss is 0.320645\n",
            "step 110 train accuracy is 1, total_loss is -111.206, inv_loss is 102.722, class_loss is 0.320794\n",
            "step 111 train accuracy is 1, total_loss is -100.255, inv_loss is 107.241, class_loss is 0.316712\n",
            "step 112 train accuracy is 1, total_loss is -111.41, inv_loss is 104.536, class_loss is 0.321005\n",
            "step 113 train accuracy is 1, total_loss is -114.45, inv_loss is 113.849, class_loss is 0.317523\n",
            "step 114 train accuracy is 1, total_loss is -112.564, inv_loss is 115.728, class_loss is 0.321723\n",
            "step 115 train accuracy is 1, total_loss is -116.97, inv_loss is 114.343, class_loss is 0.319591\n",
            "step 116 train accuracy is 1, total_loss is -107.961, inv_loss is 114.652, class_loss is 0.318209\n",
            "step 117 train accuracy is 1, total_loss is -117.088, inv_loss is 106.647, class_loss is 0.318586\n",
            "step 118 train accuracy is 1, total_loss is -110.447, inv_loss is 118.665, class_loss is 0.319696\n",
            "step 119 train accuracy is 1, total_loss is -100.287, inv_loss is 114.43, class_loss is 0.321669\n",
            "step 120 train accuracy is 1, total_loss is -110.907, inv_loss is 122.334, class_loss is 0.317786\n",
            "step 121 train accuracy is 1, total_loss is -109.447, inv_loss is 112.895, class_loss is 0.317355\n",
            "step 122 train accuracy is 1, total_loss is -117.185, inv_loss is 118.506, class_loss is 0.321306\n",
            "step 123 train accuracy is 1, total_loss is -118.289, inv_loss is 120.538, class_loss is 0.316745\n",
            "step 124 train accuracy is 1, total_loss is -110.515, inv_loss is 110.465, class_loss is 0.318831\n",
            "step 125 train accuracy is 1, total_loss is -111.641, inv_loss is 123.671, class_loss is 0.318312\n",
            "step 126 train accuracy is 1, total_loss is -112.924, inv_loss is 102.835, class_loss is 0.317703\n",
            "step 127 train accuracy is 1, total_loss is -121.135, inv_loss is 115.876, class_loss is 0.318584\n",
            "step 128 train accuracy is 1, total_loss is -120.811, inv_loss is 118.258, class_loss is 0.318277\n",
            "step 129 train accuracy is 1, total_loss is -112.144, inv_loss is 107.837, class_loss is 0.323471\n",
            "step 130 train accuracy is 1, total_loss is -115.998, inv_loss is 111.076, class_loss is 0.318293\n",
            "step 131 train accuracy is 1, total_loss is -115.346, inv_loss is 117.912, class_loss is 0.319531\n",
            "step 132 train accuracy is 1, total_loss is -113.264, inv_loss is 116.513, class_loss is 0.318073\n",
            "step 133 train accuracy is 1, total_loss is -117.368, inv_loss is 112.632, class_loss is 0.319523\n",
            "step 134 train accuracy is 1, total_loss is -117.626, inv_loss is 111.392, class_loss is 0.319669\n",
            "step 135 train accuracy is 1, total_loss is -111.207, inv_loss is 102.722, class_loss is 0.319889\n",
            "step 136 train accuracy is 1, total_loss is -100.256, inv_loss is 107.241, class_loss is 0.316142\n",
            "step 137 train accuracy is 1, total_loss is -111.411, inv_loss is 104.536, class_loss is 0.319929\n",
            "step 138 train accuracy is 1, total_loss is -114.451, inv_loss is 113.849, class_loss is 0.316783\n",
            "step 139 train accuracy is 1, total_loss is -112.565, inv_loss is 115.728, class_loss is 0.320669\n",
            "step 140 train accuracy is 1, total_loss is -116.97, inv_loss is 114.343, class_loss is 0.318716\n",
            "step 141 train accuracy is 1, total_loss is -107.962, inv_loss is 114.652, class_loss is 0.317453\n",
            "step 142 train accuracy is 1, total_loss is -117.089, inv_loss is 106.647, class_loss is 0.317787\n",
            "step 143 train accuracy is 1, total_loss is -110.448, inv_loss is 118.665, class_loss is 0.318788\n",
            "step 144 train accuracy is 1, total_loss is -100.287, inv_loss is 114.43, class_loss is 0.320596\n",
            "step 145 train accuracy is 1, total_loss is -110.908, inv_loss is 122.334, class_loss is 0.317202\n",
            "step 146 train accuracy is 1, total_loss is -109.447, inv_loss is 112.895, class_loss is 0.316705\n",
            "step 147 train accuracy is 1, total_loss is -117.186, inv_loss is 118.506, class_loss is 0.320593\n",
            "step 148 train accuracy is 1, total_loss is -118.29, inv_loss is 120.538, class_loss is 0.316207\n",
            "step 149 train accuracy is 1, total_loss is -110.516, inv_loss is 110.465, class_loss is 0.318107\n",
            "step 150 train accuracy is 1, total_loss is -111.641, inv_loss is 123.671, class_loss is 0.317626\n",
            "step 151 train accuracy is 1, total_loss is -112.925, inv_loss is 102.835, class_loss is 0.317049\n",
            "step 152 train accuracy is 1, total_loss is -121.136, inv_loss is 115.876, class_loss is 0.317912\n",
            "step 153 train accuracy is 1, total_loss is -120.811, inv_loss is 118.258, class_loss is 0.317693\n",
            "step 154 train accuracy is 1, total_loss is -112.145, inv_loss is 107.837, class_loss is 0.322676\n",
            "step 155 train accuracy is 1, total_loss is -115.999, inv_loss is 111.076, class_loss is 0.317771\n",
            "step 156 train accuracy is 1, total_loss is -115.347, inv_loss is 117.912, class_loss is 0.318816\n",
            "step 157 train accuracy is 1, total_loss is -113.264, inv_loss is 116.513, class_loss is 0.317373\n",
            "step 158 train accuracy is 1, total_loss is -117.368, inv_loss is 112.632, class_loss is 0.318797\n",
            "step 159 train accuracy is 1, total_loss is -117.626, inv_loss is 111.392, class_loss is 0.318977\n",
            "step 160 train accuracy is 1, total_loss is -111.208, inv_loss is 102.722, class_loss is 0.319235\n",
            "step 161 train accuracy is 1, total_loss is -100.257, inv_loss is 107.241, class_loss is 0.315747\n",
            "step 162 train accuracy is 1, total_loss is -111.411, inv_loss is 104.536, class_loss is 0.319147\n",
            "step 163 train accuracy is 1, total_loss is -114.452, inv_loss is 113.849, class_loss is 0.316262\n",
            "step 164 train accuracy is 1, total_loss is -112.566, inv_loss is 115.728, class_loss is 0.319894\n",
            "step 165 train accuracy is 1, total_loss is -116.971, inv_loss is 114.343, class_loss is 0.318093\n",
            "step 166 train accuracy is 1, total_loss is -107.963, inv_loss is 114.652, class_loss is 0.316907\n",
            "step 167 train accuracy is 1, total_loss is -117.09, inv_loss is 106.647, class_loss is 0.317214\n",
            "step 168 train accuracy is 1, total_loss is -110.449, inv_loss is 118.665, class_loss is 0.318134\n",
            "step 169 train accuracy is 1, total_loss is -100.288, inv_loss is 114.43, class_loss is 0.319798\n",
            "step 170 train accuracy is 1, total_loss is -110.908, inv_loss is 122.334, class_loss is 0.316782\n",
            "step 171 train accuracy is 1, total_loss is -109.448, inv_loss is 112.895, class_loss is 0.316237\n",
            "step 172 train accuracy is 1, total_loss is -117.186, inv_loss is 118.506, class_loss is 0.320068\n",
            "step 173 train accuracy is 1, total_loss is -118.29, inv_loss is 120.538, class_loss is 0.315819\n",
            "step 174 train accuracy is 1, total_loss is -110.516, inv_loss is 110.465, class_loss is 0.31758\n",
            "step 175 train accuracy is 1, total_loss is -111.642, inv_loss is 123.671, class_loss is 0.317125\n",
            "step 176 train accuracy is 1, total_loss is -112.925, inv_loss is 102.835, class_loss is 0.316568\n",
            "step 177 train accuracy is 1, total_loss is -121.137, inv_loss is 115.876, class_loss is 0.317418\n",
            "step 178 train accuracy is 1, total_loss is -120.812, inv_loss is 118.258, class_loss is 0.31727\n",
            "step 179 train accuracy is 1, total_loss is -112.145, inv_loss is 107.837, class_loss is 0.32207\n",
            "step 180 train accuracy is 1, total_loss is -115.999, inv_loss is 111.076, class_loss is 0.317386\n",
            "step 181 train accuracy is 1, total_loss is -115.348, inv_loss is 117.912, class_loss is 0.318281\n",
            "step 182 train accuracy is 1, total_loss is -113.265, inv_loss is 116.513, class_loss is 0.316854\n",
            "step 183 train accuracy is 1, total_loss is -117.369, inv_loss is 112.632, class_loss is 0.318247\n",
            "step 184 train accuracy is 1, total_loss is -117.627, inv_loss is 111.392, class_loss is 0.318458\n",
            "step 185 train accuracy is 1, total_loss is -111.209, inv_loss is 102.722, class_loss is 0.318737\n",
            "step 186 train accuracy is 1, total_loss is -100.258, inv_loss is 107.241, class_loss is 0.315457\n",
            "step 187 train accuracy is 1, total_loss is -111.412, inv_loss is 104.536, class_loss is 0.31855\n",
            "step 188 train accuracy is 1, total_loss is -114.452, inv_loss is 113.849, class_loss is 0.315875\n",
            "step 189 train accuracy is 1, total_loss is -112.566, inv_loss is 115.728, class_loss is 0.319296\n",
            "step 190 train accuracy is 1, total_loss is -116.971, inv_loss is 114.343, class_loss is 0.317625\n",
            "step 191 train accuracy is 1, total_loss is -107.963, inv_loss is 114.652, class_loss is 0.316493\n",
            "step 192 train accuracy is 1, total_loss is -117.09, inv_loss is 106.647, class_loss is 0.316783\n",
            "step 193 train accuracy is 1, total_loss is -110.449, inv_loss is 118.665, class_loss is 0.317639\n",
            "step 194 train accuracy is 1, total_loss is -100.288, inv_loss is 114.43, class_loss is 0.319178\n",
            "step 195 train accuracy is 1, total_loss is -110.909, inv_loss is 122.334, class_loss is 0.316464\n",
            "step 196 train accuracy is 1, total_loss is -109.449, inv_loss is 112.895, class_loss is 0.315884\n",
            "step 197 train accuracy is 1, total_loss is -117.187, inv_loss is 118.506, class_loss is 0.319663\n",
            "step 198 train accuracy is 1, total_loss is -118.291, inv_loss is 120.538, class_loss is 0.315524\n",
            "step 199 train accuracy is 1, total_loss is -110.517, inv_loss is 110.465, class_loss is 0.31718\n",
            "beta is 1, test accuracy is 1\n",
            "Training...\n",
            "step 0 train accuracy is 0.99, total_loss is -223.396, inv_loss is 123.671, class_loss is 0.524549\n",
            "step 1 train accuracy is 1, total_loss is -226.029, inv_loss is 102.835, class_loss is 0.447879\n",
            "step 2 train accuracy is 0.98, total_loss is -242.492, inv_loss is 115.876, class_loss is 0.424172\n",
            "step 3 train accuracy is 1, total_loss is -241.867, inv_loss is 118.258, class_loss is 0.398682\n",
            "step 4 train accuracy is 1, total_loss is -224.535, inv_loss is 107.837, class_loss is 0.39172\n",
            "step 5 train accuracy is 1, total_loss is -232.257, inv_loss is 111.076, class_loss is 0.370208\n",
            "step 6 train accuracy is 1, total_loss is -230.961, inv_loss is 117.912, class_loss is 0.37163\n",
            "step 7 train accuracy is 1, total_loss is -226.797, inv_loss is 116.513, class_loss is 0.365356\n",
            "step 8 train accuracy is 0.99, total_loss is -235.015, inv_loss is 112.632, class_loss is 0.360448\n",
            "step 9 train accuracy is 1, total_loss is -235.532, inv_loss is 111.392, class_loss is 0.35926\n",
            "step 10 train accuracy is 1, total_loss is -222.696, inv_loss is 102.722, class_loss is 0.353192\n",
            "step 11 train accuracy is 0.99, total_loss is -200.798, inv_loss is 107.241, class_loss is 0.341093\n",
            "step 12 train accuracy is 1, total_loss is -223.114, inv_loss is 104.536, class_loss is 0.352631\n",
            "step 13 train accuracy is 1, total_loss is -229.193, inv_loss is 113.849, class_loss is 0.342696\n",
            "step 14 train accuracy is 1, total_loss is -225.426, inv_loss is 115.728, class_loss is 0.348495\n",
            "step 15 train accuracy is 1, total_loss is -234.237, inv_loss is 114.343, class_loss is 0.344838\n",
            "step 16 train accuracy is 1, total_loss is -216.218, inv_loss is 114.652, class_loss is 0.338635\n",
            "step 17 train accuracy is 1, total_loss is -234.475, inv_loss is 106.647, class_loss is 0.339774\n",
            "step 18 train accuracy is 1, total_loss is -221.194, inv_loss is 118.665, class_loss is 0.342162\n",
            "step 19 train accuracy is 1, total_loss is -200.873, inv_loss is 114.43, class_loss is 0.34367\n",
            "step 20 train accuracy is 0.99, total_loss is -222.117, inv_loss is 122.334, class_loss is 0.332545\n",
            "step 21 train accuracy is 1, total_loss is -219.199, inv_loss is 112.895, class_loss is 0.332893\n",
            "step 22 train accuracy is 1, total_loss is -234.676, inv_loss is 118.506, class_loss is 0.336813\n",
            "step 23 train accuracy is 1, total_loss is -236.882, inv_loss is 120.538, class_loss is 0.328996\n",
            "step 24 train accuracy is 1, total_loss is -221.333, inv_loss is 110.465, class_loss is 0.334211\n",
            "step 25 train accuracy is 1, total_loss is -223.587, inv_loss is 123.671, class_loss is 0.332229\n",
            "step 26 train accuracy is 1, total_loss is -226.153, inv_loss is 102.835, class_loss is 0.330224\n",
            "step 27 train accuracy is 0.99, total_loss is -242.578, inv_loss is 115.876, class_loss is 0.331726\n",
            "step 28 train accuracy is 1, total_loss is -241.929, inv_loss is 118.258, class_loss is 0.329841\n",
            "step 29 train accuracy is 1, total_loss is -224.594, inv_loss is 107.837, class_loss is 0.336136\n",
            "step 30 train accuracy is 1, total_loss is -232.303, inv_loss is 111.076, class_loss is 0.327828\n",
            "step 31 train accuracy is 1, total_loss is -231.001, inv_loss is 117.912, class_loss is 0.331359\n",
            "step 32 train accuracy is 1, total_loss is -226.834, inv_loss is 116.513, class_loss is 0.329637\n",
            "step 33 train accuracy is 1, total_loss is -235.044, inv_loss is 112.632, class_loss is 0.330447\n",
            "step 34 train accuracy is 1, total_loss is -235.559, inv_loss is 111.392, class_loss is 0.330573\n",
            "step 35 train accuracy is 1, total_loss is -222.723, inv_loss is 102.722, class_loss is 0.329552\n",
            "step 36 train accuracy is 0.99, total_loss is -200.822, inv_loss is 107.241, class_loss is 0.32295\n",
            "step 37 train accuracy is 1, total_loss is -223.132, inv_loss is 104.536, class_loss is 0.330812\n",
            "step 38 train accuracy is 1, total_loss is -229.211, inv_loss is 113.849, class_loss is 0.324953\n",
            "step 39 train accuracy is 1, total_loss is -225.443, inv_loss is 115.728, class_loss is 0.330805\n",
            "step 40 train accuracy is 1, total_loss is -234.251, inv_loss is 114.343, class_loss is 0.327855\n",
            "step 41 train accuracy is 1, total_loss is -216.234, inv_loss is 114.652, class_loss is 0.325086\n",
            "step 42 train accuracy is 1, total_loss is -234.488, inv_loss is 106.647, class_loss is 0.325915\n",
            "step 43 train accuracy is 1, total_loss is -221.206, inv_loss is 118.665, class_loss is 0.327775\n",
            "step 44 train accuracy is 1, total_loss is -200.885, inv_loss is 114.43, class_loss is 0.330256\n",
            "step 45 train accuracy is 1, total_loss is -222.127, inv_loss is 122.334, class_loss is 0.323067\n",
            "step 46 train accuracy is 1, total_loss is -219.21, inv_loss is 112.895, class_loss is 0.323127\n",
            "step 47 train accuracy is 1, total_loss is -234.684, inv_loss is 118.506, class_loss is 0.327284\n",
            "step 48 train accuracy is 1, total_loss is -236.891, inv_loss is 120.538, class_loss is 0.321427\n",
            "step 49 train accuracy is 1, total_loss is -221.342, inv_loss is 110.465, class_loss is 0.324955\n",
            "step 50 train accuracy is 1, total_loss is -223.595, inv_loss is 123.671, class_loss is 0.323971\n",
            "step 51 train accuracy is 1, total_loss is -226.162, inv_loss is 102.835, class_loss is 0.322941\n",
            "step 52 train accuracy is 1, total_loss is -242.586, inv_loss is 115.876, class_loss is 0.324053\n",
            "step 53 train accuracy is 1, total_loss is -241.934, inv_loss is 118.258, class_loss is 0.323108\n",
            "step 54 train accuracy is 1, total_loss is -224.601, inv_loss is 107.837, class_loss is 0.329179\n",
            "step 55 train accuracy is 1, total_loss is -232.309, inv_loss is 111.076, class_loss is 0.322413\n",
            "step 56 train accuracy is 1, total_loss is -231.008, inv_loss is 117.912, class_loss is 0.324881\n",
            "step 57 train accuracy is 1, total_loss is -226.841, inv_loss is 116.513, class_loss is 0.323336\n",
            "step 58 train accuracy is 1, total_loss is -235.049, inv_loss is 112.632, class_loss is 0.324661\n",
            "step 59 train accuracy is 1, total_loss is -235.565, inv_loss is 111.392, class_loss is 0.324737\n",
            "step 60 train accuracy is 1, total_loss is -222.729, inv_loss is 102.722, class_loss is 0.324469\n",
            "step 61 train accuracy is 0.99, total_loss is -200.828, inv_loss is 107.241, class_loss is 0.319218\n",
            "step 62 train accuracy is 1, total_loss is -223.136, inv_loss is 104.536, class_loss is 0.325261\n",
            "step 63 train accuracy is 1, total_loss is -229.215, inv_loss is 113.849, class_loss is 0.320633\n",
            "step 64 train accuracy is 1, total_loss is -225.447, inv_loss is 115.728, class_loss is 0.325769\n",
            "step 65 train accuracy is 1, total_loss is -234.254, inv_loss is 114.343, class_loss is 0.323155\n",
            "step 66 train accuracy is 1, total_loss is -216.238, inv_loss is 114.652, class_loss is 0.321218\n",
            "step 67 train accuracy is 1, total_loss is -234.492, inv_loss is 106.647, class_loss is 0.321795\n",
            "step 68 train accuracy is 1, total_loss is -221.21, inv_loss is 118.665, class_loss is 0.323282\n",
            "step 69 train accuracy is 1, total_loss is -200.889, inv_loss is 114.43, class_loss is 0.325645\n",
            "step 70 train accuracy is 1, total_loss is -222.131, inv_loss is 122.334, class_loss is 0.320114\n",
            "step 71 train accuracy is 1, total_loss is -219.214, inv_loss is 112.895, class_loss is 0.319928\n",
            "step 72 train accuracy is 1, total_loss is -234.687, inv_loss is 118.506, class_loss is 0.324025\n",
            "step 73 train accuracy is 1, total_loss is -236.895, inv_loss is 120.538, class_loss is 0.318852\n",
            "step 74 train accuracy is 1, total_loss is -221.345, inv_loss is 110.465, class_loss is 0.321627\n",
            "step 75 train accuracy is 1, total_loss is -223.598, inv_loss is 123.671, class_loss is 0.32092\n",
            "step 76 train accuracy is 1, total_loss is -226.165, inv_loss is 102.835, class_loss is 0.32015\n",
            "step 77 train accuracy is 1, total_loss is -242.589, inv_loss is 115.876, class_loss is 0.321124\n",
            "step 78 train accuracy is 1, total_loss is -241.936, inv_loss is 118.258, class_loss is 0.320513\n",
            "step 79 train accuracy is 1, total_loss is -224.605, inv_loss is 107.837, class_loss is 0.326247\n",
            "step 80 train accuracy is 1, total_loss is -232.311, inv_loss is 111.076, class_loss is 0.320234\n",
            "step 81 train accuracy is 1, total_loss is -231.011, inv_loss is 117.912, class_loss is 0.322109\n",
            "step 82 train accuracy is 1, total_loss is -226.844, inv_loss is 116.513, class_loss is 0.320609\n",
            "step 83 train accuracy is 1, total_loss is -235.051, inv_loss is 112.632, class_loss is 0.322054\n",
            "step 84 train accuracy is 1, total_loss is -235.567, inv_loss is 111.392, class_loss is 0.322137\n",
            "step 85 train accuracy is 1, total_loss is -222.731, inv_loss is 102.722, class_loss is 0.322152\n",
            "step 86 train accuracy is 1, total_loss is -200.831, inv_loss is 107.241, class_loss is 0.317608\n",
            "step 87 train accuracy is 1, total_loss is -223.137, inv_loss is 104.536, class_loss is 0.3226\n",
            "step 88 train accuracy is 1, total_loss is -229.217, inv_loss is 113.849, class_loss is 0.318659\n",
            "step 89 train accuracy is 1, total_loss is -225.449, inv_loss is 115.728, class_loss is 0.323261\n",
            "step 90 train accuracy is 1, total_loss is -234.256, inv_loss is 114.343, class_loss is 0.320913\n",
            "step 91 train accuracy is 1, total_loss is -216.24, inv_loss is 114.652, class_loss is 0.319337\n",
            "step 92 train accuracy is 1, total_loss is -234.494, inv_loss is 106.647, class_loss is 0.319785\n",
            "step 93 train accuracy is 1, total_loss is -221.211, inv_loss is 118.665, class_loss is 0.321046\n",
            "step 94 train accuracy is 1, total_loss is -200.891, inv_loss is 114.43, class_loss is 0.323208\n",
            "step 95 train accuracy is 1, total_loss is -222.132, inv_loss is 122.334, class_loss is 0.318658\n",
            "step 96 train accuracy is 1, total_loss is -219.216, inv_loss is 112.895, class_loss is 0.318324\n",
            "step 97 train accuracy is 1, total_loss is -234.689, inv_loss is 118.506, class_loss is 0.322345\n",
            "step 98 train accuracy is 1, total_loss is -236.897, inv_loss is 120.538, class_loss is 0.317542\n",
            "step 99 train accuracy is 1, total_loss is -221.347, inv_loss is 110.465, class_loss is 0.319897\n",
            "step 100 train accuracy is 1, total_loss is -223.6, inv_loss is 123.671, class_loss is 0.319312\n",
            "step 101 train accuracy is 1, total_loss is -226.167, inv_loss is 102.835, class_loss is 0.318649\n",
            "step 102 train accuracy is 1, total_loss is -242.59, inv_loss is 115.876, class_loss is 0.319562\n",
            "step 103 train accuracy is 1, total_loss is -241.937, inv_loss is 118.258, class_loss is 0.319133\n",
            "step 104 train accuracy is 1, total_loss is -224.606, inv_loss is 107.837, class_loss is 0.324575\n",
            "step 105 train accuracy is 1, total_loss is -232.312, inv_loss is 111.076, class_loss is 0.319046\n",
            "step 106 train accuracy is 1, total_loss is -231.012, inv_loss is 117.912, class_loss is 0.320545\n",
            "step 107 train accuracy is 1, total_loss is -226.845, inv_loss is 116.513, class_loss is 0.319069\n",
            "step 108 train accuracy is 1, total_loss is -235.052, inv_loss is 112.632, class_loss is 0.320533\n",
            "step 109 train accuracy is 1, total_loss is -235.569, inv_loss is 111.392, class_loss is 0.320645\n",
            "step 110 train accuracy is 1, total_loss is -222.733, inv_loss is 102.722, class_loss is 0.320794\n",
            "step 111 train accuracy is 1, total_loss is -200.832, inv_loss is 107.241, class_loss is 0.316712\n",
            "step 112 train accuracy is 1, total_loss is -223.138, inv_loss is 104.536, class_loss is 0.321005\n",
            "step 113 train accuracy is 1, total_loss is -229.218, inv_loss is 113.849, class_loss is 0.317523\n",
            "step 114 train accuracy is 1, total_loss is -225.45, inv_loss is 115.728, class_loss is 0.321723\n",
            "step 115 train accuracy is 1, total_loss is -234.257, inv_loss is 114.343, class_loss is 0.319591\n",
            "step 116 train accuracy is 1, total_loss is -216.241, inv_loss is 114.652, class_loss is 0.318209\n",
            "step 117 train accuracy is 1, total_loss is -234.495, inv_loss is 106.647, class_loss is 0.318586\n",
            "step 118 train accuracy is 1, total_loss is -221.212, inv_loss is 118.665, class_loss is 0.319696\n",
            "step 119 train accuracy is 1, total_loss is -200.892, inv_loss is 114.43, class_loss is 0.321669\n",
            "step 120 train accuracy is 1, total_loss is -222.133, inv_loss is 122.334, class_loss is 0.317786\n",
            "step 121 train accuracy is 1, total_loss is -219.217, inv_loss is 112.895, class_loss is 0.317355\n",
            "step 122 train accuracy is 1, total_loss is -234.689, inv_loss is 118.506, class_loss is 0.321306\n",
            "step 123 train accuracy is 1, total_loss is -236.898, inv_loss is 120.538, class_loss is 0.316745\n",
            "step 124 train accuracy is 1, total_loss is -221.348, inv_loss is 110.465, class_loss is 0.318831\n",
            "step 125 train accuracy is 1, total_loss is -223.601, inv_loss is 123.671, class_loss is 0.318312\n",
            "step 126 train accuracy is 1, total_loss is -226.168, inv_loss is 102.835, class_loss is 0.317703\n",
            "step 127 train accuracy is 1, total_loss is -242.591, inv_loss is 115.876, class_loss is 0.318584\n",
            "step 128 train accuracy is 1, total_loss is -241.938, inv_loss is 118.258, class_loss is 0.318277\n",
            "step 129 train accuracy is 1, total_loss is -224.608, inv_loss is 107.837, class_loss is 0.323471\n",
            "step 130 train accuracy is 1, total_loss is -232.313, inv_loss is 111.076, class_loss is 0.318293\n",
            "step 131 train accuracy is 1, total_loss is -231.014, inv_loss is 117.912, class_loss is 0.319531\n",
            "step 132 train accuracy is 1, total_loss is -226.846, inv_loss is 116.513, class_loss is 0.318073\n",
            "step 133 train accuracy is 1, total_loss is -235.053, inv_loss is 112.632, class_loss is 0.319523\n",
            "step 134 train accuracy is 1, total_loss is -235.569, inv_loss is 111.392, class_loss is 0.319669\n",
            "step 135 train accuracy is 1, total_loss is -222.734, inv_loss is 102.722, class_loss is 0.319889\n",
            "step 136 train accuracy is 1, total_loss is -200.834, inv_loss is 107.241, class_loss is 0.316142\n",
            "step 137 train accuracy is 1, total_loss is -223.139, inv_loss is 104.536, class_loss is 0.319929\n",
            "step 138 train accuracy is 1, total_loss is -229.219, inv_loss is 113.849, class_loss is 0.316783\n",
            "step 139 train accuracy is 1, total_loss is -225.451, inv_loss is 115.728, class_loss is 0.320669\n",
            "step 140 train accuracy is 1, total_loss is -234.257, inv_loss is 114.343, class_loss is 0.318716\n",
            "step 141 train accuracy is 1, total_loss is -216.242, inv_loss is 114.652, class_loss is 0.317453\n",
            "step 142 train accuracy is 1, total_loss is -234.496, inv_loss is 106.647, class_loss is 0.317787\n",
            "step 143 train accuracy is 1, total_loss is -221.213, inv_loss is 118.665, class_loss is 0.318788\n",
            "step 144 train accuracy is 1, total_loss is -200.893, inv_loss is 114.43, class_loss is 0.320596\n",
            "step 145 train accuracy is 1, total_loss is -222.134, inv_loss is 122.334, class_loss is 0.317202\n",
            "step 146 train accuracy is 1, total_loss is -219.218, inv_loss is 112.895, class_loss is 0.316705\n",
            "step 147 train accuracy is 1, total_loss is -234.69, inv_loss is 118.506, class_loss is 0.320593\n",
            "step 148 train accuracy is 1, total_loss is -236.898, inv_loss is 120.538, class_loss is 0.316207\n",
            "step 149 train accuracy is 1, total_loss is -221.349, inv_loss is 110.465, class_loss is 0.318107\n",
            "step 150 train accuracy is 1, total_loss is -223.602, inv_loss is 123.671, class_loss is 0.317626\n",
            "step 151 train accuracy is 1, total_loss is -226.169, inv_loss is 102.835, class_loss is 0.317049\n",
            "step 152 train accuracy is 1, total_loss is -242.592, inv_loss is 115.876, class_loss is 0.317912\n",
            "step 153 train accuracy is 1, total_loss is -241.938, inv_loss is 118.258, class_loss is 0.317693\n",
            "step 154 train accuracy is 1, total_loss is -224.608, inv_loss is 107.837, class_loss is 0.322676\n",
            "step 155 train accuracy is 1, total_loss is -232.314, inv_loss is 111.076, class_loss is 0.317771\n",
            "step 156 train accuracy is 1, total_loss is -231.014, inv_loss is 117.912, class_loss is 0.318816\n",
            "step 157 train accuracy is 1, total_loss is -226.847, inv_loss is 116.513, class_loss is 0.317373\n",
            "step 158 train accuracy is 1, total_loss is -235.054, inv_loss is 112.632, class_loss is 0.318797\n",
            "step 159 train accuracy is 1, total_loss is -235.57, inv_loss is 111.392, class_loss is 0.318977\n",
            "step 160 train accuracy is 1, total_loss is -222.735, inv_loss is 102.722, class_loss is 0.319235\n",
            "step 161 train accuracy is 1, total_loss is -200.835, inv_loss is 107.241, class_loss is 0.315747\n",
            "step 162 train accuracy is 1, total_loss is -223.14, inv_loss is 104.536, class_loss is 0.319147\n",
            "step 163 train accuracy is 1, total_loss is -229.219, inv_loss is 113.849, class_loss is 0.316262\n",
            "step 164 train accuracy is 1, total_loss is -225.452, inv_loss is 115.728, class_loss is 0.319894\n",
            "step 165 train accuracy is 1, total_loss is -234.258, inv_loss is 114.343, class_loss is 0.318093\n",
            "step 166 train accuracy is 1, total_loss is -216.243, inv_loss is 114.652, class_loss is 0.316907\n",
            "step 167 train accuracy is 1, total_loss is -234.497, inv_loss is 106.647, class_loss is 0.317214\n",
            "step 168 train accuracy is 1, total_loss is -221.214, inv_loss is 118.665, class_loss is 0.318134\n",
            "step 169 train accuracy is 1, total_loss is -200.893, inv_loss is 114.43, class_loss is 0.319798\n",
            "step 170 train accuracy is 1, total_loss is -222.134, inv_loss is 122.334, class_loss is 0.316782\n",
            "step 171 train accuracy is 1, total_loss is -219.218, inv_loss is 112.895, class_loss is 0.316237\n",
            "step 172 train accuracy is 1, total_loss is -234.69, inv_loss is 118.506, class_loss is 0.320068\n",
            "step 173 train accuracy is 1, total_loss is -236.899, inv_loss is 120.538, class_loss is 0.315819\n",
            "step 174 train accuracy is 1, total_loss is -221.35, inv_loss is 110.465, class_loss is 0.31758\n",
            "step 175 train accuracy is 1, total_loss is -223.603, inv_loss is 123.671, class_loss is 0.317125\n",
            "step 176 train accuracy is 1, total_loss is -226.169, inv_loss is 102.835, class_loss is 0.316568\n",
            "step 177 train accuracy is 1, total_loss is -242.592, inv_loss is 115.876, class_loss is 0.317418\n",
            "step 178 train accuracy is 1, total_loss is -241.939, inv_loss is 118.258, class_loss is 0.31727\n",
            "step 179 train accuracy is 1, total_loss is -224.609, inv_loss is 107.837, class_loss is 0.32207\n",
            "step 180 train accuracy is 1, total_loss is -232.314, inv_loss is 111.076, class_loss is 0.317386\n",
            "step 181 train accuracy is 1, total_loss is -231.015, inv_loss is 117.912, class_loss is 0.318281\n",
            "step 182 train accuracy is 1, total_loss is -226.847, inv_loss is 116.513, class_loss is 0.316854\n",
            "step 183 train accuracy is 1, total_loss is -235.054, inv_loss is 112.632, class_loss is 0.318247\n",
            "step 184 train accuracy is 1, total_loss is -235.571, inv_loss is 111.392, class_loss is 0.318458\n",
            "step 185 train accuracy is 1, total_loss is -222.735, inv_loss is 102.722, class_loss is 0.318737\n",
            "step 186 train accuracy is 1, total_loss is -200.835, inv_loss is 107.241, class_loss is 0.315457\n",
            "step 187 train accuracy is 1, total_loss is -223.14, inv_loss is 104.536, class_loss is 0.31855\n",
            "step 188 train accuracy is 1, total_loss is -229.22, inv_loss is 113.849, class_loss is 0.315875\n",
            "step 189 train accuracy is 1, total_loss is -225.452, inv_loss is 115.728, class_loss is 0.319296\n",
            "step 190 train accuracy is 1, total_loss is -234.258, inv_loss is 114.343, class_loss is 0.317625\n",
            "step 191 train accuracy is 1, total_loss is -216.243, inv_loss is 114.652, class_loss is 0.316493\n",
            "step 192 train accuracy is 1, total_loss is -234.497, inv_loss is 106.647, class_loss is 0.316783\n",
            "step 193 train accuracy is 1, total_loss is -221.214, inv_loss is 118.665, class_loss is 0.317639\n",
            "step 194 train accuracy is 1, total_loss is -200.894, inv_loss is 114.43, class_loss is 0.319178\n",
            "step 195 train accuracy is 1, total_loss is -222.135, inv_loss is 122.334, class_loss is 0.316464\n",
            "step 196 train accuracy is 1, total_loss is -219.219, inv_loss is 112.895, class_loss is 0.315884\n",
            "step 197 train accuracy is 1, total_loss is -234.691, inv_loss is 118.506, class_loss is 0.319663\n",
            "step 198 train accuracy is 1, total_loss is -236.9, inv_loss is 120.538, class_loss is 0.315524\n",
            "step 199 train accuracy is 1, total_loss is -221.35, inv_loss is 110.465, class_loss is 0.31718\n",
            "beta is 2, test accuracy is 1\n",
            "Training...\n",
            "step 0 train accuracy is 0.99, total_loss is -559.277, inv_loss is 123.671, class_loss is 0.524549\n",
            "step 1 train accuracy is 1, total_loss is -565.76, inv_loss is 102.835, class_loss is 0.447879\n",
            "step 2 train accuracy is 0.98, total_loss is -606.859, inv_loss is 115.876, class_loss is 0.424172\n",
            "step 3 train accuracy is 1, total_loss is -605.248, inv_loss is 118.258, class_loss is 0.398682\n",
            "step 4 train accuracy is 1, total_loss is -561.927, inv_loss is 107.837, class_loss is 0.39172\n",
            "step 5 train accuracy is 1, total_loss is -581.202, inv_loss is 111.076, class_loss is 0.370208\n",
            "step 6 train accuracy is 1, total_loss is -577.963, inv_loss is 117.912, class_loss is 0.37163\n",
            "step 7 train accuracy is 1, total_loss is -567.545, inv_loss is 116.513, class_loss is 0.365356\n",
            "step 8 train accuracy is 0.99, total_loss is -588.072, inv_loss is 112.632, class_loss is 0.360448\n",
            "step 9 train accuracy is 1, total_loss is -589.363, inv_loss is 111.392, class_loss is 0.35926\n",
            "step 10 train accuracy is 1, total_loss is -557.275, inv_loss is 102.722, class_loss is 0.353192\n",
            "step 11 train accuracy is 0.99, total_loss is -502.53, inv_loss is 107.241, class_loss is 0.341093\n",
            "step 12 train accuracy is 1, total_loss is -558.298, inv_loss is 104.536, class_loss is 0.352631\n",
            "step 13 train accuracy is 1, total_loss is -573.497, inv_loss is 113.849, class_loss is 0.342696\n",
            "step 14 train accuracy is 1, total_loss is -564.084, inv_loss is 115.728, class_loss is 0.348495\n",
            "step 15 train accuracy is 1, total_loss is -586.098, inv_loss is 114.343, class_loss is 0.344838\n",
            "step 16 train accuracy is 1, total_loss is -541.059, inv_loss is 114.652, class_loss is 0.338635\n",
            "step 17 train accuracy is 1, total_loss is -586.696, inv_loss is 106.647, class_loss is 0.339774\n",
            "step 18 train accuracy is 1, total_loss is -553.49, inv_loss is 118.665, class_loss is 0.342162\n",
            "step 19 train accuracy is 1, total_loss is -502.69, inv_loss is 114.43, class_loss is 0.34367\n",
            "step 20 train accuracy is 0.99, total_loss is -555.794, inv_loss is 122.334, class_loss is 0.332545\n",
            "step 21 train accuracy is 1, total_loss is -548.51, inv_loss is 112.895, class_loss is 0.332893\n",
            "step 22 train accuracy is 1, total_loss is -587.188, inv_loss is 118.506, class_loss is 0.336813\n",
            "step 23 train accuracy is 1, total_loss is -592.708, inv_loss is 120.538, class_loss is 0.328996\n",
            "step 24 train accuracy is 1, total_loss is -553.832, inv_loss is 110.465, class_loss is 0.334211\n",
            "step 25 train accuracy is 1, total_loss is -559.468, inv_loss is 123.671, class_loss is 0.332229\n",
            "step 26 train accuracy is 1, total_loss is -565.885, inv_loss is 102.835, class_loss is 0.330224\n",
            "step 27 train accuracy is 0.99, total_loss is -606.945, inv_loss is 115.876, class_loss is 0.331726\n",
            "step 28 train accuracy is 1, total_loss is -605.31, inv_loss is 118.258, class_loss is 0.329841\n",
            "step 29 train accuracy is 1, total_loss is -561.985, inv_loss is 107.837, class_loss is 0.336136\n",
            "step 30 train accuracy is 1, total_loss is -581.248, inv_loss is 111.076, class_loss is 0.327828\n",
            "step 31 train accuracy is 1, total_loss is -578.003, inv_loss is 117.912, class_loss is 0.331359\n",
            "step 32 train accuracy is 1, total_loss is -567.582, inv_loss is 116.513, class_loss is 0.329637\n",
            "step 33 train accuracy is 1, total_loss is -588.1, inv_loss is 112.632, class_loss is 0.330447\n",
            "step 34 train accuracy is 1, total_loss is -589.39, inv_loss is 111.392, class_loss is 0.330573\n",
            "step 35 train accuracy is 1, total_loss is -557.302, inv_loss is 102.722, class_loss is 0.329552\n",
            "step 36 train accuracy is 0.99, total_loss is -502.554, inv_loss is 107.241, class_loss is 0.32295\n",
            "step 37 train accuracy is 1, total_loss is -558.316, inv_loss is 104.536, class_loss is 0.330812\n",
            "step 38 train accuracy is 1, total_loss is -573.515, inv_loss is 113.849, class_loss is 0.324953\n",
            "step 39 train accuracy is 1, total_loss is -564.1, inv_loss is 115.728, class_loss is 0.330805\n",
            "step 40 train accuracy is 1, total_loss is -586.111, inv_loss is 114.343, class_loss is 0.327855\n",
            "step 41 train accuracy is 1, total_loss is -541.075, inv_loss is 114.652, class_loss is 0.325086\n",
            "step 42 train accuracy is 1, total_loss is -586.709, inv_loss is 106.647, class_loss is 0.325915\n",
            "step 43 train accuracy is 1, total_loss is -553.502, inv_loss is 118.665, class_loss is 0.327775\n",
            "step 44 train accuracy is 1, total_loss is -502.702, inv_loss is 114.43, class_loss is 0.330256\n",
            "step 45 train accuracy is 1, total_loss is -555.805, inv_loss is 122.334, class_loss is 0.323067\n",
            "step 46 train accuracy is 1, total_loss is -548.521, inv_loss is 112.895, class_loss is 0.323127\n",
            "step 47 train accuracy is 1, total_loss is -587.196, inv_loss is 118.506, class_loss is 0.327284\n",
            "step 48 train accuracy is 1, total_loss is -592.717, inv_loss is 120.538, class_loss is 0.321427\n",
            "step 49 train accuracy is 1, total_loss is -553.842, inv_loss is 110.465, class_loss is 0.324955\n",
            "step 50 train accuracy is 1, total_loss is -559.477, inv_loss is 123.671, class_loss is 0.323971\n",
            "step 51 train accuracy is 1, total_loss is -565.893, inv_loss is 102.835, class_loss is 0.322941\n",
            "step 52 train accuracy is 1, total_loss is -606.953, inv_loss is 115.876, class_loss is 0.324053\n",
            "step 53 train accuracy is 1, total_loss is -605.315, inv_loss is 118.258, class_loss is 0.323108\n",
            "step 54 train accuracy is 1, total_loss is -561.993, inv_loss is 107.837, class_loss is 0.329179\n",
            "step 55 train accuracy is 1, total_loss is -581.254, inv_loss is 111.076, class_loss is 0.322413\n",
            "step 56 train accuracy is 1, total_loss is -578.01, inv_loss is 117.912, class_loss is 0.324881\n",
            "step 57 train accuracy is 1, total_loss is -567.589, inv_loss is 116.513, class_loss is 0.323336\n",
            "step 58 train accuracy is 1, total_loss is -588.105, inv_loss is 112.632, class_loss is 0.324661\n",
            "step 59 train accuracy is 1, total_loss is -589.396, inv_loss is 111.392, class_loss is 0.324737\n",
            "step 60 train accuracy is 1, total_loss is -557.308, inv_loss is 102.722, class_loss is 0.324469\n",
            "step 61 train accuracy is 0.99, total_loss is -502.56, inv_loss is 107.241, class_loss is 0.319218\n",
            "step 62 train accuracy is 1, total_loss is -558.32, inv_loss is 104.536, class_loss is 0.325261\n",
            "step 63 train accuracy is 1, total_loss is -573.519, inv_loss is 113.849, class_loss is 0.320633\n",
            "step 64 train accuracy is 1, total_loss is -564.105, inv_loss is 115.728, class_loss is 0.325769\n",
            "step 65 train accuracy is 1, total_loss is -586.115, inv_loss is 114.343, class_loss is 0.323155\n",
            "step 66 train accuracy is 1, total_loss is -541.079, inv_loss is 114.652, class_loss is 0.321218\n",
            "step 67 train accuracy is 1, total_loss is -586.713, inv_loss is 106.647, class_loss is 0.321795\n",
            "step 68 train accuracy is 1, total_loss is -553.505, inv_loss is 118.665, class_loss is 0.323282\n",
            "step 69 train accuracy is 1, total_loss is -502.706, inv_loss is 114.43, class_loss is 0.325645\n",
            "step 70 train accuracy is 1, total_loss is -555.808, inv_loss is 122.334, class_loss is 0.320114\n",
            "step 71 train accuracy is 1, total_loss is -548.525, inv_loss is 112.895, class_loss is 0.319928\n",
            "step 72 train accuracy is 1, total_loss is -587.199, inv_loss is 118.506, class_loss is 0.324025\n",
            "step 73 train accuracy is 1, total_loss is -592.721, inv_loss is 120.538, class_loss is 0.318852\n",
            "step 74 train accuracy is 1, total_loss is -553.845, inv_loss is 110.465, class_loss is 0.321627\n",
            "step 75 train accuracy is 1, total_loss is -559.48, inv_loss is 123.671, class_loss is 0.32092\n",
            "step 76 train accuracy is 1, total_loss is -565.897, inv_loss is 102.835, class_loss is 0.32015\n",
            "step 77 train accuracy is 1, total_loss is -606.955, inv_loss is 115.876, class_loss is 0.321124\n",
            "step 78 train accuracy is 1, total_loss is -605.317, inv_loss is 118.258, class_loss is 0.320513\n",
            "step 79 train accuracy is 1, total_loss is -561.996, inv_loss is 107.837, class_loss is 0.326247\n",
            "step 80 train accuracy is 1, total_loss is -581.257, inv_loss is 111.076, class_loss is 0.320234\n",
            "step 81 train accuracy is 1, total_loss is -578.013, inv_loss is 117.912, class_loss is 0.322109\n",
            "step 82 train accuracy is 1, total_loss is -567.591, inv_loss is 116.513, class_loss is 0.320609\n",
            "step 83 train accuracy is 1, total_loss is -588.108, inv_loss is 112.632, class_loss is 0.322054\n",
            "step 84 train accuracy is 1, total_loss is -589.398, inv_loss is 111.392, class_loss is 0.322137\n",
            "step 85 train accuracy is 1, total_loss is -557.311, inv_loss is 102.722, class_loss is 0.322152\n",
            "step 86 train accuracy is 1, total_loss is -502.563, inv_loss is 107.241, class_loss is 0.317608\n",
            "step 87 train accuracy is 1, total_loss is -558.322, inv_loss is 104.536, class_loss is 0.3226\n",
            "step 88 train accuracy is 1, total_loss is -573.521, inv_loss is 113.849, class_loss is 0.318659\n",
            "step 89 train accuracy is 1, total_loss is -564.107, inv_loss is 115.728, class_loss is 0.323261\n",
            "step 90 train accuracy is 1, total_loss is -586.116, inv_loss is 114.343, class_loss is 0.320913\n",
            "step 91 train accuracy is 1, total_loss is -541.081, inv_loss is 114.652, class_loss is 0.319337\n",
            "step 92 train accuracy is 1, total_loss is -586.715, inv_loss is 106.647, class_loss is 0.319785\n",
            "step 93 train accuracy is 1, total_loss is -553.507, inv_loss is 118.665, class_loss is 0.321046\n",
            "step 94 train accuracy is 1, total_loss is -502.708, inv_loss is 114.43, class_loss is 0.323208\n",
            "step 95 train accuracy is 1, total_loss is -555.81, inv_loss is 122.334, class_loss is 0.318658\n",
            "step 96 train accuracy is 1, total_loss is -548.527, inv_loss is 112.895, class_loss is 0.318324\n",
            "step 97 train accuracy is 1, total_loss is -587.2, inv_loss is 118.506, class_loss is 0.322345\n",
            "step 98 train accuracy is 1, total_loss is -592.723, inv_loss is 120.538, class_loss is 0.317542\n",
            "step 99 train accuracy is 1, total_loss is -553.847, inv_loss is 110.465, class_loss is 0.319897\n",
            "step 100 train accuracy is 1, total_loss is -559.482, inv_loss is 123.671, class_loss is 0.319312\n",
            "step 101 train accuracy is 1, total_loss is -565.898, inv_loss is 102.835, class_loss is 0.318649\n",
            "step 102 train accuracy is 1, total_loss is -606.957, inv_loss is 115.876, class_loss is 0.319562\n",
            "step 103 train accuracy is 1, total_loss is -605.318, inv_loss is 118.258, class_loss is 0.319133\n",
            "step 104 train accuracy is 1, total_loss is -561.998, inv_loss is 107.837, class_loss is 0.324575\n",
            "step 105 train accuracy is 1, total_loss is -581.258, inv_loss is 111.076, class_loss is 0.319046\n",
            "step 106 train accuracy is 1, total_loss is -578.014, inv_loss is 117.912, class_loss is 0.320545\n",
            "step 107 train accuracy is 1, total_loss is -567.593, inv_loss is 116.513, class_loss is 0.319069\n",
            "step 108 train accuracy is 1, total_loss is -588.109, inv_loss is 112.632, class_loss is 0.320533\n",
            "step 109 train accuracy is 1, total_loss is -589.4, inv_loss is 111.392, class_loss is 0.320645\n",
            "step 110 train accuracy is 1, total_loss is -557.312, inv_loss is 102.722, class_loss is 0.320794\n",
            "step 111 train accuracy is 1, total_loss is -502.564, inv_loss is 107.241, class_loss is 0.316712\n",
            "step 112 train accuracy is 1, total_loss is -558.323, inv_loss is 104.536, class_loss is 0.321005\n",
            "step 113 train accuracy is 1, total_loss is -573.522, inv_loss is 113.849, class_loss is 0.317523\n",
            "step 114 train accuracy is 1, total_loss is -564.108, inv_loss is 115.728, class_loss is 0.321723\n",
            "step 115 train accuracy is 1, total_loss is -586.117, inv_loss is 114.343, class_loss is 0.319591\n",
            "step 116 train accuracy is 1, total_loss is -541.082, inv_loss is 114.652, class_loss is 0.318209\n",
            "step 117 train accuracy is 1, total_loss is -586.716, inv_loss is 106.647, class_loss is 0.318586\n",
            "step 118 train accuracy is 1, total_loss is -553.508, inv_loss is 118.665, class_loss is 0.319696\n",
            "step 119 train accuracy is 1, total_loss is -502.709, inv_loss is 114.43, class_loss is 0.321669\n",
            "step 120 train accuracy is 1, total_loss is -555.811, inv_loss is 122.334, class_loss is 0.317786\n",
            "step 121 train accuracy is 1, total_loss is -548.528, inv_loss is 112.895, class_loss is 0.317355\n",
            "step 122 train accuracy is 1, total_loss is -587.201, inv_loss is 118.506, class_loss is 0.321306\n",
            "step 123 train accuracy is 1, total_loss is -592.724, inv_loss is 120.538, class_loss is 0.316745\n",
            "step 124 train accuracy is 1, total_loss is -553.848, inv_loss is 110.465, class_loss is 0.318831\n",
            "step 125 train accuracy is 1, total_loss is -559.483, inv_loss is 123.671, class_loss is 0.318312\n",
            "step 126 train accuracy is 1, total_loss is -565.899, inv_loss is 102.835, class_loss is 0.317703\n",
            "step 127 train accuracy is 1, total_loss is -606.958, inv_loss is 115.876, class_loss is 0.318584\n",
            "step 128 train accuracy is 1, total_loss is -605.319, inv_loss is 118.258, class_loss is 0.318277\n",
            "step 129 train accuracy is 1, total_loss is -561.999, inv_loss is 107.837, class_loss is 0.323471\n",
            "step 130 train accuracy is 1, total_loss is -581.259, inv_loss is 111.076, class_loss is 0.318293\n",
            "step 131 train accuracy is 1, total_loss is -578.016, inv_loss is 117.912, class_loss is 0.319531\n",
            "step 132 train accuracy is 1, total_loss is -567.594, inv_loss is 116.513, class_loss is 0.318073\n",
            "step 133 train accuracy is 1, total_loss is -588.11, inv_loss is 112.632, class_loss is 0.319523\n",
            "step 134 train accuracy is 1, total_loss is -589.401, inv_loss is 111.392, class_loss is 0.319669\n",
            "step 135 train accuracy is 1, total_loss is -557.313, inv_loss is 102.722, class_loss is 0.319889\n",
            "step 136 train accuracy is 1, total_loss is -502.566, inv_loss is 107.241, class_loss is 0.316142\n",
            "step 137 train accuracy is 1, total_loss is -558.324, inv_loss is 104.536, class_loss is 0.319929\n",
            "step 138 train accuracy is 1, total_loss is -573.523, inv_loss is 113.849, class_loss is 0.316783\n",
            "step 139 train accuracy is 1, total_loss is -564.109, inv_loss is 115.728, class_loss is 0.320669\n",
            "step 140 train accuracy is 1, total_loss is -586.118, inv_loss is 114.343, class_loss is 0.318716\n",
            "step 141 train accuracy is 1, total_loss is -541.083, inv_loss is 114.652, class_loss is 0.317453\n",
            "step 142 train accuracy is 1, total_loss is -586.717, inv_loss is 106.647, class_loss is 0.317787\n",
            "step 143 train accuracy is 1, total_loss is -553.509, inv_loss is 118.665, class_loss is 0.318788\n",
            "step 144 train accuracy is 1, total_loss is -502.709, inv_loss is 114.43, class_loss is 0.320596\n",
            "step 145 train accuracy is 1, total_loss is -555.811, inv_loss is 122.334, class_loss is 0.317202\n",
            "step 146 train accuracy is 1, total_loss is -548.529, inv_loss is 112.895, class_loss is 0.316705\n",
            "step 147 train accuracy is 1, total_loss is -587.202, inv_loss is 118.506, class_loss is 0.320593\n",
            "step 148 train accuracy is 1, total_loss is -592.725, inv_loss is 120.538, class_loss is 0.316207\n",
            "step 149 train accuracy is 1, total_loss is -553.849, inv_loss is 110.465, class_loss is 0.318107\n",
            "step 150 train accuracy is 1, total_loss is -559.484, inv_loss is 123.671, class_loss is 0.317626\n",
            "step 151 train accuracy is 1, total_loss is -565.9, inv_loss is 102.835, class_loss is 0.317049\n",
            "step 152 train accuracy is 1, total_loss is -606.959, inv_loss is 115.876, class_loss is 0.317912\n",
            "step 153 train accuracy is 1, total_loss is -605.319, inv_loss is 118.258, class_loss is 0.317693\n",
            "step 154 train accuracy is 1, total_loss is -562, inv_loss is 107.837, class_loss is 0.322676\n",
            "step 155 train accuracy is 1, total_loss is -581.259, inv_loss is 111.076, class_loss is 0.317771\n",
            "step 156 train accuracy is 1, total_loss is -578.016, inv_loss is 117.912, class_loss is 0.318816\n",
            "step 157 train accuracy is 1, total_loss is -567.595, inv_loss is 116.513, class_loss is 0.317373\n",
            "step 158 train accuracy is 1, total_loss is -588.11, inv_loss is 112.632, class_loss is 0.318797\n",
            "step 159 train accuracy is 1, total_loss is -589.401, inv_loss is 111.392, class_loss is 0.318977\n",
            "step 160 train accuracy is 1, total_loss is -557.314, inv_loss is 102.722, class_loss is 0.319235\n",
            "step 161 train accuracy is 1, total_loss is -502.566, inv_loss is 107.241, class_loss is 0.315747\n",
            "step 162 train accuracy is 1, total_loss is -558.324, inv_loss is 104.536, class_loss is 0.319147\n",
            "step 163 train accuracy is 1, total_loss is -573.523, inv_loss is 113.849, class_loss is 0.316262\n",
            "step 164 train accuracy is 1, total_loss is -564.109, inv_loss is 115.728, class_loss is 0.319894\n",
            "step 165 train accuracy is 1, total_loss is -586.118, inv_loss is 114.343, class_loss is 0.318093\n",
            "step 166 train accuracy is 1, total_loss is -541.084, inv_loss is 114.652, class_loss is 0.316907\n",
            "step 167 train accuracy is 1, total_loss is -586.718, inv_loss is 106.647, class_loss is 0.317214\n",
            "step 168 train accuracy is 1, total_loss is -553.509, inv_loss is 118.665, class_loss is 0.318134\n",
            "step 169 train accuracy is 1, total_loss is -502.71, inv_loss is 114.43, class_loss is 0.319798\n",
            "step 170 train accuracy is 1, total_loss is -555.812, inv_loss is 122.334, class_loss is 0.316782\n",
            "step 171 train accuracy is 1, total_loss is -548.529, inv_loss is 112.895, class_loss is 0.316237\n",
            "step 172 train accuracy is 1, total_loss is -587.202, inv_loss is 118.506, class_loss is 0.320068\n",
            "step 173 train accuracy is 1, total_loss is -592.725, inv_loss is 120.538, class_loss is 0.315819\n",
            "step 174 train accuracy is 1, total_loss is -553.849, inv_loss is 110.465, class_loss is 0.31758\n",
            "step 175 train accuracy is 1, total_loss is -559.484, inv_loss is 123.671, class_loss is 0.317125\n",
            "step 176 train accuracy is 1, total_loss is -565.901, inv_loss is 102.835, class_loss is 0.316568\n",
            "step 177 train accuracy is 1, total_loss is -606.959, inv_loss is 115.876, class_loss is 0.317418\n",
            "step 178 train accuracy is 1, total_loss is -605.32, inv_loss is 118.258, class_loss is 0.31727\n",
            "step 179 train accuracy is 1, total_loss is -562.001, inv_loss is 107.837, class_loss is 0.32207\n",
            "step 180 train accuracy is 1, total_loss is -581.26, inv_loss is 111.076, class_loss is 0.317386\n",
            "step 181 train accuracy is 1, total_loss is -578.017, inv_loss is 117.912, class_loss is 0.318281\n",
            "step 182 train accuracy is 1, total_loss is -567.595, inv_loss is 116.513, class_loss is 0.316854\n",
            "step 183 train accuracy is 1, total_loss is -588.111, inv_loss is 112.632, class_loss is 0.318247\n",
            "step 184 train accuracy is 1, total_loss is -589.402, inv_loss is 111.392, class_loss is 0.318458\n",
            "step 185 train accuracy is 1, total_loss is -557.315, inv_loss is 102.722, class_loss is 0.318737\n",
            "step 186 train accuracy is 1, total_loss is -502.567, inv_loss is 107.241, class_loss is 0.315457\n",
            "step 187 train accuracy is 1, total_loss is -558.324, inv_loss is 104.536, class_loss is 0.31855\n",
            "step 188 train accuracy is 1, total_loss is -573.524, inv_loss is 113.849, class_loss is 0.315875\n",
            "step 189 train accuracy is 1, total_loss is -564.11, inv_loss is 115.728, class_loss is 0.319296\n",
            "step 190 train accuracy is 1, total_loss is -586.118, inv_loss is 114.343, class_loss is 0.317625\n",
            "step 191 train accuracy is 1, total_loss is -541.084, inv_loss is 114.652, class_loss is 0.316493\n",
            "step 192 train accuracy is 1, total_loss is -586.718, inv_loss is 106.647, class_loss is 0.316783\n",
            "step 193 train accuracy is 1, total_loss is -553.51, inv_loss is 118.665, class_loss is 0.317639\n",
            "step 194 train accuracy is 1, total_loss is -502.71, inv_loss is 114.43, class_loss is 0.319178\n",
            "step 195 train accuracy is 1, total_loss is -555.812, inv_loss is 122.334, class_loss is 0.316464\n",
            "step 196 train accuracy is 1, total_loss is -548.53, inv_loss is 112.895, class_loss is 0.315884\n",
            "step 197 train accuracy is 1, total_loss is -587.203, inv_loss is 118.506, class_loss is 0.319663\n",
            "step 198 train accuracy is 1, total_loss is -592.726, inv_loss is 120.538, class_loss is 0.315524\n",
            "step 199 train accuracy is 1, total_loss is -553.85, inv_loss is 110.465, class_loss is 0.31718\n",
            "beta is 5, test accuracy is 1\n",
            "Training...\n",
            "step 0 train accuracy is 0.99, total_loss is -783.198, inv_loss is 123.671, class_loss is 0.524549\n",
            "step 1 train accuracy is 1, total_loss is -792.248, inv_loss is 102.835, class_loss is 0.447879\n",
            "step 2 train accuracy is 0.98, total_loss is -849.77, inv_loss is 115.876, class_loss is 0.424172\n",
            "step 3 train accuracy is 1, total_loss is -847.502, inv_loss is 118.258, class_loss is 0.398682\n",
            "step 4 train accuracy is 1, total_loss is -786.854, inv_loss is 107.837, class_loss is 0.39172\n",
            "step 5 train accuracy is 1, total_loss is -813.833, inv_loss is 111.076, class_loss is 0.370208\n",
            "step 6 train accuracy is 1, total_loss is -809.297, inv_loss is 117.912, class_loss is 0.37163\n",
            "step 7 train accuracy is 1, total_loss is -794.71, inv_loss is 116.513, class_loss is 0.365356\n",
            "step 8 train accuracy is 0.99, total_loss is -823.443, inv_loss is 112.632, class_loss is 0.360448\n",
            "step 9 train accuracy is 1, total_loss is -825.25, inv_loss is 111.392, class_loss is 0.35926\n",
            "step 10 train accuracy is 1, total_loss is -780.328, inv_loss is 102.722, class_loss is 0.353192\n",
            "step 11 train accuracy is 0.99, total_loss is -703.684, inv_loss is 107.241, class_loss is 0.341093\n",
            "step 12 train accuracy is 1, total_loss is -781.755, inv_loss is 104.536, class_loss is 0.352631\n",
            "step 13 train accuracy is 1, total_loss is -803.033, inv_loss is 113.849, class_loss is 0.342696\n",
            "step 14 train accuracy is 1, total_loss is -789.855, inv_loss is 115.728, class_loss is 0.348495\n",
            "step 15 train accuracy is 1, total_loss is -820.671, inv_loss is 114.343, class_loss is 0.344838\n",
            "step 16 train accuracy is 1, total_loss is -757.62, inv_loss is 114.652, class_loss is 0.338635\n",
            "step 17 train accuracy is 1, total_loss is -821.51, inv_loss is 106.647, class_loss is 0.339774\n",
            "step 18 train accuracy is 1, total_loss is -775.02, inv_loss is 118.665, class_loss is 0.342162\n",
            "step 19 train accuracy is 1, total_loss is -703.901, inv_loss is 114.43, class_loss is 0.34367\n",
            "step 20 train accuracy is 0.99, total_loss is -778.246, inv_loss is 122.334, class_loss is 0.332545\n",
            "step 21 train accuracy is 1, total_loss is -768.051, inv_loss is 112.895, class_loss is 0.332893\n",
            "step 22 train accuracy is 1, total_loss is -822.196, inv_loss is 118.506, class_loss is 0.336813\n",
            "step 23 train accuracy is 1, total_loss is -829.925, inv_loss is 120.538, class_loss is 0.328996\n",
            "step 24 train accuracy is 1, total_loss is -775.499, inv_loss is 110.465, class_loss is 0.334211\n",
            "step 25 train accuracy is 1, total_loss is -783.389, inv_loss is 123.671, class_loss is 0.332229\n",
            "step 26 train accuracy is 1, total_loss is -792.373, inv_loss is 102.835, class_loss is 0.330224\n",
            "step 27 train accuracy is 0.99, total_loss is -849.857, inv_loss is 115.876, class_loss is 0.331726\n",
            "step 28 train accuracy is 1, total_loss is -847.564, inv_loss is 118.258, class_loss is 0.329841\n",
            "step 29 train accuracy is 1, total_loss is -786.913, inv_loss is 107.837, class_loss is 0.336136\n",
            "step 30 train accuracy is 1, total_loss is -813.878, inv_loss is 111.076, class_loss is 0.327828\n",
            "step 31 train accuracy is 1, total_loss is -809.337, inv_loss is 117.912, class_loss is 0.331359\n",
            "step 32 train accuracy is 1, total_loss is -794.747, inv_loss is 116.513, class_loss is 0.329637\n",
            "step 33 train accuracy is 1, total_loss is -823.471, inv_loss is 112.632, class_loss is 0.330447\n",
            "step 34 train accuracy is 1, total_loss is -825.278, inv_loss is 111.392, class_loss is 0.330573\n",
            "step 35 train accuracy is 1, total_loss is -780.355, inv_loss is 102.722, class_loss is 0.329552\n",
            "step 36 train accuracy is 0.99, total_loss is -703.708, inv_loss is 107.241, class_loss is 0.32295\n",
            "step 37 train accuracy is 1, total_loss is -781.773, inv_loss is 104.536, class_loss is 0.330812\n",
            "step 38 train accuracy is 1, total_loss is -803.051, inv_loss is 113.849, class_loss is 0.324953\n",
            "step 39 train accuracy is 1, total_loss is -789.872, inv_loss is 115.728, class_loss is 0.330805\n",
            "step 40 train accuracy is 1, total_loss is -820.685, inv_loss is 114.343, class_loss is 0.327855\n",
            "step 41 train accuracy is 1, total_loss is -757.635, inv_loss is 114.652, class_loss is 0.325086\n",
            "step 42 train accuracy is 1, total_loss is -821.523, inv_loss is 106.647, class_loss is 0.325915\n",
            "step 43 train accuracy is 1, total_loss is -775.032, inv_loss is 118.665, class_loss is 0.327775\n",
            "step 44 train accuracy is 1, total_loss is -703.913, inv_loss is 114.43, class_loss is 0.330256\n",
            "step 45 train accuracy is 1, total_loss is -778.256, inv_loss is 122.334, class_loss is 0.323067\n",
            "step 46 train accuracy is 1, total_loss is -768.062, inv_loss is 112.895, class_loss is 0.323127\n",
            "step 47 train accuracy is 1, total_loss is -822.204, inv_loss is 118.506, class_loss is 0.327284\n",
            "step 48 train accuracy is 1, total_loss is -829.935, inv_loss is 120.538, class_loss is 0.321427\n",
            "step 49 train accuracy is 1, total_loss is -775.508, inv_loss is 110.465, class_loss is 0.324955\n",
            "step 50 train accuracy is 1, total_loss is -783.398, inv_loss is 123.671, class_loss is 0.323971\n",
            "step 51 train accuracy is 1, total_loss is -792.381, inv_loss is 102.835, class_loss is 0.322941\n",
            "step 52 train accuracy is 1, total_loss is -849.864, inv_loss is 115.876, class_loss is 0.324053\n",
            "step 53 train accuracy is 1, total_loss is -847.569, inv_loss is 118.258, class_loss is 0.323108\n",
            "step 54 train accuracy is 1, total_loss is -786.921, inv_loss is 107.837, class_loss is 0.329179\n",
            "step 55 train accuracy is 1, total_loss is -813.884, inv_loss is 111.076, class_loss is 0.322413\n",
            "step 56 train accuracy is 1, total_loss is -809.344, inv_loss is 117.912, class_loss is 0.324881\n",
            "step 57 train accuracy is 1, total_loss is -794.754, inv_loss is 116.513, class_loss is 0.323336\n",
            "step 58 train accuracy is 1, total_loss is -823.476, inv_loss is 112.632, class_loss is 0.324661\n",
            "step 59 train accuracy is 1, total_loss is -825.283, inv_loss is 111.392, class_loss is 0.324737\n",
            "step 60 train accuracy is 1, total_loss is -780.361, inv_loss is 102.722, class_loss is 0.324469\n",
            "step 61 train accuracy is 0.99, total_loss is -703.714, inv_loss is 107.241, class_loss is 0.319218\n",
            "step 62 train accuracy is 1, total_loss is -781.777, inv_loss is 104.536, class_loss is 0.325261\n",
            "step 63 train accuracy is 1, total_loss is -803.055, inv_loss is 113.849, class_loss is 0.320633\n",
            "step 64 train accuracy is 1, total_loss is -789.876, inv_loss is 115.728, class_loss is 0.325769\n",
            "step 65 train accuracy is 1, total_loss is -820.688, inv_loss is 114.343, class_loss is 0.323155\n",
            "step 66 train accuracy is 1, total_loss is -757.64, inv_loss is 114.652, class_loss is 0.321218\n",
            "step 67 train accuracy is 1, total_loss is -821.527, inv_loss is 106.647, class_loss is 0.321795\n",
            "step 68 train accuracy is 1, total_loss is -775.036, inv_loss is 118.665, class_loss is 0.323282\n",
            "step 69 train accuracy is 1, total_loss is -703.917, inv_loss is 114.43, class_loss is 0.325645\n",
            "step 70 train accuracy is 1, total_loss is -778.26, inv_loss is 122.334, class_loss is 0.320114\n",
            "step 71 train accuracy is 1, total_loss is -768.065, inv_loss is 112.895, class_loss is 0.319928\n",
            "step 72 train accuracy is 1, total_loss is -822.207, inv_loss is 118.506, class_loss is 0.324025\n",
            "step 73 train accuracy is 1, total_loss is -829.938, inv_loss is 120.538, class_loss is 0.318852\n",
            "step 74 train accuracy is 1, total_loss is -775.512, inv_loss is 110.465, class_loss is 0.321627\n",
            "step 75 train accuracy is 1, total_loss is -783.401, inv_loss is 123.671, class_loss is 0.32092\n",
            "step 76 train accuracy is 1, total_loss is -792.384, inv_loss is 102.835, class_loss is 0.32015\n",
            "step 77 train accuracy is 1, total_loss is -849.867, inv_loss is 115.876, class_loss is 0.321124\n",
            "step 78 train accuracy is 1, total_loss is -847.571, inv_loss is 118.258, class_loss is 0.320513\n",
            "step 79 train accuracy is 1, total_loss is -786.924, inv_loss is 107.837, class_loss is 0.326247\n",
            "step 80 train accuracy is 1, total_loss is -813.887, inv_loss is 111.076, class_loss is 0.320234\n",
            "step 81 train accuracy is 1, total_loss is -809.347, inv_loss is 117.912, class_loss is 0.322109\n",
            "step 82 train accuracy is 1, total_loss is -794.756, inv_loss is 116.513, class_loss is 0.320609\n",
            "step 83 train accuracy is 1, total_loss is -823.479, inv_loss is 112.632, class_loss is 0.322054\n",
            "step 84 train accuracy is 1, total_loss is -825.286, inv_loss is 111.392, class_loss is 0.322137\n",
            "step 85 train accuracy is 1, total_loss is -780.364, inv_loss is 102.722, class_loss is 0.322152\n",
            "step 86 train accuracy is 1, total_loss is -703.717, inv_loss is 107.241, class_loss is 0.317608\n",
            "step 87 train accuracy is 1, total_loss is -781.778, inv_loss is 104.536, class_loss is 0.3226\n",
            "step 88 train accuracy is 1, total_loss is -803.057, inv_loss is 113.849, class_loss is 0.318659\n",
            "step 89 train accuracy is 1, total_loss is -789.878, inv_loss is 115.728, class_loss is 0.323261\n",
            "step 90 train accuracy is 1, total_loss is -820.69, inv_loss is 114.343, class_loss is 0.320913\n",
            "step 91 train accuracy is 1, total_loss is -757.642, inv_loss is 114.652, class_loss is 0.319337\n",
            "step 92 train accuracy is 1, total_loss is -821.529, inv_loss is 106.647, class_loss is 0.319785\n",
            "step 93 train accuracy is 1, total_loss is -775.038, inv_loss is 118.665, class_loss is 0.321046\n",
            "step 94 train accuracy is 1, total_loss is -703.919, inv_loss is 114.43, class_loss is 0.323208\n",
            "step 95 train accuracy is 1, total_loss is -778.261, inv_loss is 122.334, class_loss is 0.318658\n",
            "step 96 train accuracy is 1, total_loss is -768.067, inv_loss is 112.895, class_loss is 0.318324\n",
            "step 97 train accuracy is 1, total_loss is -822.208, inv_loss is 118.506, class_loss is 0.322345\n",
            "step 98 train accuracy is 1, total_loss is -829.94, inv_loss is 120.538, class_loss is 0.317542\n",
            "step 99 train accuracy is 1, total_loss is -775.513, inv_loss is 110.465, class_loss is 0.319897\n",
            "step 100 train accuracy is 1, total_loss is -783.403, inv_loss is 123.671, class_loss is 0.319312\n",
            "step 101 train accuracy is 1, total_loss is -792.386, inv_loss is 102.835, class_loss is 0.318649\n",
            "step 102 train accuracy is 1, total_loss is -849.868, inv_loss is 115.876, class_loss is 0.319562\n",
            "step 103 train accuracy is 1, total_loss is -847.573, inv_loss is 118.258, class_loss is 0.319133\n",
            "step 104 train accuracy is 1, total_loss is -786.926, inv_loss is 107.837, class_loss is 0.324575\n",
            "step 105 train accuracy is 1, total_loss is -813.888, inv_loss is 111.076, class_loss is 0.319046\n",
            "step 106 train accuracy is 1, total_loss is -809.349, inv_loss is 117.912, class_loss is 0.320545\n",
            "step 107 train accuracy is 1, total_loss is -794.758, inv_loss is 116.513, class_loss is 0.319069\n",
            "step 108 train accuracy is 1, total_loss is -823.48, inv_loss is 112.632, class_loss is 0.320533\n",
            "step 109 train accuracy is 1, total_loss is -825.287, inv_loss is 111.392, class_loss is 0.320645\n",
            "step 110 train accuracy is 1, total_loss is -780.365, inv_loss is 102.722, class_loss is 0.320794\n",
            "step 111 train accuracy is 1, total_loss is -703.719, inv_loss is 107.241, class_loss is 0.316712\n",
            "step 112 train accuracy is 1, total_loss is -781.779, inv_loss is 104.536, class_loss is 0.321005\n",
            "step 113 train accuracy is 1, total_loss is -803.058, inv_loss is 113.849, class_loss is 0.317523\n",
            "step 114 train accuracy is 1, total_loss is -789.88, inv_loss is 115.728, class_loss is 0.321723\n",
            "step 115 train accuracy is 1, total_loss is -820.691, inv_loss is 114.343, class_loss is 0.319591\n",
            "step 116 train accuracy is 1, total_loss is -757.643, inv_loss is 114.652, class_loss is 0.318209\n",
            "step 117 train accuracy is 1, total_loss is -821.531, inv_loss is 106.647, class_loss is 0.318586\n",
            "step 118 train accuracy is 1, total_loss is -775.039, inv_loss is 118.665, class_loss is 0.319696\n",
            "step 119 train accuracy is 1, total_loss is -703.92, inv_loss is 114.43, class_loss is 0.321669\n",
            "step 120 train accuracy is 1, total_loss is -778.262, inv_loss is 122.334, class_loss is 0.317786\n",
            "step 121 train accuracy is 1, total_loss is -768.069, inv_loss is 112.895, class_loss is 0.317355\n",
            "step 122 train accuracy is 1, total_loss is -822.209, inv_loss is 118.506, class_loss is 0.321306\n",
            "step 123 train accuracy is 1, total_loss is -829.941, inv_loss is 120.538, class_loss is 0.316745\n",
            "step 124 train accuracy is 1, total_loss is -775.515, inv_loss is 110.465, class_loss is 0.318831\n",
            "step 125 train accuracy is 1, total_loss is -783.404, inv_loss is 123.671, class_loss is 0.318312\n",
            "step 126 train accuracy is 1, total_loss is -792.387, inv_loss is 102.835, class_loss is 0.317703\n",
            "step 127 train accuracy is 1, total_loss is -849.869, inv_loss is 115.876, class_loss is 0.318584\n",
            "step 128 train accuracy is 1, total_loss is -847.573, inv_loss is 118.258, class_loss is 0.318277\n",
            "step 129 train accuracy is 1, total_loss is -786.927, inv_loss is 107.837, class_loss is 0.323471\n",
            "step 130 train accuracy is 1, total_loss is -813.889, inv_loss is 111.076, class_loss is 0.318293\n",
            "step 131 train accuracy is 1, total_loss is -809.35, inv_loss is 117.912, class_loss is 0.319531\n",
            "step 132 train accuracy is 1, total_loss is -794.759, inv_loss is 116.513, class_loss is 0.318073\n",
            "step 133 train accuracy is 1, total_loss is -823.481, inv_loss is 112.632, class_loss is 0.319523\n",
            "step 134 train accuracy is 1, total_loss is -825.288, inv_loss is 111.392, class_loss is 0.319669\n",
            "step 135 train accuracy is 1, total_loss is -780.366, inv_loss is 102.722, class_loss is 0.319889\n",
            "step 136 train accuracy is 1, total_loss is -703.72, inv_loss is 107.241, class_loss is 0.316142\n",
            "step 137 train accuracy is 1, total_loss is -781.78, inv_loss is 104.536, class_loss is 0.319929\n",
            "step 138 train accuracy is 1, total_loss is -803.059, inv_loss is 113.849, class_loss is 0.316783\n",
            "step 139 train accuracy is 1, total_loss is -789.88, inv_loss is 115.728, class_loss is 0.320669\n",
            "step 140 train accuracy is 1, total_loss is -820.691, inv_loss is 114.343, class_loss is 0.318716\n",
            "step 141 train accuracy is 1, total_loss is -757.644, inv_loss is 114.652, class_loss is 0.317453\n",
            "step 142 train accuracy is 1, total_loss is -821.531, inv_loss is 106.647, class_loss is 0.317787\n",
            "step 143 train accuracy is 1, total_loss is -775.039, inv_loss is 118.665, class_loss is 0.318788\n",
            "step 144 train accuracy is 1, total_loss is -703.92, inv_loss is 114.43, class_loss is 0.320596\n",
            "step 145 train accuracy is 1, total_loss is -778.263, inv_loss is 122.334, class_loss is 0.317202\n",
            "step 146 train accuracy is 1, total_loss is -768.069, inv_loss is 112.895, class_loss is 0.316705\n",
            "step 147 train accuracy is 1, total_loss is -822.21, inv_loss is 118.506, class_loss is 0.320593\n",
            "step 148 train accuracy is 1, total_loss is -829.942, inv_loss is 120.538, class_loss is 0.316207\n",
            "step 149 train accuracy is 1, total_loss is -775.515, inv_loss is 110.465, class_loss is 0.318107\n",
            "step 150 train accuracy is 1, total_loss is -783.405, inv_loss is 123.671, class_loss is 0.317626\n",
            "step 151 train accuracy is 1, total_loss is -792.388, inv_loss is 102.835, class_loss is 0.317049\n",
            "step 152 train accuracy is 1, total_loss is -849.87, inv_loss is 115.876, class_loss is 0.317912\n",
            "step 153 train accuracy is 1, total_loss is -847.574, inv_loss is 118.258, class_loss is 0.317693\n",
            "step 154 train accuracy is 1, total_loss is -786.928, inv_loss is 107.837, class_loss is 0.322676\n",
            "step 155 train accuracy is 1, total_loss is -813.89, inv_loss is 111.076, class_loss is 0.317771\n",
            "step 156 train accuracy is 1, total_loss is -809.351, inv_loss is 117.912, class_loss is 0.318816\n",
            "step 157 train accuracy is 1, total_loss is -794.76, inv_loss is 116.513, class_loss is 0.317373\n",
            "step 158 train accuracy is 1, total_loss is -823.481, inv_loss is 112.632, class_loss is 0.318797\n",
            "step 159 train accuracy is 1, total_loss is -825.289, inv_loss is 111.392, class_loss is 0.318977\n",
            "step 160 train accuracy is 1, total_loss is -780.367, inv_loss is 102.722, class_loss is 0.319235\n",
            "step 161 train accuracy is 1, total_loss is -703.721, inv_loss is 107.241, class_loss is 0.315747\n",
            "step 162 train accuracy is 1, total_loss is -781.781, inv_loss is 104.536, class_loss is 0.319147\n",
            "step 163 train accuracy is 1, total_loss is -803.059, inv_loss is 113.849, class_loss is 0.316262\n",
            "step 164 train accuracy is 1, total_loss is -789.881, inv_loss is 115.728, class_loss is 0.319894\n",
            "step 165 train accuracy is 1, total_loss is -820.692, inv_loss is 114.343, class_loss is 0.318093\n",
            "step 166 train accuracy is 1, total_loss is -757.644, inv_loss is 114.652, class_loss is 0.316907\n",
            "step 167 train accuracy is 1, total_loss is -821.532, inv_loss is 106.647, class_loss is 0.317214\n",
            "step 168 train accuracy is 1, total_loss is -775.04, inv_loss is 118.665, class_loss is 0.318134\n",
            "step 169 train accuracy is 1, total_loss is -703.921, inv_loss is 114.43, class_loss is 0.319798\n",
            "step 170 train accuracy is 1, total_loss is -778.263, inv_loss is 122.334, class_loss is 0.316782\n",
            "step 171 train accuracy is 1, total_loss is -768.07, inv_loss is 112.895, class_loss is 0.316237\n",
            "step 172 train accuracy is 1, total_loss is -822.21, inv_loss is 118.506, class_loss is 0.320068\n",
            "step 173 train accuracy is 1, total_loss is -829.943, inv_loss is 120.538, class_loss is 0.315819\n",
            "step 174 train accuracy is 1, total_loss is -775.516, inv_loss is 110.465, class_loss is 0.31758\n",
            "step 175 train accuracy is 1, total_loss is -783.405, inv_loss is 123.671, class_loss is 0.317125\n",
            "step 176 train accuracy is 1, total_loss is -792.388, inv_loss is 102.835, class_loss is 0.316568\n",
            "step 177 train accuracy is 1, total_loss is -849.871, inv_loss is 115.876, class_loss is 0.317418\n",
            "step 178 train accuracy is 1, total_loss is -847.574, inv_loss is 118.258, class_loss is 0.31727\n",
            "step 179 train accuracy is 1, total_loss is -786.929, inv_loss is 107.837, class_loss is 0.32207\n",
            "step 180 train accuracy is 1, total_loss is -813.89, inv_loss is 111.076, class_loss is 0.317386\n",
            "step 181 train accuracy is 1, total_loss is -809.352, inv_loss is 117.912, class_loss is 0.318281\n",
            "step 182 train accuracy is 1, total_loss is -794.76, inv_loss is 116.513, class_loss is 0.316854\n",
            "step 183 train accuracy is 1, total_loss is -823.482, inv_loss is 112.632, class_loss is 0.318247\n",
            "step 184 train accuracy is 1, total_loss is -825.289, inv_loss is 111.392, class_loss is 0.318458\n",
            "step 185 train accuracy is 1, total_loss is -780.368, inv_loss is 102.722, class_loss is 0.318737\n",
            "step 186 train accuracy is 1, total_loss is -703.722, inv_loss is 107.241, class_loss is 0.315457\n",
            "step 187 train accuracy is 1, total_loss is -781.781, inv_loss is 104.536, class_loss is 0.31855\n",
            "step 188 train accuracy is 1, total_loss is -803.06, inv_loss is 113.849, class_loss is 0.315875\n",
            "step 189 train accuracy is 1, total_loss is -789.881, inv_loss is 115.728, class_loss is 0.319296\n",
            "step 190 train accuracy is 1, total_loss is -820.692, inv_loss is 114.343, class_loss is 0.317625\n",
            "step 191 train accuracy is 1, total_loss is -757.645, inv_loss is 114.652, class_loss is 0.316493\n",
            "step 192 train accuracy is 1, total_loss is -821.532, inv_loss is 106.647, class_loss is 0.316783\n",
            "step 193 train accuracy is 1, total_loss is -775.04, inv_loss is 118.665, class_loss is 0.317639\n",
            "step 194 train accuracy is 1, total_loss is -703.921, inv_loss is 114.43, class_loss is 0.319178\n",
            "step 195 train accuracy is 1, total_loss is -778.264, inv_loss is 122.334, class_loss is 0.316464\n",
            "step 196 train accuracy is 1, total_loss is -768.071, inv_loss is 112.895, class_loss is 0.315884\n",
            "step 197 train accuracy is 1, total_loss is -822.21, inv_loss is 118.506, class_loss is 0.319663\n",
            "step 198 train accuracy is 1, total_loss is -829.943, inv_loss is 120.538, class_loss is 0.315524\n",
            "step 199 train accuracy is 1, total_loss is -775.516, inv_loss is 110.465, class_loss is 0.31718\n",
            "beta is 7, test accuracy is 1\n",
            "Training...\n",
            "step 0 train accuracy is 0.99, total_loss is -1119.08, inv_loss is 123.671, class_loss is 0.524549\n",
            "step 1 train accuracy is 1, total_loss is -1131.98, inv_loss is 102.835, class_loss is 0.447879\n",
            "step 2 train accuracy is 0.98, total_loss is -1214.14, inv_loss is 115.876, class_loss is 0.424172\n",
            "step 3 train accuracy is 1, total_loss is -1210.88, inv_loss is 118.258, class_loss is 0.398682\n",
            "step 4 train accuracy is 1, total_loss is -1124.25, inv_loss is 107.837, class_loss is 0.39172\n",
            "step 5 train accuracy is 1, total_loss is -1162.78, inv_loss is 111.076, class_loss is 0.370208\n",
            "step 6 train accuracy is 1, total_loss is -1156.3, inv_loss is 117.912, class_loss is 0.37163\n",
            "step 7 train accuracy is 1, total_loss is -1135.46, inv_loss is 116.513, class_loss is 0.365356\n",
            "step 8 train accuracy is 0.99, total_loss is -1176.5, inv_loss is 112.632, class_loss is 0.360448\n",
            "step 9 train accuracy is 1, total_loss is -1179.08, inv_loss is 111.392, class_loss is 0.35926\n",
            "step 10 train accuracy is 1, total_loss is -1114.91, inv_loss is 102.722, class_loss is 0.353192\n",
            "step 11 train accuracy is 0.99, total_loss is -1005.42, inv_loss is 107.241, class_loss is 0.341093\n",
            "step 12 train accuracy is 1, total_loss is -1116.94, inv_loss is 104.536, class_loss is 0.352631\n",
            "step 13 train accuracy is 1, total_loss is -1147.34, inv_loss is 113.849, class_loss is 0.342696\n",
            "step 14 train accuracy is 1, total_loss is -1128.51, inv_loss is 115.728, class_loss is 0.348495\n",
            "step 15 train accuracy is 1, total_loss is -1172.53, inv_loss is 114.343, class_loss is 0.344838\n",
            "step 16 train accuracy is 1, total_loss is -1082.46, inv_loss is 114.652, class_loss is 0.338635\n",
            "step 17 train accuracy is 1, total_loss is -1173.73, inv_loss is 106.647, class_loss is 0.339774\n",
            "step 18 train accuracy is 1, total_loss is -1107.32, inv_loss is 118.665, class_loss is 0.342162\n",
            "step 19 train accuracy is 1, total_loss is -1005.72, inv_loss is 114.43, class_loss is 0.34367\n",
            "step 20 train accuracy is 0.99, total_loss is -1111.92, inv_loss is 122.334, class_loss is 0.332545\n",
            "step 21 train accuracy is 1, total_loss is -1097.36, inv_loss is 112.895, class_loss is 0.332893\n",
            "step 22 train accuracy is 1, total_loss is -1174.71, inv_loss is 118.506, class_loss is 0.336813\n",
            "step 23 train accuracy is 1, total_loss is -1185.75, inv_loss is 120.538, class_loss is 0.328996\n",
            "step 24 train accuracy is 1, total_loss is -1108, inv_loss is 110.465, class_loss is 0.334211\n",
            "step 25 train accuracy is 1, total_loss is -1119.27, inv_loss is 123.671, class_loss is 0.332229\n",
            "step 26 train accuracy is 1, total_loss is -1132.1, inv_loss is 102.835, class_loss is 0.330224\n",
            "step 27 train accuracy is 0.99, total_loss is -1214.22, inv_loss is 115.876, class_loss is 0.331726\n",
            "step 28 train accuracy is 1, total_loss is -1210.95, inv_loss is 118.258, class_loss is 0.329841\n",
            "step 29 train accuracy is 1, total_loss is -1124.3, inv_loss is 107.837, class_loss is 0.336136\n",
            "step 30 train accuracy is 1, total_loss is -1162.82, inv_loss is 111.076, class_loss is 0.327828\n",
            "step 31 train accuracy is 1, total_loss is -1156.34, inv_loss is 117.912, class_loss is 0.331359\n",
            "step 32 train accuracy is 1, total_loss is -1135.49, inv_loss is 116.513, class_loss is 0.329637\n",
            "step 33 train accuracy is 1, total_loss is -1176.53, inv_loss is 112.632, class_loss is 0.330447\n",
            "step 34 train accuracy is 1, total_loss is -1179.11, inv_loss is 111.392, class_loss is 0.330573\n",
            "step 35 train accuracy is 1, total_loss is -1114.93, inv_loss is 102.722, class_loss is 0.329552\n",
            "step 36 train accuracy is 0.99, total_loss is -1005.44, inv_loss is 107.241, class_loss is 0.32295\n",
            "step 37 train accuracy is 1, total_loss is -1116.96, inv_loss is 104.536, class_loss is 0.330812\n",
            "step 38 train accuracy is 1, total_loss is -1147.35, inv_loss is 113.849, class_loss is 0.324953\n",
            "step 39 train accuracy is 1, total_loss is -1128.53, inv_loss is 115.728, class_loss is 0.330805\n",
            "step 40 train accuracy is 1, total_loss is -1172.55, inv_loss is 114.343, class_loss is 0.327855\n",
            "step 41 train accuracy is 1, total_loss is -1082.48, inv_loss is 114.652, class_loss is 0.325086\n",
            "step 42 train accuracy is 1, total_loss is -1173.74, inv_loss is 106.647, class_loss is 0.325915\n",
            "step 43 train accuracy is 1, total_loss is -1107.33, inv_loss is 118.665, class_loss is 0.327775\n",
            "step 44 train accuracy is 1, total_loss is -1005.73, inv_loss is 114.43, class_loss is 0.330256\n",
            "step 45 train accuracy is 1, total_loss is -1111.93, inv_loss is 122.334, class_loss is 0.323067\n",
            "step 46 train accuracy is 1, total_loss is -1097.37, inv_loss is 112.895, class_loss is 0.323127\n",
            "step 47 train accuracy is 1, total_loss is -1174.72, inv_loss is 118.506, class_loss is 0.327284\n",
            "step 48 train accuracy is 1, total_loss is -1185.76, inv_loss is 120.538, class_loss is 0.321427\n",
            "step 49 train accuracy is 1, total_loss is -1108.01, inv_loss is 110.465, class_loss is 0.324955\n",
            "step 50 train accuracy is 1, total_loss is -1119.28, inv_loss is 123.671, class_loss is 0.323971\n",
            "step 51 train accuracy is 1, total_loss is -1132.11, inv_loss is 102.835, class_loss is 0.322941\n",
            "step 52 train accuracy is 1, total_loss is -1214.23, inv_loss is 115.876, class_loss is 0.324053\n",
            "step 53 train accuracy is 1, total_loss is -1210.95, inv_loss is 118.258, class_loss is 0.323108\n",
            "step 54 train accuracy is 1, total_loss is -1124.31, inv_loss is 107.837, class_loss is 0.329179\n",
            "step 55 train accuracy is 1, total_loss is -1162.83, inv_loss is 111.076, class_loss is 0.322413\n",
            "step 56 train accuracy is 1, total_loss is -1156.35, inv_loss is 117.912, class_loss is 0.324881\n",
            "step 57 train accuracy is 1, total_loss is -1135.5, inv_loss is 116.513, class_loss is 0.323336\n",
            "step 58 train accuracy is 1, total_loss is -1176.53, inv_loss is 112.632, class_loss is 0.324661\n",
            "step 59 train accuracy is 1, total_loss is -1179.11, inv_loss is 111.392, class_loss is 0.324737\n",
            "step 60 train accuracy is 1, total_loss is -1114.94, inv_loss is 102.722, class_loss is 0.324469\n",
            "step 61 train accuracy is 0.99, total_loss is -1005.45, inv_loss is 107.241, class_loss is 0.319218\n",
            "step 62 train accuracy is 1, total_loss is -1116.96, inv_loss is 104.536, class_loss is 0.325261\n",
            "step 63 train accuracy is 1, total_loss is -1147.36, inv_loss is 113.849, class_loss is 0.320633\n",
            "step 64 train accuracy is 1, total_loss is -1128.53, inv_loss is 115.728, class_loss is 0.325769\n",
            "step 65 train accuracy is 1, total_loss is -1172.55, inv_loss is 114.343, class_loss is 0.323155\n",
            "step 66 train accuracy is 1, total_loss is -1082.48, inv_loss is 114.652, class_loss is 0.321218\n",
            "step 67 train accuracy is 1, total_loss is -1173.75, inv_loss is 106.647, class_loss is 0.321795\n",
            "step 68 train accuracy is 1, total_loss is -1107.33, inv_loss is 118.665, class_loss is 0.323282\n",
            "step 69 train accuracy is 1, total_loss is -1005.73, inv_loss is 114.43, class_loss is 0.325645\n",
            "step 70 train accuracy is 1, total_loss is -1111.94, inv_loss is 122.334, class_loss is 0.320114\n",
            "step 71 train accuracy is 1, total_loss is -1097.38, inv_loss is 112.895, class_loss is 0.319928\n",
            "step 72 train accuracy is 1, total_loss is -1174.72, inv_loss is 118.506, class_loss is 0.324025\n",
            "step 73 train accuracy is 1, total_loss is -1185.76, inv_loss is 120.538, class_loss is 0.318852\n",
            "step 74 train accuracy is 1, total_loss is -1108.01, inv_loss is 110.465, class_loss is 0.321627\n",
            "step 75 train accuracy is 1, total_loss is -1119.28, inv_loss is 123.671, class_loss is 0.32092\n",
            "step 76 train accuracy is 1, total_loss is -1132.12, inv_loss is 102.835, class_loss is 0.32015\n",
            "step 77 train accuracy is 1, total_loss is -1214.23, inv_loss is 115.876, class_loss is 0.321124\n",
            "step 78 train accuracy is 1, total_loss is -1210.95, inv_loss is 118.258, class_loss is 0.320513\n",
            "step 79 train accuracy is 1, total_loss is -1124.32, inv_loss is 107.837, class_loss is 0.326247\n",
            "step 80 train accuracy is 1, total_loss is -1162.83, inv_loss is 111.076, class_loss is 0.320234\n",
            "step 81 train accuracy is 1, total_loss is -1156.35, inv_loss is 117.912, class_loss is 0.322109\n",
            "step 82 train accuracy is 1, total_loss is -1135.5, inv_loss is 116.513, class_loss is 0.320609\n",
            "step 83 train accuracy is 1, total_loss is -1176.53, inv_loss is 112.632, class_loss is 0.322054\n",
            "step 84 train accuracy is 1, total_loss is -1179.12, inv_loss is 111.392, class_loss is 0.322137\n",
            "step 85 train accuracy is 1, total_loss is -1114.94, inv_loss is 102.722, class_loss is 0.322152\n",
            "step 86 train accuracy is 1, total_loss is -1005.45, inv_loss is 107.241, class_loss is 0.317608\n",
            "step 87 train accuracy is 1, total_loss is -1116.96, inv_loss is 104.536, class_loss is 0.3226\n",
            "step 88 train accuracy is 1, total_loss is -1147.36, inv_loss is 113.849, class_loss is 0.318659\n",
            "step 89 train accuracy is 1, total_loss is -1128.54, inv_loss is 115.728, class_loss is 0.323261\n",
            "step 90 train accuracy is 1, total_loss is -1172.55, inv_loss is 114.343, class_loss is 0.320913\n",
            "step 91 train accuracy is 1, total_loss is -1082.48, inv_loss is 114.652, class_loss is 0.319337\n",
            "step 92 train accuracy is 1, total_loss is -1173.75, inv_loss is 106.647, class_loss is 0.319785\n",
            "step 93 train accuracy is 1, total_loss is -1107.33, inv_loss is 118.665, class_loss is 0.321046\n",
            "step 94 train accuracy is 1, total_loss is -1005.74, inv_loss is 114.43, class_loss is 0.323208\n",
            "step 95 train accuracy is 1, total_loss is -1111.94, inv_loss is 122.334, class_loss is 0.318658\n",
            "step 96 train accuracy is 1, total_loss is -1097.38, inv_loss is 112.895, class_loss is 0.318324\n",
            "step 97 train accuracy is 1, total_loss is -1174.72, inv_loss is 118.506, class_loss is 0.322345\n",
            "step 98 train accuracy is 1, total_loss is -1185.77, inv_loss is 120.538, class_loss is 0.317542\n",
            "step 99 train accuracy is 1, total_loss is -1108.01, inv_loss is 110.465, class_loss is 0.319897\n",
            "step 100 train accuracy is 1, total_loss is -1119.28, inv_loss is 123.671, class_loss is 0.319312\n",
            "step 101 train accuracy is 1, total_loss is -1132.12, inv_loss is 102.835, class_loss is 0.318649\n",
            "step 102 train accuracy is 1, total_loss is -1214.24, inv_loss is 115.876, class_loss is 0.319562\n",
            "step 103 train accuracy is 1, total_loss is -1210.95, inv_loss is 118.258, class_loss is 0.319133\n",
            "step 104 train accuracy is 1, total_loss is -1124.32, inv_loss is 107.837, class_loss is 0.324575\n",
            "step 105 train accuracy is 1, total_loss is -1162.83, inv_loss is 111.076, class_loss is 0.319046\n",
            "step 106 train accuracy is 1, total_loss is -1156.35, inv_loss is 117.912, class_loss is 0.320545\n",
            "step 107 train accuracy is 1, total_loss is -1135.51, inv_loss is 116.513, class_loss is 0.319069\n",
            "step 108 train accuracy is 1, total_loss is -1176.54, inv_loss is 112.632, class_loss is 0.320533\n",
            "step 109 train accuracy is 1, total_loss is -1179.12, inv_loss is 111.392, class_loss is 0.320645\n",
            "step 110 train accuracy is 1, total_loss is -1114.94, inv_loss is 102.722, class_loss is 0.320794\n",
            "step 111 train accuracy is 1, total_loss is -1005.45, inv_loss is 107.241, class_loss is 0.316712\n",
            "step 112 train accuracy is 1, total_loss is -1116.96, inv_loss is 104.536, class_loss is 0.321005\n",
            "step 113 train accuracy is 1, total_loss is -1147.36, inv_loss is 113.849, class_loss is 0.317523\n",
            "step 114 train accuracy is 1, total_loss is -1128.54, inv_loss is 115.728, class_loss is 0.321723\n",
            "step 115 train accuracy is 1, total_loss is -1172.55, inv_loss is 114.343, class_loss is 0.319591\n",
            "step 116 train accuracy is 1, total_loss is -1082.48, inv_loss is 114.652, class_loss is 0.318209\n",
            "step 117 train accuracy is 1, total_loss is -1173.75, inv_loss is 106.647, class_loss is 0.318586\n",
            "step 118 train accuracy is 1, total_loss is -1107.33, inv_loss is 118.665, class_loss is 0.319696\n",
            "step 119 train accuracy is 1, total_loss is -1005.74, inv_loss is 114.43, class_loss is 0.321669\n",
            "step 120 train accuracy is 1, total_loss is -1111.94, inv_loss is 122.334, class_loss is 0.317786\n",
            "step 121 train accuracy is 1, total_loss is -1097.38, inv_loss is 112.895, class_loss is 0.317355\n",
            "step 122 train accuracy is 1, total_loss is -1174.72, inv_loss is 118.506, class_loss is 0.321306\n",
            "step 123 train accuracy is 1, total_loss is -1185.77, inv_loss is 120.538, class_loss is 0.316745\n",
            "step 124 train accuracy is 1, total_loss is -1108.01, inv_loss is 110.465, class_loss is 0.318831\n",
            "step 125 train accuracy is 1, total_loss is -1119.29, inv_loss is 123.671, class_loss is 0.318312\n",
            "step 126 train accuracy is 1, total_loss is -1132.12, inv_loss is 102.835, class_loss is 0.317703\n",
            "step 127 train accuracy is 1, total_loss is -1214.24, inv_loss is 115.876, class_loss is 0.318584\n",
            "step 128 train accuracy is 1, total_loss is -1210.95, inv_loss is 118.258, class_loss is 0.318277\n",
            "step 129 train accuracy is 1, total_loss is -1124.32, inv_loss is 107.837, class_loss is 0.323471\n",
            "step 130 train accuracy is 1, total_loss is -1162.83, inv_loss is 111.076, class_loss is 0.318293\n",
            "step 131 train accuracy is 1, total_loss is -1156.35, inv_loss is 117.912, class_loss is 0.319531\n",
            "step 132 train accuracy is 1, total_loss is -1135.51, inv_loss is 116.513, class_loss is 0.318073\n",
            "step 133 train accuracy is 1, total_loss is -1176.54, inv_loss is 112.632, class_loss is 0.319523\n",
            "step 134 train accuracy is 1, total_loss is -1179.12, inv_loss is 111.392, class_loss is 0.319669\n",
            "step 135 train accuracy is 1, total_loss is -1114.95, inv_loss is 102.722, class_loss is 0.319889\n",
            "step 136 train accuracy is 1, total_loss is -1005.45, inv_loss is 107.241, class_loss is 0.316142\n",
            "step 137 train accuracy is 1, total_loss is -1116.96, inv_loss is 104.536, class_loss is 0.319929\n",
            "step 138 train accuracy is 1, total_loss is -1147.36, inv_loss is 113.849, class_loss is 0.316783\n",
            "step 139 train accuracy is 1, total_loss is -1128.54, inv_loss is 115.728, class_loss is 0.320669\n",
            "step 140 train accuracy is 1, total_loss is -1172.55, inv_loss is 114.343, class_loss is 0.318716\n",
            "step 141 train accuracy is 1, total_loss is -1082.48, inv_loss is 114.652, class_loss is 0.317453\n",
            "step 142 train accuracy is 1, total_loss is -1173.75, inv_loss is 106.647, class_loss is 0.317787\n",
            "step 143 train accuracy is 1, total_loss is -1107.34, inv_loss is 118.665, class_loss is 0.318788\n",
            "step 144 train accuracy is 1, total_loss is -1005.74, inv_loss is 114.43, class_loss is 0.320596\n",
            "step 145 train accuracy is 1, total_loss is -1111.94, inv_loss is 122.334, class_loss is 0.317202\n",
            "step 146 train accuracy is 1, total_loss is -1097.38, inv_loss is 112.895, class_loss is 0.316705\n",
            "step 147 train accuracy is 1, total_loss is -1174.72, inv_loss is 118.506, class_loss is 0.320593\n",
            "step 148 train accuracy is 1, total_loss is -1185.77, inv_loss is 120.538, class_loss is 0.316207\n",
            "step 149 train accuracy is 1, total_loss is -1108.02, inv_loss is 110.465, class_loss is 0.318107\n",
            "step 150 train accuracy is 1, total_loss is -1119.29, inv_loss is 123.671, class_loss is 0.317626\n",
            "step 151 train accuracy is 1, total_loss is -1132.12, inv_loss is 102.835, class_loss is 0.317049\n",
            "step 152 train accuracy is 1, total_loss is -1214.24, inv_loss is 115.876, class_loss is 0.317912\n",
            "step 153 train accuracy is 1, total_loss is -1210.95, inv_loss is 118.258, class_loss is 0.317693\n",
            "step 154 train accuracy is 1, total_loss is -1124.32, inv_loss is 107.837, class_loss is 0.322676\n",
            "step 155 train accuracy is 1, total_loss is -1162.83, inv_loss is 111.076, class_loss is 0.317771\n",
            "step 156 train accuracy is 1, total_loss is -1156.35, inv_loss is 117.912, class_loss is 0.318816\n",
            "step 157 train accuracy is 1, total_loss is -1135.51, inv_loss is 116.513, class_loss is 0.317373\n",
            "step 158 train accuracy is 1, total_loss is -1176.54, inv_loss is 112.632, class_loss is 0.318797\n",
            "step 159 train accuracy is 1, total_loss is -1179.12, inv_loss is 111.392, class_loss is 0.318977\n",
            "step 160 train accuracy is 1, total_loss is -1114.95, inv_loss is 102.722, class_loss is 0.319235\n",
            "step 161 train accuracy is 1, total_loss is -1005.45, inv_loss is 107.241, class_loss is 0.315747\n",
            "step 162 train accuracy is 1, total_loss is -1116.97, inv_loss is 104.536, class_loss is 0.319147\n",
            "step 163 train accuracy is 1, total_loss is -1147.36, inv_loss is 113.849, class_loss is 0.316262\n",
            "step 164 train accuracy is 1, total_loss is -1128.54, inv_loss is 115.728, class_loss is 0.319894\n",
            "step 165 train accuracy is 1, total_loss is -1172.55, inv_loss is 114.343, class_loss is 0.318093\n",
            "step 166 train accuracy is 1, total_loss is -1082.49, inv_loss is 114.652, class_loss is 0.316907\n",
            "step 167 train accuracy is 1, total_loss is -1173.75, inv_loss is 106.647, class_loss is 0.317214\n",
            "step 168 train accuracy is 1, total_loss is -1107.34, inv_loss is 118.665, class_loss is 0.318134\n",
            "step 169 train accuracy is 1, total_loss is -1005.74, inv_loss is 114.43, class_loss is 0.319798\n",
            "step 170 train accuracy is 1, total_loss is -1111.94, inv_loss is 122.334, class_loss is 0.316782\n",
            "step 171 train accuracy is 1, total_loss is -1097.38, inv_loss is 112.895, class_loss is 0.316237\n",
            "step 172 train accuracy is 1, total_loss is -1174.72, inv_loss is 118.506, class_loss is 0.320068\n",
            "step 173 train accuracy is 1, total_loss is -1185.77, inv_loss is 120.538, class_loss is 0.315819\n",
            "step 174 train accuracy is 1, total_loss is -1108.02, inv_loss is 110.465, class_loss is 0.31758\n",
            "step 175 train accuracy is 1, total_loss is -1119.29, inv_loss is 123.671, class_loss is 0.317125\n",
            "step 176 train accuracy is 1, total_loss is -1132.12, inv_loss is 102.835, class_loss is 0.316568\n",
            "step 177 train accuracy is 1, total_loss is -1214.24, inv_loss is 115.876, class_loss is 0.317418\n",
            "step 178 train accuracy is 1, total_loss is -1210.96, inv_loss is 118.258, class_loss is 0.31727\n",
            "step 179 train accuracy is 1, total_loss is -1124.32, inv_loss is 107.837, class_loss is 0.32207\n",
            "step 180 train accuracy is 1, total_loss is -1162.84, inv_loss is 111.076, class_loss is 0.317386\n",
            "step 181 train accuracy is 1, total_loss is -1156.35, inv_loss is 117.912, class_loss is 0.318281\n",
            "step 182 train accuracy is 1, total_loss is -1135.51, inv_loss is 116.513, class_loss is 0.316854\n",
            "step 183 train accuracy is 1, total_loss is -1176.54, inv_loss is 112.632, class_loss is 0.318247\n",
            "step 184 train accuracy is 1, total_loss is -1179.12, inv_loss is 111.392, class_loss is 0.318458\n",
            "step 185 train accuracy is 1, total_loss is -1114.95, inv_loss is 102.722, class_loss is 0.318737\n",
            "step 186 train accuracy is 1, total_loss is -1005.45, inv_loss is 107.241, class_loss is 0.315457\n",
            "step 187 train accuracy is 1, total_loss is -1116.97, inv_loss is 104.536, class_loss is 0.31855\n",
            "step 188 train accuracy is 1, total_loss is -1147.36, inv_loss is 113.849, class_loss is 0.315875\n",
            "step 189 train accuracy is 1, total_loss is -1128.54, inv_loss is 115.728, class_loss is 0.319296\n",
            "step 190 train accuracy is 1, total_loss is -1172.55, inv_loss is 114.343, class_loss is 0.317625\n",
            "step 191 train accuracy is 1, total_loss is -1082.49, inv_loss is 114.652, class_loss is 0.316493\n",
            "step 192 train accuracy is 1, total_loss is -1173.75, inv_loss is 106.647, class_loss is 0.316783\n",
            "step 193 train accuracy is 1, total_loss is -1107.34, inv_loss is 118.665, class_loss is 0.317639\n",
            "step 194 train accuracy is 1, total_loss is -1005.74, inv_loss is 114.43, class_loss is 0.319178\n",
            "step 195 train accuracy is 1, total_loss is -1111.94, inv_loss is 122.334, class_loss is 0.316464\n",
            "step 196 train accuracy is 1, total_loss is -1097.38, inv_loss is 112.895, class_loss is 0.315884\n",
            "step 197 train accuracy is 1, total_loss is -1174.72, inv_loss is 118.506, class_loss is 0.319663\n",
            "step 198 train accuracy is 1, total_loss is -1185.77, inv_loss is 120.538, class_loss is 0.315524\n",
            "step 199 train accuracy is 1, total_loss is -1108.02, inv_loss is 110.465, class_loss is 0.31718\n",
            "beta is 10, test accuracy is 1\n",
            "Training...\n",
            "step 0 train accuracy is 0.99, total_loss is -1678.88, inv_loss is 123.671, class_loss is 0.524549\n",
            "step 1 train accuracy is 1, total_loss is -1698.2, inv_loss is 102.835, class_loss is 0.447879\n",
            "step 2 train accuracy is 0.98, total_loss is -1821.42, inv_loss is 115.876, class_loss is 0.424172\n",
            "step 3 train accuracy is 1, total_loss is -1816.52, inv_loss is 118.258, class_loss is 0.398682\n",
            "step 4 train accuracy is 1, total_loss is -1686.57, inv_loss is 107.837, class_loss is 0.39172\n",
            "step 5 train accuracy is 1, total_loss is -1744.35, inv_loss is 111.076, class_loss is 0.370208\n",
            "step 6 train accuracy is 1, total_loss is -1734.64, inv_loss is 117.912, class_loss is 0.37163\n",
            "step 7 train accuracy is 1, total_loss is -1703.37, inv_loss is 116.513, class_loss is 0.365356\n",
            "step 8 train accuracy is 0.99, total_loss is -1764.93, inv_loss is 112.632, class_loss is 0.360448\n",
            "step 9 train accuracy is 1, total_loss is -1768.8, inv_loss is 111.392, class_loss is 0.35926\n",
            "step 10 train accuracy is 1, total_loss is -1672.54, inv_loss is 102.722, class_loss is 0.353192\n",
            "step 11 train accuracy is 0.99, total_loss is -1508.3, inv_loss is 107.241, class_loss is 0.341093\n",
            "step 12 train accuracy is 1, total_loss is -1675.58, inv_loss is 104.536, class_loss is 0.352631\n",
            "step 13 train accuracy is 1, total_loss is -1721.18, inv_loss is 113.849, class_loss is 0.342696\n",
            "step 14 train accuracy is 1, total_loss is -1692.94, inv_loss is 115.728, class_loss is 0.348495\n",
            "step 15 train accuracy is 1, total_loss is -1758.97, inv_loss is 114.343, class_loss is 0.344838\n",
            "step 16 train accuracy is 1, total_loss is -1623.86, inv_loss is 114.652, class_loss is 0.338635\n",
            "step 17 train accuracy is 1, total_loss is -1760.77, inv_loss is 106.647, class_loss is 0.339774\n",
            "step 18 train accuracy is 1, total_loss is -1661.14, inv_loss is 118.665, class_loss is 0.342162\n",
            "step 19 train accuracy is 1, total_loss is -1508.74, inv_loss is 114.43, class_loss is 0.34367\n",
            "step 20 train accuracy is 0.99, total_loss is -1668.05, inv_loss is 122.334, class_loss is 0.332545\n",
            "step 21 train accuracy is 1, total_loss is -1646.21, inv_loss is 112.895, class_loss is 0.332893\n",
            "step 22 train accuracy is 1, total_loss is -1762.23, inv_loss is 118.506, class_loss is 0.336813\n",
            "step 23 train accuracy is 1, total_loss is -1778.8, inv_loss is 120.538, class_loss is 0.328996\n",
            "step 24 train accuracy is 1, total_loss is -1662.17, inv_loss is 110.465, class_loss is 0.334211\n",
            "step 25 train accuracy is 1, total_loss is -1679.07, inv_loss is 123.671, class_loss is 0.332229\n",
            "step 26 train accuracy is 1, total_loss is -1698.32, inv_loss is 102.835, class_loss is 0.330224\n",
            "step 27 train accuracy is 0.99, total_loss is -1821.5, inv_loss is 115.876, class_loss is 0.331726\n",
            "step 28 train accuracy is 1, total_loss is -1816.58, inv_loss is 118.258, class_loss is 0.329841\n",
            "step 29 train accuracy is 1, total_loss is -1686.62, inv_loss is 107.837, class_loss is 0.336136\n",
            "step 30 train accuracy is 1, total_loss is -1744.4, inv_loss is 111.076, class_loss is 0.327828\n",
            "step 31 train accuracy is 1, total_loss is -1734.68, inv_loss is 117.912, class_loss is 0.331359\n",
            "step 32 train accuracy is 1, total_loss is -1703.41, inv_loss is 116.513, class_loss is 0.329637\n",
            "step 33 train accuracy is 1, total_loss is -1764.95, inv_loss is 112.632, class_loss is 0.330447\n",
            "step 34 train accuracy is 1, total_loss is -1768.83, inv_loss is 111.392, class_loss is 0.330573\n",
            "step 35 train accuracy is 1, total_loss is -1672.57, inv_loss is 102.722, class_loss is 0.329552\n",
            "step 36 train accuracy is 0.99, total_loss is -1508.33, inv_loss is 107.241, class_loss is 0.32295\n",
            "step 37 train accuracy is 1, total_loss is -1675.6, inv_loss is 104.536, class_loss is 0.330812\n",
            "step 38 train accuracy is 1, total_loss is -1721.19, inv_loss is 113.849, class_loss is 0.324953\n",
            "step 39 train accuracy is 1, total_loss is -1692.96, inv_loss is 115.728, class_loss is 0.330805\n",
            "step 40 train accuracy is 1, total_loss is -1758.98, inv_loss is 114.343, class_loss is 0.327855\n",
            "step 41 train accuracy is 1, total_loss is -1623.88, inv_loss is 114.652, class_loss is 0.325086\n",
            "step 42 train accuracy is 1, total_loss is -1760.78, inv_loss is 106.647, class_loss is 0.325915\n",
            "step 43 train accuracy is 1, total_loss is -1661.15, inv_loss is 118.665, class_loss is 0.327775\n",
            "step 44 train accuracy is 1, total_loss is -1508.76, inv_loss is 114.43, class_loss is 0.330256\n",
            "step 45 train accuracy is 1, total_loss is -1668.06, inv_loss is 122.334, class_loss is 0.323067\n",
            "step 46 train accuracy is 1, total_loss is -1646.22, inv_loss is 112.895, class_loss is 0.323127\n",
            "step 47 train accuracy is 1, total_loss is -1762.24, inv_loss is 118.506, class_loss is 0.327284\n",
            "step 48 train accuracy is 1, total_loss is -1778.8, inv_loss is 120.538, class_loss is 0.321427\n",
            "step 49 train accuracy is 1, total_loss is -1662.17, inv_loss is 110.465, class_loss is 0.324955\n",
            "step 50 train accuracy is 1, total_loss is -1679.08, inv_loss is 123.671, class_loss is 0.323971\n",
            "step 51 train accuracy is 1, total_loss is -1698.33, inv_loss is 102.835, class_loss is 0.322941\n",
            "step 52 train accuracy is 1, total_loss is -1821.51, inv_loss is 115.876, class_loss is 0.324053\n",
            "step 53 train accuracy is 1, total_loss is -1816.59, inv_loss is 118.258, class_loss is 0.323108\n",
            "step 54 train accuracy is 1, total_loss is -1686.63, inv_loss is 107.837, class_loss is 0.329179\n",
            "step 55 train accuracy is 1, total_loss is -1744.41, inv_loss is 111.076, class_loss is 0.322413\n",
            "step 56 train accuracy is 1, total_loss is -1734.68, inv_loss is 117.912, class_loss is 0.324881\n",
            "step 57 train accuracy is 1, total_loss is -1703.41, inv_loss is 116.513, class_loss is 0.323336\n",
            "step 58 train accuracy is 1, total_loss is -1764.96, inv_loss is 112.632, class_loss is 0.324661\n",
            "step 59 train accuracy is 1, total_loss is -1768.83, inv_loss is 111.392, class_loss is 0.324737\n",
            "step 60 train accuracy is 1, total_loss is -1672.57, inv_loss is 102.722, class_loss is 0.324469\n",
            "step 61 train accuracy is 0.99, total_loss is -1508.33, inv_loss is 107.241, class_loss is 0.319218\n",
            "step 62 train accuracy is 1, total_loss is -1675.6, inv_loss is 104.536, class_loss is 0.325261\n",
            "step 63 train accuracy is 1, total_loss is -1721.2, inv_loss is 113.849, class_loss is 0.320633\n",
            "step 64 train accuracy is 1, total_loss is -1692.96, inv_loss is 115.728, class_loss is 0.325769\n",
            "step 65 train accuracy is 1, total_loss is -1758.98, inv_loss is 114.343, class_loss is 0.323155\n",
            "step 66 train accuracy is 1, total_loss is -1623.88, inv_loss is 114.652, class_loss is 0.321218\n",
            "step 67 train accuracy is 1, total_loss is -1760.78, inv_loss is 106.647, class_loss is 0.321795\n",
            "step 68 train accuracy is 1, total_loss is -1661.16, inv_loss is 118.665, class_loss is 0.323282\n",
            "step 69 train accuracy is 1, total_loss is -1508.76, inv_loss is 114.43, class_loss is 0.325645\n",
            "step 70 train accuracy is 1, total_loss is -1668.07, inv_loss is 122.334, class_loss is 0.320114\n",
            "step 71 train accuracy is 1, total_loss is -1646.23, inv_loss is 112.895, class_loss is 0.319928\n",
            "step 72 train accuracy is 1, total_loss is -1762.24, inv_loss is 118.506, class_loss is 0.324025\n",
            "step 73 train accuracy is 1, total_loss is -1778.81, inv_loss is 120.538, class_loss is 0.318852\n",
            "step 74 train accuracy is 1, total_loss is -1662.18, inv_loss is 110.465, class_loss is 0.321627\n",
            "step 75 train accuracy is 1, total_loss is -1679.09, inv_loss is 123.671, class_loss is 0.32092\n",
            "step 76 train accuracy is 1, total_loss is -1698.34, inv_loss is 102.835, class_loss is 0.32015\n",
            "step 77 train accuracy is 1, total_loss is -1821.51, inv_loss is 115.876, class_loss is 0.321124\n",
            "step 78 train accuracy is 1, total_loss is -1816.59, inv_loss is 118.258, class_loss is 0.320513\n",
            "step 79 train accuracy is 1, total_loss is -1686.64, inv_loss is 107.837, class_loss is 0.326247\n",
            "step 80 train accuracy is 1, total_loss is -1744.41, inv_loss is 111.076, class_loss is 0.320234\n",
            "step 81 train accuracy is 1, total_loss is -1734.69, inv_loss is 117.912, class_loss is 0.322109\n",
            "step 82 train accuracy is 1, total_loss is -1703.42, inv_loss is 116.513, class_loss is 0.320609\n",
            "step 83 train accuracy is 1, total_loss is -1764.96, inv_loss is 112.632, class_loss is 0.322054\n",
            "step 84 train accuracy is 1, total_loss is -1768.84, inv_loss is 111.392, class_loss is 0.322137\n",
            "step 85 train accuracy is 1, total_loss is -1672.58, inv_loss is 102.722, class_loss is 0.322152\n",
            "step 86 train accuracy is 1, total_loss is -1508.34, inv_loss is 107.241, class_loss is 0.317608\n",
            "step 87 train accuracy is 1, total_loss is -1675.6, inv_loss is 104.536, class_loss is 0.3226\n",
            "step 88 train accuracy is 1, total_loss is -1721.2, inv_loss is 113.849, class_loss is 0.318659\n",
            "step 89 train accuracy is 1, total_loss is -1692.97, inv_loss is 115.728, class_loss is 0.323261\n",
            "step 90 train accuracy is 1, total_loss is -1758.98, inv_loss is 114.343, class_loss is 0.320913\n",
            "step 91 train accuracy is 1, total_loss is -1623.88, inv_loss is 114.652, class_loss is 0.319337\n",
            "step 92 train accuracy is 1, total_loss is -1760.79, inv_loss is 106.647, class_loss is 0.319785\n",
            "step 93 train accuracy is 1, total_loss is -1661.16, inv_loss is 118.665, class_loss is 0.321046\n",
            "step 94 train accuracy is 1, total_loss is -1508.76, inv_loss is 114.43, class_loss is 0.323208\n",
            "step 95 train accuracy is 1, total_loss is -1668.07, inv_loss is 122.334, class_loss is 0.318658\n",
            "step 96 train accuracy is 1, total_loss is -1646.23, inv_loss is 112.895, class_loss is 0.318324\n",
            "step 97 train accuracy is 1, total_loss is -1762.24, inv_loss is 118.506, class_loss is 0.322345\n",
            "step 98 train accuracy is 1, total_loss is -1778.81, inv_loss is 120.538, class_loss is 0.317542\n",
            "step 99 train accuracy is 1, total_loss is -1662.18, inv_loss is 110.465, class_loss is 0.319897\n",
            "step 100 train accuracy is 1, total_loss is -1679.09, inv_loss is 123.671, class_loss is 0.319312\n",
            "step 101 train accuracy is 1, total_loss is -1698.34, inv_loss is 102.835, class_loss is 0.318649\n",
            "step 102 train accuracy is 1, total_loss is -1821.51, inv_loss is 115.876, class_loss is 0.319562\n",
            "step 103 train accuracy is 1, total_loss is -1816.59, inv_loss is 118.258, class_loss is 0.319133\n",
            "step 104 train accuracy is 1, total_loss is -1686.64, inv_loss is 107.837, class_loss is 0.324575\n",
            "step 105 train accuracy is 1, total_loss is -1744.41, inv_loss is 111.076, class_loss is 0.319046\n",
            "step 106 train accuracy is 1, total_loss is -1734.69, inv_loss is 117.912, class_loss is 0.320545\n",
            "step 107 train accuracy is 1, total_loss is -1703.42, inv_loss is 116.513, class_loss is 0.319069\n",
            "step 108 train accuracy is 1, total_loss is -1764.96, inv_loss is 112.632, class_loss is 0.320533\n",
            "step 109 train accuracy is 1, total_loss is -1768.84, inv_loss is 111.392, class_loss is 0.320645\n",
            "step 110 train accuracy is 1, total_loss is -1672.58, inv_loss is 102.722, class_loss is 0.320794\n",
            "step 111 train accuracy is 1, total_loss is -1508.34, inv_loss is 107.241, class_loss is 0.316712\n",
            "step 112 train accuracy is 1, total_loss is -1675.61, inv_loss is 104.536, class_loss is 0.321005\n",
            "step 113 train accuracy is 1, total_loss is -1721.2, inv_loss is 113.849, class_loss is 0.317523\n",
            "step 114 train accuracy is 1, total_loss is -1692.97, inv_loss is 115.728, class_loss is 0.321723\n",
            "step 115 train accuracy is 1, total_loss is -1758.98, inv_loss is 114.343, class_loss is 0.319591\n",
            "step 116 train accuracy is 1, total_loss is -1623.89, inv_loss is 114.652, class_loss is 0.318209\n",
            "step 117 train accuracy is 1, total_loss is -1760.79, inv_loss is 106.647, class_loss is 0.318586\n",
            "step 118 train accuracy is 1, total_loss is -1661.16, inv_loss is 118.665, class_loss is 0.319696\n",
            "step 119 train accuracy is 1, total_loss is -1508.76, inv_loss is 114.43, class_loss is 0.321669\n",
            "step 120 train accuracy is 1, total_loss is -1668.07, inv_loss is 122.334, class_loss is 0.317786\n",
            "step 121 train accuracy is 1, total_loss is -1646.23, inv_loss is 112.895, class_loss is 0.317355\n",
            "step 122 train accuracy is 1, total_loss is -1762.24, inv_loss is 118.506, class_loss is 0.321306\n",
            "step 123 train accuracy is 1, total_loss is -1778.81, inv_loss is 120.538, class_loss is 0.316745\n",
            "step 124 train accuracy is 1, total_loss is -1662.18, inv_loss is 110.465, class_loss is 0.318831\n",
            "step 125 train accuracy is 1, total_loss is -1679.09, inv_loss is 123.671, class_loss is 0.318312\n",
            "step 126 train accuracy is 1, total_loss is -1698.34, inv_loss is 102.835, class_loss is 0.317703\n",
            "step 127 train accuracy is 1, total_loss is -1821.51, inv_loss is 115.876, class_loss is 0.318584\n",
            "step 128 train accuracy is 1, total_loss is -1816.59, inv_loss is 118.258, class_loss is 0.318277\n",
            "step 129 train accuracy is 1, total_loss is -1686.64, inv_loss is 107.837, class_loss is 0.323471\n",
            "step 130 train accuracy is 1, total_loss is -1744.41, inv_loss is 111.076, class_loss is 0.318293\n",
            "step 131 train accuracy is 1, total_loss is -1734.69, inv_loss is 117.912, class_loss is 0.319531\n",
            "step 132 train accuracy is 1, total_loss is -1703.42, inv_loss is 116.513, class_loss is 0.318073\n",
            "step 133 train accuracy is 1, total_loss is -1764.96, inv_loss is 112.632, class_loss is 0.319523\n",
            "step 134 train accuracy is 1, total_loss is -1768.84, inv_loss is 111.392, class_loss is 0.319669\n",
            "step 135 train accuracy is 1, total_loss is -1672.58, inv_loss is 102.722, class_loss is 0.319889\n",
            "step 136 train accuracy is 1, total_loss is -1508.34, inv_loss is 107.241, class_loss is 0.316142\n",
            "step 137 train accuracy is 1, total_loss is -1675.61, inv_loss is 104.536, class_loss is 0.319929\n",
            "step 138 train accuracy is 1, total_loss is -1721.2, inv_loss is 113.849, class_loss is 0.316783\n",
            "step 139 train accuracy is 1, total_loss is -1692.97, inv_loss is 115.728, class_loss is 0.320669\n",
            "step 140 train accuracy is 1, total_loss is -1758.99, inv_loss is 114.343, class_loss is 0.318716\n",
            "step 141 train accuracy is 1, total_loss is -1623.89, inv_loss is 114.652, class_loss is 0.317453\n",
            "step 142 train accuracy is 1, total_loss is -1760.79, inv_loss is 106.647, class_loss is 0.317787\n",
            "step 143 train accuracy is 1, total_loss is -1661.16, inv_loss is 118.665, class_loss is 0.318788\n",
            "step 144 train accuracy is 1, total_loss is -1508.76, inv_loss is 114.43, class_loss is 0.320596\n",
            "step 145 train accuracy is 1, total_loss is -1668.07, inv_loss is 122.334, class_loss is 0.317202\n",
            "step 146 train accuracy is 1, total_loss is -1646.23, inv_loss is 112.895, class_loss is 0.316705\n",
            "step 147 train accuracy is 1, total_loss is -1762.24, inv_loss is 118.506, class_loss is 0.320593\n",
            "step 148 train accuracy is 1, total_loss is -1778.81, inv_loss is 120.538, class_loss is 0.316207\n",
            "step 149 train accuracy is 1, total_loss is -1662.18, inv_loss is 110.465, class_loss is 0.318107\n",
            "step 150 train accuracy is 1, total_loss is -1679.09, inv_loss is 123.671, class_loss is 0.317626\n",
            "step 151 train accuracy is 1, total_loss is -1698.34, inv_loss is 102.835, class_loss is 0.317049\n",
            "step 152 train accuracy is 1, total_loss is -1821.52, inv_loss is 115.876, class_loss is 0.317912\n",
            "step 153 train accuracy is 1, total_loss is -1816.59, inv_loss is 118.258, class_loss is 0.317693\n",
            "step 154 train accuracy is 1, total_loss is -1686.64, inv_loss is 107.837, class_loss is 0.322676\n",
            "step 155 train accuracy is 1, total_loss is -1744.41, inv_loss is 111.076, class_loss is 0.317771\n",
            "step 156 train accuracy is 1, total_loss is -1734.69, inv_loss is 117.912, class_loss is 0.318816\n",
            "step 157 train accuracy is 1, total_loss is -1703.42, inv_loss is 116.513, class_loss is 0.317373\n",
            "step 158 train accuracy is 1, total_loss is -1764.97, inv_loss is 112.632, class_loss is 0.318797\n",
            "step 159 train accuracy is 1, total_loss is -1768.84, inv_loss is 111.392, class_loss is 0.318977\n",
            "step 160 train accuracy is 1, total_loss is -1672.58, inv_loss is 102.722, class_loss is 0.319235\n",
            "step 161 train accuracy is 1, total_loss is -1508.34, inv_loss is 107.241, class_loss is 0.315747\n",
            "step 162 train accuracy is 1, total_loss is -1675.61, inv_loss is 104.536, class_loss is 0.319147\n",
            "step 163 train accuracy is 1, total_loss is -1721.2, inv_loss is 113.849, class_loss is 0.316262\n",
            "step 164 train accuracy is 1, total_loss is -1692.97, inv_loss is 115.728, class_loss is 0.319894\n",
            "step 165 train accuracy is 1, total_loss is -1758.99, inv_loss is 114.343, class_loss is 0.318093\n",
            "step 166 train accuracy is 1, total_loss is -1623.89, inv_loss is 114.652, class_loss is 0.316907\n",
            "step 167 train accuracy is 1, total_loss is -1760.79, inv_loss is 106.647, class_loss is 0.317214\n",
            "step 168 train accuracy is 1, total_loss is -1661.16, inv_loss is 118.665, class_loss is 0.318134\n",
            "step 169 train accuracy is 1, total_loss is -1508.77, inv_loss is 114.43, class_loss is 0.319798\n",
            "step 170 train accuracy is 1, total_loss is -1668.07, inv_loss is 122.334, class_loss is 0.316782\n",
            "step 171 train accuracy is 1, total_loss is -1646.23, inv_loss is 112.895, class_loss is 0.316237\n",
            "step 172 train accuracy is 1, total_loss is -1762.24, inv_loss is 118.506, class_loss is 0.320068\n",
            "step 173 train accuracy is 1, total_loss is -1778.81, inv_loss is 120.538, class_loss is 0.315819\n",
            "step 174 train accuracy is 1, total_loss is -1662.18, inv_loss is 110.465, class_loss is 0.31758\n",
            "step 175 train accuracy is 1, total_loss is -1679.09, inv_loss is 123.671, class_loss is 0.317125\n",
            "step 176 train accuracy is 1, total_loss is -1698.34, inv_loss is 102.835, class_loss is 0.316568\n",
            "step 177 train accuracy is 1, total_loss is -1821.52, inv_loss is 115.876, class_loss is 0.317418\n",
            "step 178 train accuracy is 1, total_loss is -1816.59, inv_loss is 118.258, class_loss is 0.31727\n",
            "step 179 train accuracy is 1, total_loss is -1686.64, inv_loss is 107.837, class_loss is 0.32207\n",
            "step 180 train accuracy is 1, total_loss is -1744.41, inv_loss is 111.076, class_loss is 0.317386\n",
            "step 181 train accuracy is 1, total_loss is -1734.69, inv_loss is 117.912, class_loss is 0.318281\n",
            "step 182 train accuracy is 1, total_loss is -1703.42, inv_loss is 116.513, class_loss is 0.316854\n",
            "step 183 train accuracy is 1, total_loss is -1764.97, inv_loss is 112.632, class_loss is 0.318247\n",
            "step 184 train accuracy is 1, total_loss is -1768.84, inv_loss is 111.392, class_loss is 0.318458\n",
            "step 185 train accuracy is 1, total_loss is -1672.58, inv_loss is 102.722, class_loss is 0.318737\n",
            "step 186 train accuracy is 1, total_loss is -1508.34, inv_loss is 107.241, class_loss is 0.315457\n",
            "step 187 train accuracy is 1, total_loss is -1675.61, inv_loss is 104.536, class_loss is 0.31855\n",
            "step 188 train accuracy is 1, total_loss is -1721.2, inv_loss is 113.849, class_loss is 0.315875\n",
            "step 189 train accuracy is 1, total_loss is -1692.97, inv_loss is 115.728, class_loss is 0.319296\n",
            "step 190 train accuracy is 1, total_loss is -1758.99, inv_loss is 114.343, class_loss is 0.317625\n",
            "step 191 train accuracy is 1, total_loss is -1623.89, inv_loss is 114.652, class_loss is 0.316493\n",
            "step 192 train accuracy is 1, total_loss is -1760.79, inv_loss is 106.647, class_loss is 0.316783\n",
            "step 193 train accuracy is 1, total_loss is -1661.16, inv_loss is 118.665, class_loss is 0.317639\n",
            "step 194 train accuracy is 1, total_loss is -1508.77, inv_loss is 114.43, class_loss is 0.319178\n",
            "step 195 train accuracy is 1, total_loss is -1668.07, inv_loss is 122.334, class_loss is 0.316464\n",
            "step 196 train accuracy is 1, total_loss is -1646.23, inv_loss is 112.895, class_loss is 0.315884\n",
            "step 197 train accuracy is 1, total_loss is -1762.24, inv_loss is 118.506, class_loss is 0.319663\n",
            "step 198 train accuracy is 1, total_loss is -1778.81, inv_loss is 120.538, class_loss is 0.315524\n",
            "step 199 train accuracy is 1, total_loss is -1662.18, inv_loss is 110.465, class_loss is 0.31718\n",
            "beta is 15, test accuracy is 1\n",
            "Training...\n",
            "step 0 train accuracy is 0.99, total_loss is -2238.69, inv_loss is 123.671, class_loss is 0.524549\n",
            "step 1 train accuracy is 1, total_loss is -2264.42, inv_loss is 102.835, class_loss is 0.447879\n",
            "step 2 train accuracy is 0.98, total_loss is -2428.69, inv_loss is 115.876, class_loss is 0.424172\n",
            "step 3 train accuracy is 1, total_loss is -2422.15, inv_loss is 118.258, class_loss is 0.398682\n",
            "step 4 train accuracy is 1, total_loss is -2248.89, inv_loss is 107.837, class_loss is 0.39172\n",
            "step 5 train accuracy is 1, total_loss is -2325.93, inv_loss is 111.076, class_loss is 0.370208\n",
            "step 6 train accuracy is 1, total_loss is -2312.97, inv_loss is 117.912, class_loss is 0.37163\n",
            "step 7 train accuracy is 1, total_loss is -2271.28, inv_loss is 116.513, class_loss is 0.365356\n",
            "step 8 train accuracy is 0.99, total_loss is -2353.35, inv_loss is 112.632, class_loss is 0.360448\n",
            "step 9 train accuracy is 1, total_loss is -2358.52, inv_loss is 111.392, class_loss is 0.35926\n",
            "step 10 train accuracy is 1, total_loss is -2230.17, inv_loss is 102.722, class_loss is 0.353192\n",
            "step 11 train accuracy is 0.99, total_loss is -2011.19, inv_loss is 107.241, class_loss is 0.341093\n",
            "step 12 train accuracy is 1, total_loss is -2234.22, inv_loss is 104.536, class_loss is 0.352631\n",
            "step 13 train accuracy is 1, total_loss is -2295.02, inv_loss is 113.849, class_loss is 0.342696\n",
            "step 14 train accuracy is 1, total_loss is -2257.37, inv_loss is 115.728, class_loss is 0.348495\n",
            "step 15 train accuracy is 1, total_loss is -2345.4, inv_loss is 114.343, class_loss is 0.344838\n",
            "step 16 train accuracy is 1, total_loss is -2165.26, inv_loss is 114.652, class_loss is 0.338635\n",
            "step 17 train accuracy is 1, total_loss is -2347.8, inv_loss is 106.647, class_loss is 0.339774\n",
            "step 18 train accuracy is 1, total_loss is -2214.97, inv_loss is 118.665, class_loss is 0.342162\n",
            "step 19 train accuracy is 1, total_loss is -2011.77, inv_loss is 114.43, class_loss is 0.34367\n",
            "step 20 train accuracy is 0.99, total_loss is -2224.18, inv_loss is 122.334, class_loss is 0.332545\n",
            "step 21 train accuracy is 1, total_loss is -2195.07, inv_loss is 112.895, class_loss is 0.332893\n",
            "step 22 train accuracy is 1, total_loss is -2349.75, inv_loss is 118.506, class_loss is 0.336813\n",
            "step 23 train accuracy is 1, total_loss is -2371.84, inv_loss is 120.538, class_loss is 0.328996\n",
            "step 24 train accuracy is 1, total_loss is -2216.33, inv_loss is 110.465, class_loss is 0.334211\n",
            "step 25 train accuracy is 1, total_loss is -2238.88, inv_loss is 123.671, class_loss is 0.332229\n",
            "step 26 train accuracy is 1, total_loss is -2264.54, inv_loss is 102.835, class_loss is 0.330224\n",
            "step 27 train accuracy is 0.99, total_loss is -2428.78, inv_loss is 115.876, class_loss is 0.331726\n",
            "step 28 train accuracy is 1, total_loss is -2422.22, inv_loss is 118.258, class_loss is 0.329841\n",
            "step 29 train accuracy is 1, total_loss is -2248.94, inv_loss is 107.837, class_loss is 0.336136\n",
            "step 30 train accuracy is 1, total_loss is -2325.98, inv_loss is 111.076, class_loss is 0.327828\n",
            "step 31 train accuracy is 1, total_loss is -2313.01, inv_loss is 117.912, class_loss is 0.331359\n",
            "step 32 train accuracy is 1, total_loss is -2271.32, inv_loss is 116.513, class_loss is 0.329637\n",
            "step 33 train accuracy is 1, total_loss is -2353.38, inv_loss is 112.632, class_loss is 0.330447\n",
            "step 34 train accuracy is 1, total_loss is -2358.55, inv_loss is 111.392, class_loss is 0.330573\n",
            "step 35 train accuracy is 1, total_loss is -2230.2, inv_loss is 102.722, class_loss is 0.329552\n",
            "step 36 train accuracy is 0.99, total_loss is -2011.21, inv_loss is 107.241, class_loss is 0.32295\n",
            "step 37 train accuracy is 1, total_loss is -2234.24, inv_loss is 104.536, class_loss is 0.330812\n",
            "step 38 train accuracy is 1, total_loss is -2295.03, inv_loss is 113.849, class_loss is 0.324953\n",
            "step 39 train accuracy is 1, total_loss is -2257.39, inv_loss is 115.728, class_loss is 0.330805\n",
            "step 40 train accuracy is 1, total_loss is -2345.41, inv_loss is 114.343, class_loss is 0.327855\n",
            "step 41 train accuracy is 1, total_loss is -2165.28, inv_loss is 114.652, class_loss is 0.325086\n",
            "step 42 train accuracy is 1, total_loss is -2347.81, inv_loss is 106.647, class_loss is 0.325915\n",
            "step 43 train accuracy is 1, total_loss is -2214.98, inv_loss is 118.665, class_loss is 0.327775\n",
            "step 44 train accuracy is 1, total_loss is -2011.78, inv_loss is 114.43, class_loss is 0.330256\n",
            "step 45 train accuracy is 1, total_loss is -2224.19, inv_loss is 122.334, class_loss is 0.323067\n",
            "step 46 train accuracy is 1, total_loss is -2195.08, inv_loss is 112.895, class_loss is 0.323127\n",
            "step 47 train accuracy is 1, total_loss is -2349.76, inv_loss is 118.506, class_loss is 0.327284\n",
            "step 48 train accuracy is 1, total_loss is -2371.85, inv_loss is 120.538, class_loss is 0.321427\n",
            "step 49 train accuracy is 1, total_loss is -2216.34, inv_loss is 110.465, class_loss is 0.324955\n",
            "step 50 train accuracy is 1, total_loss is -2238.88, inv_loss is 123.671, class_loss is 0.323971\n",
            "step 51 train accuracy is 1, total_loss is -2264.55, inv_loss is 102.835, class_loss is 0.322941\n",
            "step 52 train accuracy is 1, total_loss is -2428.79, inv_loss is 115.876, class_loss is 0.324053\n",
            "step 53 train accuracy is 1, total_loss is -2422.22, inv_loss is 118.258, class_loss is 0.323108\n",
            "step 54 train accuracy is 1, total_loss is -2248.95, inv_loss is 107.837, class_loss is 0.329179\n",
            "step 55 train accuracy is 1, total_loss is -2325.98, inv_loss is 111.076, class_loss is 0.322413\n",
            "step 56 train accuracy is 1, total_loss is -2313.02, inv_loss is 117.912, class_loss is 0.324881\n",
            "step 57 train accuracy is 1, total_loss is -2271.33, inv_loss is 116.513, class_loss is 0.323336\n",
            "step 58 train accuracy is 1, total_loss is -2353.39, inv_loss is 112.632, class_loss is 0.324661\n",
            "step 59 train accuracy is 1, total_loss is -2358.55, inv_loss is 111.392, class_loss is 0.324737\n",
            "step 60 train accuracy is 1, total_loss is -2230.21, inv_loss is 102.722, class_loss is 0.324469\n",
            "step 61 train accuracy is 0.99, total_loss is -2011.22, inv_loss is 107.241, class_loss is 0.319218\n",
            "step 62 train accuracy is 1, total_loss is -2234.24, inv_loss is 104.536, class_loss is 0.325261\n",
            "step 63 train accuracy is 1, total_loss is -2295.04, inv_loss is 113.849, class_loss is 0.320633\n",
            "step 64 train accuracy is 1, total_loss is -2257.39, inv_loss is 115.728, class_loss is 0.325769\n",
            "step 65 train accuracy is 1, total_loss is -2345.42, inv_loss is 114.343, class_loss is 0.323155\n",
            "step 66 train accuracy is 1, total_loss is -2165.28, inv_loss is 114.652, class_loss is 0.321218\n",
            "step 67 train accuracy is 1, total_loss is -2347.82, inv_loss is 106.647, class_loss is 0.321795\n",
            "step 68 train accuracy is 1, total_loss is -2214.98, inv_loss is 118.665, class_loss is 0.323282\n",
            "step 69 train accuracy is 1, total_loss is -2011.79, inv_loss is 114.43, class_loss is 0.325645\n",
            "step 70 train accuracy is 1, total_loss is -2224.2, inv_loss is 122.334, class_loss is 0.320114\n",
            "step 71 train accuracy is 1, total_loss is -2195.08, inv_loss is 112.895, class_loss is 0.319928\n",
            "step 72 train accuracy is 1, total_loss is -2349.76, inv_loss is 118.506, class_loss is 0.324025\n",
            "step 73 train accuracy is 1, total_loss is -2371.85, inv_loss is 120.538, class_loss is 0.318852\n",
            "step 74 train accuracy is 1, total_loss is -2216.34, inv_loss is 110.465, class_loss is 0.321627\n",
            "step 75 train accuracy is 1, total_loss is -2238.89, inv_loss is 123.671, class_loss is 0.32092\n",
            "step 76 train accuracy is 1, total_loss is -2264.55, inv_loss is 102.835, class_loss is 0.32015\n",
            "step 77 train accuracy is 1, total_loss is -2428.79, inv_loss is 115.876, class_loss is 0.321124\n",
            "step 78 train accuracy is 1, total_loss is -2422.22, inv_loss is 118.258, class_loss is 0.320513\n",
            "step 79 train accuracy is 1, total_loss is -2248.95, inv_loss is 107.837, class_loss is 0.326247\n",
            "step 80 train accuracy is 1, total_loss is -2325.98, inv_loss is 111.076, class_loss is 0.320234\n",
            "step 81 train accuracy is 1, total_loss is -2313.02, inv_loss is 117.912, class_loss is 0.322109\n",
            "step 82 train accuracy is 1, total_loss is -2271.33, inv_loss is 116.513, class_loss is 0.320609\n",
            "step 83 train accuracy is 1, total_loss is -2353.39, inv_loss is 112.632, class_loss is 0.322054\n",
            "step 84 train accuracy is 1, total_loss is -2358.55, inv_loss is 111.392, class_loss is 0.322137\n",
            "step 85 train accuracy is 1, total_loss is -2230.21, inv_loss is 102.722, class_loss is 0.322152\n",
            "step 86 train accuracy is 1, total_loss is -2011.22, inv_loss is 107.241, class_loss is 0.317608\n",
            "step 87 train accuracy is 1, total_loss is -2234.24, inv_loss is 104.536, class_loss is 0.3226\n",
            "step 88 train accuracy is 1, total_loss is -2295.04, inv_loss is 113.849, class_loss is 0.318659\n",
            "step 89 train accuracy is 1, total_loss is -2257.39, inv_loss is 115.728, class_loss is 0.323261\n",
            "step 90 train accuracy is 1, total_loss is -2345.42, inv_loss is 114.343, class_loss is 0.320913\n",
            "step 91 train accuracy is 1, total_loss is -2165.29, inv_loss is 114.652, class_loss is 0.319337\n",
            "step 92 train accuracy is 1, total_loss is -2347.82, inv_loss is 106.647, class_loss is 0.319785\n",
            "step 93 train accuracy is 1, total_loss is -2214.99, inv_loss is 118.665, class_loss is 0.321046\n",
            "step 94 train accuracy is 1, total_loss is -2011.79, inv_loss is 114.43, class_loss is 0.323208\n",
            "step 95 train accuracy is 1, total_loss is -2224.2, inv_loss is 122.334, class_loss is 0.318658\n",
            "step 96 train accuracy is 1, total_loss is -2195.08, inv_loss is 112.895, class_loss is 0.318324\n",
            "step 97 train accuracy is 1, total_loss is -2349.76, inv_loss is 118.506, class_loss is 0.322345\n",
            "step 98 train accuracy is 1, total_loss is -2371.85, inv_loss is 120.538, class_loss is 0.317542\n",
            "step 99 train accuracy is 1, total_loss is -2216.35, inv_loss is 110.465, class_loss is 0.319897\n",
            "step 100 train accuracy is 1, total_loss is -2238.89, inv_loss is 123.671, class_loss is 0.319312\n",
            "step 101 train accuracy is 1, total_loss is -2264.56, inv_loss is 102.835, class_loss is 0.318649\n",
            "step 102 train accuracy is 1, total_loss is -2428.79, inv_loss is 115.876, class_loss is 0.319562\n",
            "step 103 train accuracy is 1, total_loss is -2422.22, inv_loss is 118.258, class_loss is 0.319133\n",
            "step 104 train accuracy is 1, total_loss is -2248.96, inv_loss is 107.837, class_loss is 0.324575\n",
            "step 105 train accuracy is 1, total_loss is -2325.98, inv_loss is 111.076, class_loss is 0.319046\n",
            "step 106 train accuracy is 1, total_loss is -2313.02, inv_loss is 117.912, class_loss is 0.320545\n",
            "step 107 train accuracy is 1, total_loss is -2271.33, inv_loss is 116.513, class_loss is 0.319069\n",
            "step 108 train accuracy is 1, total_loss is -2353.39, inv_loss is 112.632, class_loss is 0.320533\n",
            "step 109 train accuracy is 1, total_loss is -2358.56, inv_loss is 111.392, class_loss is 0.320645\n",
            "step 110 train accuracy is 1, total_loss is -2230.21, inv_loss is 102.722, class_loss is 0.320794\n",
            "step 111 train accuracy is 1, total_loss is -2011.22, inv_loss is 107.241, class_loss is 0.316712\n",
            "step 112 train accuracy is 1, total_loss is -2234.25, inv_loss is 104.536, class_loss is 0.321005\n",
            "step 113 train accuracy is 1, total_loss is -2295.04, inv_loss is 113.849, class_loss is 0.317523\n",
            "step 114 train accuracy is 1, total_loss is -2257.4, inv_loss is 115.728, class_loss is 0.321723\n",
            "step 115 train accuracy is 1, total_loss is -2345.42, inv_loss is 114.343, class_loss is 0.319591\n",
            "step 116 train accuracy is 1, total_loss is -2165.29, inv_loss is 114.652, class_loss is 0.318209\n",
            "step 117 train accuracy is 1, total_loss is -2347.82, inv_loss is 106.647, class_loss is 0.318586\n",
            "step 118 train accuracy is 1, total_loss is -2214.99, inv_loss is 118.665, class_loss is 0.319696\n",
            "step 119 train accuracy is 1, total_loss is -2011.79, inv_loss is 114.43, class_loss is 0.321669\n",
            "step 120 train accuracy is 1, total_loss is -2224.2, inv_loss is 122.334, class_loss is 0.317786\n",
            "step 121 train accuracy is 1, total_loss is -2195.08, inv_loss is 112.895, class_loss is 0.317355\n",
            "step 122 train accuracy is 1, total_loss is -2349.76, inv_loss is 118.506, class_loss is 0.321306\n",
            "step 123 train accuracy is 1, total_loss is -2371.86, inv_loss is 120.538, class_loss is 0.316745\n",
            "step 124 train accuracy is 1, total_loss is -2216.35, inv_loss is 110.465, class_loss is 0.318831\n",
            "step 125 train accuracy is 1, total_loss is -2238.89, inv_loss is 123.671, class_loss is 0.318312\n",
            "step 126 train accuracy is 1, total_loss is -2264.56, inv_loss is 102.835, class_loss is 0.317703\n",
            "step 127 train accuracy is 1, total_loss is -2428.79, inv_loss is 115.876, class_loss is 0.318584\n",
            "step 128 train accuracy is 1, total_loss is -2422.22, inv_loss is 118.258, class_loss is 0.318277\n",
            "step 129 train accuracy is 1, total_loss is -2248.96, inv_loss is 107.837, class_loss is 0.323471\n",
            "step 130 train accuracy is 1, total_loss is -2325.99, inv_loss is 111.076, class_loss is 0.318293\n",
            "step 131 train accuracy is 1, total_loss is -2313.02, inv_loss is 117.912, class_loss is 0.319531\n",
            "step 132 train accuracy is 1, total_loss is -2271.33, inv_loss is 116.513, class_loss is 0.318073\n",
            "step 133 train accuracy is 1, total_loss is -2353.39, inv_loss is 112.632, class_loss is 0.319523\n",
            "step 134 train accuracy is 1, total_loss is -2358.56, inv_loss is 111.392, class_loss is 0.319669\n",
            "step 135 train accuracy is 1, total_loss is -2230.21, inv_loss is 102.722, class_loss is 0.319889\n",
            "step 136 train accuracy is 1, total_loss is -2011.22, inv_loss is 107.241, class_loss is 0.316142\n",
            "step 137 train accuracy is 1, total_loss is -2234.25, inv_loss is 104.536, class_loss is 0.319929\n",
            "step 138 train accuracy is 1, total_loss is -2295.04, inv_loss is 113.849, class_loss is 0.316783\n",
            "step 139 train accuracy is 1, total_loss is -2257.4, inv_loss is 115.728, class_loss is 0.320669\n",
            "step 140 train accuracy is 1, total_loss is -2345.42, inv_loss is 114.343, class_loss is 0.318716\n",
            "step 141 train accuracy is 1, total_loss is -2165.29, inv_loss is 114.652, class_loss is 0.317453\n",
            "step 142 train accuracy is 1, total_loss is -2347.82, inv_loss is 106.647, class_loss is 0.317787\n",
            "step 143 train accuracy is 1, total_loss is -2214.99, inv_loss is 118.665, class_loss is 0.318788\n",
            "step 144 train accuracy is 1, total_loss is -2011.79, inv_loss is 114.43, class_loss is 0.320596\n",
            "step 145 train accuracy is 1, total_loss is -2224.2, inv_loss is 122.334, class_loss is 0.317202\n",
            "step 146 train accuracy is 1, total_loss is -2195.08, inv_loss is 112.895, class_loss is 0.316705\n",
            "step 147 train accuracy is 1, total_loss is -2349.76, inv_loss is 118.506, class_loss is 0.320593\n",
            "step 148 train accuracy is 1, total_loss is -2371.86, inv_loss is 120.538, class_loss is 0.316207\n",
            "step 149 train accuracy is 1, total_loss is -2216.35, inv_loss is 110.465, class_loss is 0.318107\n",
            "step 150 train accuracy is 1, total_loss is -2238.89, inv_loss is 123.671, class_loss is 0.317626\n",
            "step 151 train accuracy is 1, total_loss is -2264.56, inv_loss is 102.835, class_loss is 0.317049\n",
            "step 152 train accuracy is 1, total_loss is -2428.79, inv_loss is 115.876, class_loss is 0.317912\n",
            "step 153 train accuracy is 1, total_loss is -2422.23, inv_loss is 118.258, class_loss is 0.317693\n",
            "step 154 train accuracy is 1, total_loss is -2248.96, inv_loss is 107.837, class_loss is 0.322676\n",
            "step 155 train accuracy is 1, total_loss is -2325.99, inv_loss is 111.076, class_loss is 0.317771\n",
            "step 156 train accuracy is 1, total_loss is -2313.03, inv_loss is 117.912, class_loss is 0.318816\n",
            "step 157 train accuracy is 1, total_loss is -2271.33, inv_loss is 116.513, class_loss is 0.317373\n",
            "step 158 train accuracy is 1, total_loss is -2353.39, inv_loss is 112.632, class_loss is 0.318797\n",
            "step 159 train accuracy is 1, total_loss is -2358.56, inv_loss is 111.392, class_loss is 0.318977\n",
            "step 160 train accuracy is 1, total_loss is -2230.21, inv_loss is 102.722, class_loss is 0.319235\n",
            "step 161 train accuracy is 1, total_loss is -2011.23, inv_loss is 107.241, class_loss is 0.315747\n",
            "step 162 train accuracy is 1, total_loss is -2234.25, inv_loss is 104.536, class_loss is 0.319147\n",
            "step 163 train accuracy is 1, total_loss is -2295.04, inv_loss is 113.849, class_loss is 0.316262\n",
            "step 164 train accuracy is 1, total_loss is -2257.4, inv_loss is 115.728, class_loss is 0.319894\n",
            "step 165 train accuracy is 1, total_loss is -2345.42, inv_loss is 114.343, class_loss is 0.318093\n",
            "step 166 train accuracy is 1, total_loss is -2165.29, inv_loss is 114.652, class_loss is 0.316907\n",
            "step 167 train accuracy is 1, total_loss is -2347.82, inv_loss is 106.647, class_loss is 0.317214\n",
            "step 168 train accuracy is 1, total_loss is -2214.99, inv_loss is 118.665, class_loss is 0.318134\n",
            "step 169 train accuracy is 1, total_loss is -2011.79, inv_loss is 114.43, class_loss is 0.319798\n",
            "step 170 train accuracy is 1, total_loss is -2224.2, inv_loss is 122.334, class_loss is 0.316782\n",
            "step 171 train accuracy is 1, total_loss is -2195.08, inv_loss is 112.895, class_loss is 0.316237\n",
            "step 172 train accuracy is 1, total_loss is -2349.76, inv_loss is 118.506, class_loss is 0.320068\n",
            "step 173 train accuracy is 1, total_loss is -2371.86, inv_loss is 120.538, class_loss is 0.315819\n",
            "step 174 train accuracy is 1, total_loss is -2216.35, inv_loss is 110.465, class_loss is 0.31758\n",
            "step 175 train accuracy is 1, total_loss is -2238.89, inv_loss is 123.671, class_loss is 0.317125\n",
            "step 176 train accuracy is 1, total_loss is -2264.56, inv_loss is 102.835, class_loss is 0.316568\n",
            "step 177 train accuracy is 1, total_loss is -2428.79, inv_loss is 115.876, class_loss is 0.317418\n",
            "step 178 train accuracy is 1, total_loss is -2422.23, inv_loss is 118.258, class_loss is 0.31727\n",
            "step 179 train accuracy is 1, total_loss is -2248.96, inv_loss is 107.837, class_loss is 0.32207\n",
            "step 180 train accuracy is 1, total_loss is -2325.99, inv_loss is 111.076, class_loss is 0.317386\n",
            "step 181 train accuracy is 1, total_loss is -2313.03, inv_loss is 117.912, class_loss is 0.318281\n",
            "step 182 train accuracy is 1, total_loss is -2271.33, inv_loss is 116.513, class_loss is 0.316854\n",
            "step 183 train accuracy is 1, total_loss is -2353.39, inv_loss is 112.632, class_loss is 0.318247\n",
            "step 184 train accuracy is 1, total_loss is -2358.56, inv_loss is 111.392, class_loss is 0.318458\n",
            "step 185 train accuracy is 1, total_loss is -2230.21, inv_loss is 102.722, class_loss is 0.318737\n",
            "step 186 train accuracy is 1, total_loss is -2011.23, inv_loss is 107.241, class_loss is 0.315457\n",
            "step 187 train accuracy is 1, total_loss is -2234.25, inv_loss is 104.536, class_loss is 0.31855\n",
            "step 188 train accuracy is 1, total_loss is -2295.04, inv_loss is 113.849, class_loss is 0.315875\n",
            "step 189 train accuracy is 1, total_loss is -2257.4, inv_loss is 115.728, class_loss is 0.319296\n",
            "step 190 train accuracy is 1, total_loss is -2345.42, inv_loss is 114.343, class_loss is 0.317625\n",
            "step 191 train accuracy is 1, total_loss is -2165.29, inv_loss is 114.652, class_loss is 0.316493\n",
            "step 192 train accuracy is 1, total_loss is -2347.82, inv_loss is 106.647, class_loss is 0.316783\n",
            "step 193 train accuracy is 1, total_loss is -2214.99, inv_loss is 118.665, class_loss is 0.317639\n",
            "step 194 train accuracy is 1, total_loss is -2011.79, inv_loss is 114.43, class_loss is 0.319178\n",
            "step 195 train accuracy is 1, total_loss is -2224.2, inv_loss is 122.334, class_loss is 0.316464\n",
            "step 196 train accuracy is 1, total_loss is -2195.08, inv_loss is 112.895, class_loss is 0.315884\n",
            "step 197 train accuracy is 1, total_loss is -2349.76, inv_loss is 118.506, class_loss is 0.319663\n",
            "step 198 train accuracy is 1, total_loss is -2371.86, inv_loss is 120.538, class_loss is 0.315524\n",
            "step 199 train accuracy is 1, total_loss is -2216.35, inv_loss is 110.465, class_loss is 0.31718\n",
            "beta is 20, test accuracy is 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2d8cd74198>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFKCAYAAAAnj5dkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwBjiDACAMcQZAABjiDMAAMYQZwAAjPl/ZKv3iXx5wqAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}