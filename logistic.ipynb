{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logistic.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fuyan2/ML_research/blob/master/logistic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ELAik7KyA_P0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fb42d893-012c-4d8e-905e-608e5e1c514b"
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pdb\n",
        "import copy\n",
        "import multiprocessing as mp\n",
        "\n",
        "from datetime import datetime\n",
        "from skimage.measure import compare_ssim\n",
        "\n",
        "#Defining Parameters\n",
        "IMG_ROW = 28\n",
        "IMG_COL = 28\n",
        "NUM_LABEL = 10\n",
        "INV_HIDDEN = 5000\n",
        "EPOCHS = 100\n",
        "learning_rate = 0.1\n",
        "loss_beta = 0.003\n",
        "BATCH_SIZE =250\n",
        "\n",
        "#Universal Setup Construct Dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train = np.reshape(x_train, [x_train.shape[0], IMG_ROW*IMG_COL])\n",
        "x_test = np.reshape(x_test, [x_test.shape[0], IMG_ROW*IMG_COL])\n",
        "y_train = np.reshape(y_train, [y_train.shape[0], -1])\n",
        "y_test = np.reshape(y_test, [y_test.shape[0], -1])\n",
        "\n",
        "features = tf.placeholder(tf.float32, shape=[None, IMG_ROW * IMG_COL])\n",
        "labels = tf.placeholder(tf.int32, shape=[None, 1])\n",
        "batch_size = tf.placeholder(tf.int64)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels)).batch(batch_size)\n",
        "iter = dataset.make_initializable_iterator()\n",
        "x, y_ = iter.get_next()\n",
        "y = tf.one_hot(tf.reshape(y_,[-1]), NUM_LABEL)\n",
        "\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"IteratorGetNext_20:0\", shape=(?, 784), dtype=float32)\n",
            "Tensor(\"one_hot_28:0\", shape=(?, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "njQd1mYR1TCs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1326
        },
        "outputId": "daf0cc05-96d7-4d97-86f7-39d82a956ce8"
      },
      "cell_type": "code",
      "source": [
        "xavier_initializer = tf.contrib.layers.xavier_initializer()\n",
        "\n",
        "def layer(input, num_units):\n",
        "  W = tf.Variable(tf.zeros([input.shape[1], num_units]), name=\"w\")\n",
        "  B = tf.Variable(tf.zeros([num_units]), name=\"b\")\n",
        "  output = tf.matmul(input,W) + B\n",
        "  return W, B, output\n",
        "\n",
        "def lrelu(x, alpha):\n",
        "  return tf.nn.relu(x) - alpha * tf.nn.relu(-x)\n",
        "\n",
        "def inverter(y, w, b):\n",
        "  with tf.variable_scope('InvLayer_1', reuse=tf.AUTO_REUSE) as scope:\n",
        "    wx = tf.add_n([\n",
        "      tf.matmul(tf.reshape(w, [1, -1]), inv_weights['inv_w']),\n",
        "      tf.matmul(tf.reshape(b, [1, -1]), inv_weights['inv_b']),\n",
        "    ])\n",
        "    wy = tf.matmul(y, inv_weights['h_label'])\n",
        "\n",
        "    wt = tf.add(wy, wx)\n",
        "\n",
        "    hidden_layer =  tf.add(wt, inv_biases['h_b'])\n",
        "    rect = lrelu(hidden_layer, 0.3)\n",
        "\n",
        "  # Layer 2, rectifier with output IMG_ROWS * IMG_COLS\n",
        "  with tf.variable_scope('DLayer_2') as scope:\n",
        "    out_layer = tf.add(tf.matmul(rect, inv_weights['inv_out']), inv_biases['inv_out'])\n",
        "    rect = lrelu(out_layer, 0.3)\n",
        "  return rect\n",
        "\n",
        "#Build Logistic Layer\n",
        "with tf.name_scope(\"logistic_layer\"):\n",
        "  w,b,z = layer(x,NUM_LABEL)\n",
        "  y_ml = tf.nn.softmax(z)\n",
        "\n",
        "#Build Inverter Regularizer\n",
        "model_weights = tf.concat([tf.reshape(w,[1, -1]),tf.reshape(b,[1, -1])], 1)\n",
        "inv_weights = {\n",
        "  'inv_w': tf.Variable(tf.zeros([tf.reshape(w, [-1]).shape[0], INV_HIDDEN])),\n",
        "  'inv_b': tf.Variable(tf.zeros([tf.reshape(b, [-1]).shape[0], INV_HIDDEN])),\n",
        "  'h_label': tf.Variable(tf.zeros([NUM_LABEL, INV_HIDDEN])),\n",
        "  'inv_out': tf.Variable(tf.zeros([INV_HIDDEN, IMG_ROW * IMG_COL]))\n",
        "}\n",
        "inv_biases = {\n",
        "  'h_b': tf.Variable(tf.zeros([INV_HIDDEN])),\n",
        "  'inv_out': tf.Variable(tf.zeros([IMG_ROW * IMG_COL])),\n",
        "}\n",
        "\n",
        "inv_x = inverter(y, w, b)\n",
        "\n",
        "#Calculate loss\n",
        "class_loss = tf.losses.softmax_cross_entropy(y,y_ml)\n",
        "inv_loss = tf.losses.mean_squared_error(labels=x, predictions=inv_x)\n",
        "\n",
        "# calculate prediction accuracy\n",
        "correct = tf.equal(tf.argmax(y_ml, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "def train(loss_beta, learning_rate, Epoch):\n",
        "  total_loss = class_loss - loss_beta * inv_loss\n",
        "  model_optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(total_loss)\n",
        "  inverter_optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(inv_loss)\n",
        "  init_vars = tf.global_variables_initializer()\n",
        "  \n",
        "  with tf.Session() as sess:\n",
        "    sess.run(init_vars)\n",
        "    # initialise iterator with train data\n",
        "    sess.run(iter.initializer, feed_dict = {features: x_train, labels: y_train, batch_size: BATCH_SIZE})\n",
        "    \n",
        "    print('Training...')\n",
        "    for i in range(Epoch):\n",
        "      sess.run(model_optimizer)\n",
        "      sess.run(inverter_optimizer)\n",
        "      train_acc = sess.run(accuracy)\n",
        "      print(\"step %g train accuracy is %g\"%(i, train_acc))\n",
        "      \n",
        "    # initialise iterator with test data\n",
        "    sess.run(iter.initializer, feed_dict = {features: x_test, labels: y_test, batch_size: y_test.shape[0]})\n",
        "    test_acc = sess.run(accuracy)\n",
        "    print('Test accuracy: {:4f}'.format(test_acc))\n",
        "      \n",
        "    return test_acc\n",
        "\n",
        "betas = [0, 0.001, 0.01, 0.1, 0.5, 1., 2., 5., 7., 10., 15., 20.]\n",
        "test_accs = np.zeros(len(betas))\n",
        "for i,beta in enumerate(betas):\n",
        "  test_accs[i] = train(betas,0.01,500)\n",
        "  print(\"beta is %g, test accuracy is %g\"%(beta, test_accs[i]))\n",
        "  \n",
        "plt.plot(betas, test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "step 0 train accuracy is 0.456\n",
            "step 1 train accuracy is 0.528\n",
            "step 2 train accuracy is 0.528\n",
            "step 3 train accuracy is 0.548\n",
            "step 4 train accuracy is 0.496\n",
            "step 5 train accuracy is 0.512\n",
            "step 6 train accuracy is 0.608\n",
            "step 7 train accuracy is 0.648\n",
            "step 8 train accuracy is 0.652\n",
            "step 9 train accuracy is 0.548\n",
            "step 10 train accuracy is 0.576\n",
            "step 11 train accuracy is 0.62\n",
            "step 12 train accuracy is 0.62\n",
            "step 13 train accuracy is 0.612\n",
            "step 14 train accuracy is 0.612\n",
            "step 15 train accuracy is 0.524\n",
            "step 16 train accuracy is 0.572\n",
            "step 17 train accuracy is 0.58\n",
            "step 18 train accuracy is 0.512\n",
            "step 19 train accuracy is 0.528\n",
            "step 20 train accuracy is 0.628\n",
            "step 21 train accuracy is 0.604\n",
            "step 22 train accuracy is 0.596\n",
            "step 23 train accuracy is 0.612\n",
            "step 24 train accuracy is 0.592\n",
            "step 25 train accuracy is 0.644\n",
            "step 26 train accuracy is 0.588\n",
            "step 27 train accuracy is 0.624\n",
            "step 28 train accuracy is 0.576\n",
            "step 29 train accuracy is 0.68\n",
            "step 30 train accuracy is 0.596\n",
            "step 31 train accuracy is 0.584\n",
            "step 32 train accuracy is 0.588\n",
            "step 33 train accuracy is 0.572\n",
            "step 34 train accuracy is 0.6\n",
            "step 35 train accuracy is 0.596\n",
            "step 36 train accuracy is 0.636\n",
            "step 37 train accuracy is 0.58\n",
            "step 38 train accuracy is 0.528\n",
            "step 39 train accuracy is 0.496\n",
            "step 40 train accuracy is 0.588\n",
            "step 41 train accuracy is 0.524\n",
            "step 42 train accuracy is 0.48\n",
            "step 43 train accuracy is 0.568\n",
            "step 44 train accuracy is 0.616\n",
            "step 45 train accuracy is 0.584\n",
            "step 46 train accuracy is 0.552\n",
            "step 47 train accuracy is 0.596\n",
            "step 48 train accuracy is 0.608\n",
            "step 49 train accuracy is 0.524\n",
            "step 50 train accuracy is 0.628\n",
            "step 51 train accuracy is 0.632\n",
            "step 52 train accuracy is 0.636\n",
            "step 53 train accuracy is 0.6\n",
            "step 54 train accuracy is 0.572\n",
            "step 55 train accuracy is 0.608\n",
            "step 56 train accuracy is 0.52\n",
            "step 57 train accuracy is 0.608\n",
            "step 58 train accuracy is 0.536\n",
            "step 59 train accuracy is 0.56\n",
            "step 60 train accuracy is 0.616\n",
            "step 61 train accuracy is 0.552\n",
            "step 62 train accuracy is 0.608\n",
            "step 63 train accuracy is 0.592\n",
            "step 64 train accuracy is 0.62\n",
            "step 65 train accuracy is 0.636\n",
            "step 66 train accuracy is 0.608\n",
            "step 67 train accuracy is 0.6\n",
            "step 68 train accuracy is 0.628\n",
            "step 69 train accuracy is 0.688\n",
            "step 70 train accuracy is 0.604\n",
            "step 71 train accuracy is 0.644\n",
            "step 72 train accuracy is 0.652\n",
            "step 73 train accuracy is 0.624\n",
            "step 74 train accuracy is 0.628\n",
            "step 75 train accuracy is 0.692\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}